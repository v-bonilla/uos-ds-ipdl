I0509 21:39:26.981269 19026 upgrade_proto.cpp:1082] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': /mnt/bigdisk/AMBDIG8/digits/jobs/20200509-184242-1814/solver.prototxt
I0509 21:39:26.981418 19026 upgrade_proto.cpp:1089] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0509 21:39:26.981423 19026 upgrade_proto.cpp:1091] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0509 21:39:26.981489 19026 caffe.cpp:218] Using GPUs 3
I0509 21:39:26.999938 19026 caffe.cpp:223] GPU 3: GeForce RTX 2080
I0509 21:39:27.398910 19026 solver.cpp:44] Initializing solver from parameters:
test_iter: 76
test_interval: 102
base_lr: 0.01
display: 12
max_iter: 6120
lr_policy: "sigmoid"
gamma: -0.00081699347
momentum: 0.9
weight_decay: 0.0001
stepsize: 3060
snapshot: 3060
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 3
net: "train_val.prototxt"
train_state {
level: 0
stage: ""
}
type: "Nesterov"
I0509 21:39:27.399966 19026 solver.cpp:87] Creating training net from net file: train_val.prototxt
I0509 21:39:27.400612 19026 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer val-data
I0509 21:39:27.400626 19026 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0509 21:39:27.400758 19026 net.cpp:51] Initializing net from parameters:
state {
phase: TRAIN
level: 0
stage: ""
}
layer {
name: "train-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TRAIN
}
transform_param {
mirror: true
crop_size: 227
mean_value: 115.96062
mean_value: 117.19437
mean_value: 119.79225
}
data_param {
source: "/mnt/bigdisk/AMBDIG8/digits/jobs/20200509-183908-c8eb/train_db"
batch_size: 128
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 11
stride: 4
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "norm1"
type: "LRN"
bottom: "conv1"
top: "norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "norm1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8"
type: "InnerProduct"
bottom: "fc7"
top: "fc8"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 196
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8"
bottom: "label"
top: "loss"
}
I0509 21:39:27.400846 19026 layer_factory.hpp:77] Creating layer train-data
I0509 21:39:27.402773 19026 db_lmdb.cpp:35] Opened lmdb /mnt/bigdisk/AMBDIG8/digits/jobs/20200509-183908-c8eb/train_db
I0509 21:39:27.403412 19026 net.cpp:84] Creating Layer train-data
I0509 21:39:27.403424 19026 net.cpp:380] train-data -> data
I0509 21:39:27.403442 19026 net.cpp:380] train-data -> label
I0509 21:39:27.405758 19026 data_layer.cpp:45] output data size: 128,3,227,227
I0509 21:39:27.544507 19026 net.cpp:122] Setting up train-data
I0509 21:39:27.544530 19026 net.cpp:129] Top shape: 128 3 227 227 (19787136)
I0509 21:39:27.544535 19026 net.cpp:129] Top shape: 128 (128)
I0509 21:39:27.544538 19026 net.cpp:137] Memory required for data: 79149056
I0509 21:39:27.544548 19026 layer_factory.hpp:77] Creating layer conv1
I0509 21:39:27.544569 19026 net.cpp:84] Creating Layer conv1
I0509 21:39:27.544574 19026 net.cpp:406] conv1 <- data
I0509 21:39:27.544585 19026 net.cpp:380] conv1 -> conv1
I0509 21:39:28.956269 19026 net.cpp:122] Setting up conv1
I0509 21:39:28.956290 19026 net.cpp:129] Top shape: 128 96 55 55 (37171200)
I0509 21:39:28.956293 19026 net.cpp:137] Memory required for data: 227833856
I0509 21:39:28.956312 19026 layer_factory.hpp:77] Creating layer relu1
I0509 21:39:28.956326 19026 net.cpp:84] Creating Layer relu1
I0509 21:39:28.956329 19026 net.cpp:406] relu1 <- conv1
I0509 21:39:28.956334 19026 net.cpp:367] relu1 -> conv1 (in-place)
I0509 21:39:28.956739 19026 net.cpp:122] Setting up relu1
I0509 21:39:28.956749 19026 net.cpp:129] Top shape: 128 96 55 55 (37171200)
I0509 21:39:28.956751 19026 net.cpp:137] Memory required for data: 376518656
I0509 21:39:28.956754 19026 layer_factory.hpp:77] Creating layer norm1
I0509 21:39:28.956763 19026 net.cpp:84] Creating Layer norm1
I0509 21:39:28.956766 19026 net.cpp:406] norm1 <- conv1
I0509 21:39:28.956773 19026 net.cpp:380] norm1 -> norm1
I0509 21:39:28.957371 19026 net.cpp:122] Setting up norm1
I0509 21:39:28.957408 19026 net.cpp:129] Top shape: 128 96 55 55 (37171200)
I0509 21:39:28.957412 19026 net.cpp:137] Memory required for data: 525203456
I0509 21:39:28.957415 19026 layer_factory.hpp:77] Creating layer pool1
I0509 21:39:28.957423 19026 net.cpp:84] Creating Layer pool1
I0509 21:39:28.957427 19026 net.cpp:406] pool1 <- norm1
I0509 21:39:28.957432 19026 net.cpp:380] pool1 -> pool1
I0509 21:39:28.957473 19026 net.cpp:122] Setting up pool1
I0509 21:39:28.957479 19026 net.cpp:129] Top shape: 128 96 27 27 (8957952)
I0509 21:39:28.957481 19026 net.cpp:137] Memory required for data: 561035264
I0509 21:39:28.957484 19026 layer_factory.hpp:77] Creating layer conv2
I0509 21:39:28.957495 19026 net.cpp:84] Creating Layer conv2
I0509 21:39:28.957499 19026 net.cpp:406] conv2 <- pool1
I0509 21:39:28.957505 19026 net.cpp:380] conv2 -> conv2
I0509 21:39:28.965131 19026 net.cpp:122] Setting up conv2
I0509 21:39:28.965145 19026 net.cpp:129] Top shape: 128 256 27 27 (23887872)
I0509 21:39:28.965148 19026 net.cpp:137] Memory required for data: 656586752
I0509 21:39:28.965158 19026 layer_factory.hpp:77] Creating layer relu2
I0509 21:39:28.965167 19026 net.cpp:84] Creating Layer relu2
I0509 21:39:28.965170 19026 net.cpp:406] relu2 <- conv2
I0509 21:39:28.965175 19026 net.cpp:367] relu2 -> conv2 (in-place)
I0509 21:39:28.965744 19026 net.cpp:122] Setting up relu2
I0509 21:39:28.965752 19026 net.cpp:129] Top shape: 128 256 27 27 (23887872)
I0509 21:39:28.965755 19026 net.cpp:137] Memory required for data: 752138240
I0509 21:39:28.965759 19026 layer_factory.hpp:77] Creating layer norm2
I0509 21:39:28.965766 19026 net.cpp:84] Creating Layer norm2
I0509 21:39:28.965770 19026 net.cpp:406] norm2 <- conv2
I0509 21:39:28.965775 19026 net.cpp:380] norm2 -> norm2
I0509 21:39:28.966183 19026 net.cpp:122] Setting up norm2
I0509 21:39:28.966193 19026 net.cpp:129] Top shape: 128 256 27 27 (23887872)
I0509 21:39:28.966195 19026 net.cpp:137] Memory required for data: 847689728
I0509 21:39:28.966199 19026 layer_factory.hpp:77] Creating layer pool2
I0509 21:39:28.966207 19026 net.cpp:84] Creating Layer pool2
I0509 21:39:28.966212 19026 net.cpp:406] pool2 <- norm2
I0509 21:39:28.966219 19026 net.cpp:380] pool2 -> pool2
I0509 21:39:28.966253 19026 net.cpp:122] Setting up pool2
I0509 21:39:28.966259 19026 net.cpp:129] Top shape: 128 256 13 13 (5537792)
I0509 21:39:28.966261 19026 net.cpp:137] Memory required for data: 869840896
I0509 21:39:28.966264 19026 layer_factory.hpp:77] Creating layer conv3
I0509 21:39:28.966274 19026 net.cpp:84] Creating Layer conv3
I0509 21:39:28.966277 19026 net.cpp:406] conv3 <- pool2
I0509 21:39:28.966284 19026 net.cpp:380] conv3 -> conv3
I0509 21:39:28.977161 19026 net.cpp:122] Setting up conv3
I0509 21:39:28.977178 19026 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0509 21:39:28.977181 19026 net.cpp:137] Memory required for data: 903067648
I0509 21:39:28.977190 19026 layer_factory.hpp:77] Creating layer relu3
I0509 21:39:28.977198 19026 net.cpp:84] Creating Layer relu3
I0509 21:39:28.977201 19026 net.cpp:406] relu3 <- conv3
I0509 21:39:28.977210 19026 net.cpp:367] relu3 -> conv3 (in-place)
I0509 21:39:28.977778 19026 net.cpp:122] Setting up relu3
I0509 21:39:28.977787 19026 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0509 21:39:28.977790 19026 net.cpp:137] Memory required for data: 936294400
I0509 21:39:28.977793 19026 layer_factory.hpp:77] Creating layer conv4
I0509 21:39:28.977804 19026 net.cpp:84] Creating Layer conv4
I0509 21:39:28.977808 19026 net.cpp:406] conv4 <- conv3
I0509 21:39:28.977815 19026 net.cpp:380] conv4 -> conv4
I0509 21:39:28.989770 19026 net.cpp:122] Setting up conv4
I0509 21:39:28.989790 19026 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0509 21:39:28.989794 19026 net.cpp:137] Memory required for data: 969521152
I0509 21:39:28.989802 19026 layer_factory.hpp:77] Creating layer relu4
I0509 21:39:28.989811 19026 net.cpp:84] Creating Layer relu4
I0509 21:39:28.989814 19026 net.cpp:406] relu4 <- conv4
I0509 21:39:28.989820 19026 net.cpp:367] relu4 -> conv4 (in-place)
I0509 21:39:28.990469 19026 net.cpp:122] Setting up relu4
I0509 21:39:28.990505 19026 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0509 21:39:28.990509 19026 net.cpp:137] Memory required for data: 1002747904
I0509 21:39:28.990512 19026 layer_factory.hpp:77] Creating layer conv5
I0509 21:39:28.990523 19026 net.cpp:84] Creating Layer conv5
I0509 21:39:28.990527 19026 net.cpp:406] conv5 <- conv4
I0509 21:39:28.990533 19026 net.cpp:380] conv5 -> conv5
I0509 21:39:29.000253 19026 net.cpp:122] Setting up conv5
I0509 21:39:29.000269 19026 net.cpp:129] Top shape: 128 256 13 13 (5537792)
I0509 21:39:29.000272 19026 net.cpp:137] Memory required for data: 1024899072
I0509 21:39:29.000285 19026 layer_factory.hpp:77] Creating layer relu5
I0509 21:39:29.000293 19026 net.cpp:84] Creating Layer relu5
I0509 21:39:29.000298 19026 net.cpp:406] relu5 <- conv5
I0509 21:39:29.000304 19026 net.cpp:367] relu5 -> conv5 (in-place)
I0509 21:39:29.000856 19026 net.cpp:122] Setting up relu5
I0509 21:39:29.000869 19026 net.cpp:129] Top shape: 128 256 13 13 (5537792)
I0509 21:39:29.000871 19026 net.cpp:137] Memory required for data: 1047050240
I0509 21:39:29.000874 19026 layer_factory.hpp:77] Creating layer pool5
I0509 21:39:29.000881 19026 net.cpp:84] Creating Layer pool5
I0509 21:39:29.000885 19026 net.cpp:406] pool5 <- conv5
I0509 21:39:29.000888 19026 net.cpp:380] pool5 -> pool5
I0509 21:39:29.000927 19026 net.cpp:122] Setting up pool5
I0509 21:39:29.000933 19026 net.cpp:129] Top shape: 128 256 6 6 (1179648)
I0509 21:39:29.000936 19026 net.cpp:137] Memory required for data: 1051768832
I0509 21:39:29.000938 19026 layer_factory.hpp:77] Creating layer fc6
I0509 21:39:29.000952 19026 net.cpp:84] Creating Layer fc6
I0509 21:39:29.000954 19026 net.cpp:406] fc6 <- pool5
I0509 21:39:29.000959 19026 net.cpp:380] fc6 -> fc6
I0509 21:39:29.363235 19026 net.cpp:122] Setting up fc6
I0509 21:39:29.363258 19026 net.cpp:129] Top shape: 128 4096 (524288)
I0509 21:39:29.363261 19026 net.cpp:137] Memory required for data: 1053865984
I0509 21:39:29.363270 19026 layer_factory.hpp:77] Creating layer relu6
I0509 21:39:29.363279 19026 net.cpp:84] Creating Layer relu6
I0509 21:39:29.363282 19026 net.cpp:406] relu6 <- fc6
I0509 21:39:29.363291 19026 net.cpp:367] relu6 -> fc6 (in-place)
I0509 21:39:29.364048 19026 net.cpp:122] Setting up relu6
I0509 21:39:29.364056 19026 net.cpp:129] Top shape: 128 4096 (524288)
I0509 21:39:29.364059 19026 net.cpp:137] Memory required for data: 1055963136
I0509 21:39:29.364063 19026 layer_factory.hpp:77] Creating layer drop6
I0509 21:39:29.364070 19026 net.cpp:84] Creating Layer drop6
I0509 21:39:29.364074 19026 net.cpp:406] drop6 <- fc6
I0509 21:39:29.364079 19026 net.cpp:367] drop6 -> fc6 (in-place)
I0509 21:39:29.364110 19026 net.cpp:122] Setting up drop6
I0509 21:39:29.364115 19026 net.cpp:129] Top shape: 128 4096 (524288)
I0509 21:39:29.364118 19026 net.cpp:137] Memory required for data: 1058060288
I0509 21:39:29.364120 19026 layer_factory.hpp:77] Creating layer fc7
I0509 21:39:29.364127 19026 net.cpp:84] Creating Layer fc7
I0509 21:39:29.364130 19026 net.cpp:406] fc7 <- fc6
I0509 21:39:29.364136 19026 net.cpp:380] fc7 -> fc7
I0509 21:39:29.524353 19026 net.cpp:122] Setting up fc7
I0509 21:39:29.524374 19026 net.cpp:129] Top shape: 128 4096 (524288)
I0509 21:39:29.524376 19026 net.cpp:137] Memory required for data: 1060157440
I0509 21:39:29.524385 19026 layer_factory.hpp:77] Creating layer relu7
I0509 21:39:29.524394 19026 net.cpp:84] Creating Layer relu7
I0509 21:39:29.524396 19026 net.cpp:406] relu7 <- fc7
I0509 21:39:29.524405 19026 net.cpp:367] relu7 -> fc7 (in-place)
I0509 21:39:29.524901 19026 net.cpp:122] Setting up relu7
I0509 21:39:29.524919 19026 net.cpp:129] Top shape: 128 4096 (524288)
I0509 21:39:29.524922 19026 net.cpp:137] Memory required for data: 1062254592
I0509 21:39:29.524926 19026 layer_factory.hpp:77] Creating layer drop7
I0509 21:39:29.524933 19026 net.cpp:84] Creating Layer drop7
I0509 21:39:29.524936 19026 net.cpp:406] drop7 <- fc7
I0509 21:39:29.524941 19026 net.cpp:367] drop7 -> fc7 (in-place)
I0509 21:39:29.524971 19026 net.cpp:122] Setting up drop7
I0509 21:39:29.524998 19026 net.cpp:129] Top shape: 128 4096 (524288)
I0509 21:39:29.525002 19026 net.cpp:137] Memory required for data: 1064351744
I0509 21:39:29.525004 19026 layer_factory.hpp:77] Creating layer fc8
I0509 21:39:29.525013 19026 net.cpp:84] Creating Layer fc8
I0509 21:39:29.525017 19026 net.cpp:406] fc8 <- fc7
I0509 21:39:29.525022 19026 net.cpp:380] fc8 -> fc8
I0509 21:39:29.532891 19026 net.cpp:122] Setting up fc8
I0509 21:39:29.532903 19026 net.cpp:129] Top shape: 128 196 (25088)
I0509 21:39:29.532907 19026 net.cpp:137] Memory required for data: 1064452096
I0509 21:39:29.532912 19026 layer_factory.hpp:77] Creating layer loss
I0509 21:39:29.532919 19026 net.cpp:84] Creating Layer loss
I0509 21:39:29.532923 19026 net.cpp:406] loss <- fc8
I0509 21:39:29.532927 19026 net.cpp:406] loss <- label
I0509 21:39:29.532934 19026 net.cpp:380] loss -> loss
I0509 21:39:29.532944 19026 layer_factory.hpp:77] Creating layer loss
I0509 21:39:29.541949 19026 net.cpp:122] Setting up loss
I0509 21:39:29.541965 19026 net.cpp:129] Top shape: (1)
I0509 21:39:29.541970 19026 net.cpp:132]     with loss weight 1
I0509 21:39:29.541988 19026 net.cpp:137] Memory required for data: 1064452100
I0509 21:39:29.541993 19026 net.cpp:198] loss needs backward computation.
I0509 21:39:29.542002 19026 net.cpp:198] fc8 needs backward computation.
I0509 21:39:29.542006 19026 net.cpp:198] drop7 needs backward computation.
I0509 21:39:29.542009 19026 net.cpp:198] relu7 needs backward computation.
I0509 21:39:29.542012 19026 net.cpp:198] fc7 needs backward computation.
I0509 21:39:29.542017 19026 net.cpp:198] drop6 needs backward computation.
I0509 21:39:29.542021 19026 net.cpp:198] relu6 needs backward computation.
I0509 21:39:29.542024 19026 net.cpp:198] fc6 needs backward computation.
I0509 21:39:29.542027 19026 net.cpp:198] pool5 needs backward computation.
I0509 21:39:29.542032 19026 net.cpp:198] relu5 needs backward computation.
I0509 21:39:29.542035 19026 net.cpp:198] conv5 needs backward computation.
I0509 21:39:29.542039 19026 net.cpp:198] relu4 needs backward computation.
I0509 21:39:29.542043 19026 net.cpp:198] conv4 needs backward computation.
I0509 21:39:29.542047 19026 net.cpp:198] relu3 needs backward computation.
I0509 21:39:29.542050 19026 net.cpp:198] conv3 needs backward computation.
I0509 21:39:29.542058 19026 net.cpp:198] pool2 needs backward computation.
I0509 21:39:29.542062 19026 net.cpp:198] norm2 needs backward computation.
I0509 21:39:29.542066 19026 net.cpp:198] relu2 needs backward computation.
I0509 21:39:29.542069 19026 net.cpp:198] conv2 needs backward computation.
I0509 21:39:29.542073 19026 net.cpp:198] pool1 needs backward computation.
I0509 21:39:29.542078 19026 net.cpp:198] norm1 needs backward computation.
I0509 21:39:29.542081 19026 net.cpp:198] relu1 needs backward computation.
I0509 21:39:29.542084 19026 net.cpp:198] conv1 needs backward computation.
I0509 21:39:29.542089 19026 net.cpp:200] train-data does not need backward computation.
I0509 21:39:29.542093 19026 net.cpp:242] This network produces output loss
I0509 21:39:29.542109 19026 net.cpp:255] Network initialization done.
I0509 21:39:29.542665 19026 solver.cpp:172] Creating test net (#0) specified by net file: train_val.prototxt
I0509 21:39:29.542702 19026 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer train-data
I0509 21:39:29.542892 19026 net.cpp:51] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "val-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TEST
}
transform_param {
crop_size: 227
mean_value: 115.96062
mean_value: 117.19437
mean_value: 119.79225
}
data_param {
source: "/mnt/bigdisk/AMBDIG8/digits/jobs/20200509-183908-c8eb/val_db"
batch_size: 32
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 11
stride: 4
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "norm1"
type: "LRN"
bottom: "conv1"
top: "norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "norm1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8"
type: "InnerProduct"
bottom: "fc7"
top: "fc8"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 196
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "fc8"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8"
bottom: "label"
top: "loss"
}
I0509 21:39:29.543028 19026 layer_factory.hpp:77] Creating layer val-data
I0509 21:39:29.544900 19026 db_lmdb.cpp:35] Opened lmdb /mnt/bigdisk/AMBDIG8/digits/jobs/20200509-183908-c8eb/val_db
I0509 21:39:29.545558 19026 net.cpp:84] Creating Layer val-data
I0509 21:39:29.545570 19026 net.cpp:380] val-data -> data
I0509 21:39:29.545580 19026 net.cpp:380] val-data -> label
I0509 21:39:29.548874 19026 data_layer.cpp:45] output data size: 32,3,227,227
I0509 21:39:29.584673 19026 net.cpp:122] Setting up val-data
I0509 21:39:29.584692 19026 net.cpp:129] Top shape: 32 3 227 227 (4946784)
I0509 21:39:29.584697 19026 net.cpp:129] Top shape: 32 (32)
I0509 21:39:29.584699 19026 net.cpp:137] Memory required for data: 19787264
I0509 21:39:29.584704 19026 layer_factory.hpp:77] Creating layer label_val-data_1_split
I0509 21:39:29.584717 19026 net.cpp:84] Creating Layer label_val-data_1_split
I0509 21:39:29.584720 19026 net.cpp:406] label_val-data_1_split <- label
I0509 21:39:29.584726 19026 net.cpp:380] label_val-data_1_split -> label_val-data_1_split_0
I0509 21:39:29.584734 19026 net.cpp:380] label_val-data_1_split -> label_val-data_1_split_1
I0509 21:39:29.584779 19026 net.cpp:122] Setting up label_val-data_1_split
I0509 21:39:29.584784 19026 net.cpp:129] Top shape: 32 (32)
I0509 21:39:29.584786 19026 net.cpp:129] Top shape: 32 (32)
I0509 21:39:29.584789 19026 net.cpp:137] Memory required for data: 19787520
I0509 21:39:29.584791 19026 layer_factory.hpp:77] Creating layer conv1
I0509 21:39:29.584802 19026 net.cpp:84] Creating Layer conv1
I0509 21:39:29.584805 19026 net.cpp:406] conv1 <- data
I0509 21:39:29.584810 19026 net.cpp:380] conv1 -> conv1
I0509 21:39:29.588174 19026 net.cpp:122] Setting up conv1
I0509 21:39:29.588186 19026 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I0509 21:39:29.588188 19026 net.cpp:137] Memory required for data: 56958720
I0509 21:39:29.588197 19026 layer_factory.hpp:77] Creating layer relu1
I0509 21:39:29.588207 19026 net.cpp:84] Creating Layer relu1
I0509 21:39:29.588212 19026 net.cpp:406] relu1 <- conv1
I0509 21:39:29.588215 19026 net.cpp:367] relu1 -> conv1 (in-place)
I0509 21:39:29.588611 19026 net.cpp:122] Setting up relu1
I0509 21:39:29.588623 19026 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I0509 21:39:29.588625 19026 net.cpp:137] Memory required for data: 94129920
I0509 21:39:29.588629 19026 layer_factory.hpp:77] Creating layer norm1
I0509 21:39:29.588636 19026 net.cpp:84] Creating Layer norm1
I0509 21:39:29.588639 19026 net.cpp:406] norm1 <- conv1
I0509 21:39:29.588645 19026 net.cpp:380] norm1 -> norm1
I0509 21:39:29.589227 19026 net.cpp:122] Setting up norm1
I0509 21:39:29.589237 19026 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I0509 21:39:29.589239 19026 net.cpp:137] Memory required for data: 131301120
I0509 21:39:29.589242 19026 layer_factory.hpp:77] Creating layer pool1
I0509 21:39:29.589251 19026 net.cpp:84] Creating Layer pool1
I0509 21:39:29.589254 19026 net.cpp:406] pool1 <- norm1
I0509 21:39:29.589259 19026 net.cpp:380] pool1 -> pool1
I0509 21:39:29.589291 19026 net.cpp:122] Setting up pool1
I0509 21:39:29.589298 19026 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I0509 21:39:29.589299 19026 net.cpp:137] Memory required for data: 140259072
I0509 21:39:29.589303 19026 layer_factory.hpp:77] Creating layer conv2
I0509 21:39:29.589311 19026 net.cpp:84] Creating Layer conv2
I0509 21:39:29.589315 19026 net.cpp:406] conv2 <- pool1
I0509 21:39:29.589321 19026 net.cpp:380] conv2 -> conv2
I0509 21:39:29.599076 19026 net.cpp:122] Setting up conv2
I0509 21:39:29.599094 19026 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I0509 21:39:29.599097 19026 net.cpp:137] Memory required for data: 164146944
I0509 21:39:29.599107 19026 layer_factory.hpp:77] Creating layer relu2
I0509 21:39:29.599136 19026 net.cpp:84] Creating Layer relu2
I0509 21:39:29.599140 19026 net.cpp:406] relu2 <- conv2
I0509 21:39:29.599146 19026 net.cpp:367] relu2 -> conv2 (in-place)
I0509 21:39:29.599697 19026 net.cpp:122] Setting up relu2
I0509 21:39:29.599709 19026 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I0509 21:39:29.599711 19026 net.cpp:137] Memory required for data: 188034816
I0509 21:39:29.599714 19026 layer_factory.hpp:77] Creating layer norm2
I0509 21:39:29.599725 19026 net.cpp:84] Creating Layer norm2
I0509 21:39:29.599730 19026 net.cpp:406] norm2 <- conv2
I0509 21:39:29.599735 19026 net.cpp:380] norm2 -> norm2
I0509 21:39:29.600472 19026 net.cpp:122] Setting up norm2
I0509 21:39:29.600481 19026 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I0509 21:39:29.600484 19026 net.cpp:137] Memory required for data: 211922688
I0509 21:39:29.600487 19026 layer_factory.hpp:77] Creating layer pool2
I0509 21:39:29.600500 19026 net.cpp:84] Creating Layer pool2
I0509 21:39:29.600503 19026 net.cpp:406] pool2 <- norm2
I0509 21:39:29.600508 19026 net.cpp:380] pool2 -> pool2
I0509 21:39:29.600541 19026 net.cpp:122] Setting up pool2
I0509 21:39:29.600548 19026 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I0509 21:39:29.600549 19026 net.cpp:137] Memory required for data: 217460480
I0509 21:39:29.600553 19026 layer_factory.hpp:77] Creating layer conv3
I0509 21:39:29.600562 19026 net.cpp:84] Creating Layer conv3
I0509 21:39:29.600565 19026 net.cpp:406] conv3 <- pool2
I0509 21:39:29.600571 19026 net.cpp:380] conv3 -> conv3
I0509 21:39:29.612378 19026 net.cpp:122] Setting up conv3
I0509 21:39:29.612397 19026 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0509 21:39:29.612401 19026 net.cpp:137] Memory required for data: 225767168
I0509 21:39:29.612414 19026 layer_factory.hpp:77] Creating layer relu3
I0509 21:39:29.612422 19026 net.cpp:84] Creating Layer relu3
I0509 21:39:29.612426 19026 net.cpp:406] relu3 <- conv3
I0509 21:39:29.612432 19026 net.cpp:367] relu3 -> conv3 (in-place)
I0509 21:39:29.613010 19026 net.cpp:122] Setting up relu3
I0509 21:39:29.613020 19026 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0509 21:39:29.613023 19026 net.cpp:137] Memory required for data: 234073856
I0509 21:39:29.613026 19026 layer_factory.hpp:77] Creating layer conv4
I0509 21:39:29.613039 19026 net.cpp:84] Creating Layer conv4
I0509 21:39:29.613044 19026 net.cpp:406] conv4 <- conv3
I0509 21:39:29.613050 19026 net.cpp:380] conv4 -> conv4
I0509 21:39:29.623358 19026 net.cpp:122] Setting up conv4
I0509 21:39:29.623371 19026 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0509 21:39:29.623374 19026 net.cpp:137] Memory required for data: 242380544
I0509 21:39:29.623380 19026 layer_factory.hpp:77] Creating layer relu4
I0509 21:39:29.623389 19026 net.cpp:84] Creating Layer relu4
I0509 21:39:29.623394 19026 net.cpp:406] relu4 <- conv4
I0509 21:39:29.623399 19026 net.cpp:367] relu4 -> conv4 (in-place)
I0509 21:39:29.623769 19026 net.cpp:122] Setting up relu4
I0509 21:39:29.623780 19026 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0509 21:39:29.623782 19026 net.cpp:137] Memory required for data: 250687232
I0509 21:39:29.623785 19026 layer_factory.hpp:77] Creating layer conv5
I0509 21:39:29.623796 19026 net.cpp:84] Creating Layer conv5
I0509 21:39:29.623800 19026 net.cpp:406] conv5 <- conv4
I0509 21:39:29.623806 19026 net.cpp:380] conv5 -> conv5
I0509 21:39:29.633579 19026 net.cpp:122] Setting up conv5
I0509 21:39:29.633595 19026 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I0509 21:39:29.633599 19026 net.cpp:137] Memory required for data: 256225024
I0509 21:39:29.633610 19026 layer_factory.hpp:77] Creating layer relu5
I0509 21:39:29.633620 19026 net.cpp:84] Creating Layer relu5
I0509 21:39:29.633625 19026 net.cpp:406] relu5 <- conv5
I0509 21:39:29.633630 19026 net.cpp:367] relu5 -> conv5 (in-place)
I0509 21:39:29.634178 19026 net.cpp:122] Setting up relu5
I0509 21:39:29.634187 19026 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I0509 21:39:29.634191 19026 net.cpp:137] Memory required for data: 261762816
I0509 21:39:29.634193 19026 layer_factory.hpp:77] Creating layer pool5
I0509 21:39:29.634225 19026 net.cpp:84] Creating Layer pool5
I0509 21:39:29.634230 19026 net.cpp:406] pool5 <- conv5
I0509 21:39:29.634235 19026 net.cpp:380] pool5 -> pool5
I0509 21:39:29.634277 19026 net.cpp:122] Setting up pool5
I0509 21:39:29.634284 19026 net.cpp:129] Top shape: 32 256 6 6 (294912)
I0509 21:39:29.634285 19026 net.cpp:137] Memory required for data: 262942464
I0509 21:39:29.634289 19026 layer_factory.hpp:77] Creating layer fc6
I0509 21:39:29.634295 19026 net.cpp:84] Creating Layer fc6
I0509 21:39:29.634299 19026 net.cpp:406] fc6 <- pool5
I0509 21:39:29.634305 19026 net.cpp:380] fc6 -> fc6
I0509 21:39:29.993893 19026 net.cpp:122] Setting up fc6
I0509 21:39:29.993917 19026 net.cpp:129] Top shape: 32 4096 (131072)
I0509 21:39:29.993921 19026 net.cpp:137] Memory required for data: 263466752
I0509 21:39:29.993929 19026 layer_factory.hpp:77] Creating layer relu6
I0509 21:39:29.993938 19026 net.cpp:84] Creating Layer relu6
I0509 21:39:29.993942 19026 net.cpp:406] relu6 <- fc6
I0509 21:39:29.993947 19026 net.cpp:367] relu6 -> fc6 (in-place)
I0509 21:39:29.994688 19026 net.cpp:122] Setting up relu6
I0509 21:39:29.994697 19026 net.cpp:129] Top shape: 32 4096 (131072)
I0509 21:39:29.994700 19026 net.cpp:137] Memory required for data: 263991040
I0509 21:39:29.994704 19026 layer_factory.hpp:77] Creating layer drop6
I0509 21:39:29.994710 19026 net.cpp:84] Creating Layer drop6
I0509 21:39:29.994714 19026 net.cpp:406] drop6 <- fc6
I0509 21:39:29.994721 19026 net.cpp:367] drop6 -> fc6 (in-place)
I0509 21:39:29.994745 19026 net.cpp:122] Setting up drop6
I0509 21:39:29.994750 19026 net.cpp:129] Top shape: 32 4096 (131072)
I0509 21:39:29.994752 19026 net.cpp:137] Memory required for data: 264515328
I0509 21:39:29.994755 19026 layer_factory.hpp:77] Creating layer fc7
I0509 21:39:29.994765 19026 net.cpp:84] Creating Layer fc7
I0509 21:39:29.994767 19026 net.cpp:406] fc7 <- fc6
I0509 21:39:29.994772 19026 net.cpp:380] fc7 -> fc7
I0509 21:39:30.154791 19026 net.cpp:122] Setting up fc7
I0509 21:39:30.154810 19026 net.cpp:129] Top shape: 32 4096 (131072)
I0509 21:39:30.154814 19026 net.cpp:137] Memory required for data: 265039616
I0509 21:39:30.154822 19026 layer_factory.hpp:77] Creating layer relu7
I0509 21:39:30.154834 19026 net.cpp:84] Creating Layer relu7
I0509 21:39:30.154839 19026 net.cpp:406] relu7 <- fc7
I0509 21:39:30.154844 19026 net.cpp:367] relu7 -> fc7 (in-place)
I0509 21:39:30.155329 19026 net.cpp:122] Setting up relu7
I0509 21:39:30.155339 19026 net.cpp:129] Top shape: 32 4096 (131072)
I0509 21:39:30.155344 19026 net.cpp:137] Memory required for data: 265563904
I0509 21:39:30.155346 19026 layer_factory.hpp:77] Creating layer drop7
I0509 21:39:30.155352 19026 net.cpp:84] Creating Layer drop7
I0509 21:39:30.155355 19026 net.cpp:406] drop7 <- fc7
I0509 21:39:30.155359 19026 net.cpp:367] drop7 -> fc7 (in-place)
I0509 21:39:30.155385 19026 net.cpp:122] Setting up drop7
I0509 21:39:30.155390 19026 net.cpp:129] Top shape: 32 4096 (131072)
I0509 21:39:30.155393 19026 net.cpp:137] Memory required for data: 266088192
I0509 21:39:30.155395 19026 layer_factory.hpp:77] Creating layer fc8
I0509 21:39:30.155403 19026 net.cpp:84] Creating Layer fc8
I0509 21:39:30.155407 19026 net.cpp:406] fc8 <- fc7
I0509 21:39:30.155411 19026 net.cpp:380] fc8 -> fc8
I0509 21:39:30.163254 19026 net.cpp:122] Setting up fc8
I0509 21:39:30.163265 19026 net.cpp:129] Top shape: 32 196 (6272)
I0509 21:39:30.163269 19026 net.cpp:137] Memory required for data: 266113280
I0509 21:39:30.163275 19026 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0509 21:39:30.163280 19026 net.cpp:84] Creating Layer fc8_fc8_0_split
I0509 21:39:30.163285 19026 net.cpp:406] fc8_fc8_0_split <- fc8
I0509 21:39:30.163290 19026 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0509 21:39:30.163297 19026 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0509 21:39:30.163329 19026 net.cpp:122] Setting up fc8_fc8_0_split
I0509 21:39:30.163336 19026 net.cpp:129] Top shape: 32 196 (6272)
I0509 21:39:30.163339 19026 net.cpp:129] Top shape: 32 196 (6272)
I0509 21:39:30.163362 19026 net.cpp:137] Memory required for data: 266163456
I0509 21:39:30.163365 19026 layer_factory.hpp:77] Creating layer accuracy
I0509 21:39:30.163372 19026 net.cpp:84] Creating Layer accuracy
I0509 21:39:30.163375 19026 net.cpp:406] accuracy <- fc8_fc8_0_split_0
I0509 21:39:30.163379 19026 net.cpp:406] accuracy <- label_val-data_1_split_0
I0509 21:39:30.163383 19026 net.cpp:380] accuracy -> accuracy
I0509 21:39:30.163393 19026 net.cpp:122] Setting up accuracy
I0509 21:39:30.163396 19026 net.cpp:129] Top shape: (1)
I0509 21:39:30.163399 19026 net.cpp:137] Memory required for data: 266163460
I0509 21:39:30.163401 19026 layer_factory.hpp:77] Creating layer loss
I0509 21:39:30.163406 19026 net.cpp:84] Creating Layer loss
I0509 21:39:30.163408 19026 net.cpp:406] loss <- fc8_fc8_0_split_1
I0509 21:39:30.163412 19026 net.cpp:406] loss <- label_val-data_1_split_1
I0509 21:39:30.163416 19026 net.cpp:380] loss -> loss
I0509 21:39:30.163422 19026 layer_factory.hpp:77] Creating layer loss
I0509 21:39:30.164151 19026 net.cpp:122] Setting up loss
I0509 21:39:30.164160 19026 net.cpp:129] Top shape: (1)
I0509 21:39:30.164162 19026 net.cpp:132]     with loss weight 1
I0509 21:39:30.164171 19026 net.cpp:137] Memory required for data: 266163464
I0509 21:39:30.164175 19026 net.cpp:198] loss needs backward computation.
I0509 21:39:30.164178 19026 net.cpp:200] accuracy does not need backward computation.
I0509 21:39:30.164185 19026 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0509 21:39:30.164187 19026 net.cpp:198] fc8 needs backward computation.
I0509 21:39:30.164191 19026 net.cpp:198] drop7 needs backward computation.
I0509 21:39:30.164192 19026 net.cpp:198] relu7 needs backward computation.
I0509 21:39:30.164196 19026 net.cpp:198] fc7 needs backward computation.
I0509 21:39:30.164198 19026 net.cpp:198] drop6 needs backward computation.
I0509 21:39:30.164201 19026 net.cpp:198] relu6 needs backward computation.
I0509 21:39:30.164203 19026 net.cpp:198] fc6 needs backward computation.
I0509 21:39:30.164206 19026 net.cpp:198] pool5 needs backward computation.
I0509 21:39:30.164211 19026 net.cpp:198] relu5 needs backward computation.
I0509 21:39:30.164213 19026 net.cpp:198] conv5 needs backward computation.
I0509 21:39:30.164216 19026 net.cpp:198] relu4 needs backward computation.
I0509 21:39:30.164218 19026 net.cpp:198] conv4 needs backward computation.
I0509 21:39:30.164222 19026 net.cpp:198] relu3 needs backward computation.
I0509 21:39:30.164224 19026 net.cpp:198] conv3 needs backward computation.
I0509 21:39:30.164227 19026 net.cpp:198] pool2 needs backward computation.
I0509 21:39:30.164230 19026 net.cpp:198] norm2 needs backward computation.
I0509 21:39:30.164233 19026 net.cpp:198] relu2 needs backward computation.
I0509 21:39:30.164237 19026 net.cpp:198] conv2 needs backward computation.
I0509 21:39:30.164238 19026 net.cpp:198] pool1 needs backward computation.
I0509 21:39:30.164242 19026 net.cpp:198] norm1 needs backward computation.
I0509 21:39:30.164244 19026 net.cpp:198] relu1 needs backward computation.
I0509 21:39:30.164247 19026 net.cpp:198] conv1 needs backward computation.
I0509 21:39:30.164250 19026 net.cpp:200] label_val-data_1_split does not need backward computation.
I0509 21:39:30.164253 19026 net.cpp:200] val-data does not need backward computation.
I0509 21:39:30.164256 19026 net.cpp:242] This network produces output accuracy
I0509 21:39:30.164259 19026 net.cpp:242] This network produces output loss
I0509 21:39:30.164275 19026 net.cpp:255] Network initialization done.
I0509 21:39:30.164345 19026 solver.cpp:56] Solver scaffolding done.
I0509 21:39:30.164757 19026 caffe.cpp:248] Starting Optimization
I0509 21:39:30.164767 19026 solver.cpp:272] Solving
I0509 21:39:30.164768 19026 solver.cpp:273] Learning Rate Policy: sigmoid
I0509 21:39:30.166296 19026 solver.cpp:330] Iteration 0, Testing net (#0)
I0509 21:39:30.166306 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:39:30.257513 19026 blocking_queue.cpp:49] Waiting for data
I0509 21:39:37.141594 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:39:37.167380 19026 solver.cpp:397]     Test net output #0: accuracy = 0.00575658
I0509 21:39:37.167428 19026 solver.cpp:397]     Test net output #1: loss = 5.28044 (* 1 = 5.28044 loss)
I0509 21:39:37.266381 19026 solver.cpp:218] Iteration 0 (-1.2387e-30 iter/s, 7.10162s/12 iters), loss = 5.27033
I0509 21:39:37.268023 19026 solver.cpp:237]     Train net output #0: loss = 5.27033 (* 1 = 5.27033 loss)
I0509 21:39:37.268054 19026 sgd_solver.cpp:105] Iteration 0, lr = 0.00924142
I0509 21:39:41.307140 19026 solver.cpp:218] Iteration 12 (2.97094 iter/s, 4.03912s/12 iters), loss = 5.29465
I0509 21:39:41.307180 19026 solver.cpp:237]     Train net output #0: loss = 5.29465 (* 1 = 5.29465 loss)
I0509 21:39:41.307188 19026 sgd_solver.cpp:105] Iteration 12, lr = 0.00923452
I0509 21:39:46.323453 19026 solver.cpp:218] Iteration 24 (2.39221 iter/s, 5.01629s/12 iters), loss = 5.31623
I0509 21:39:46.323493 19026 solver.cpp:237]     Train net output #0: loss = 5.31623 (* 1 = 5.31623 loss)
I0509 21:39:46.323500 19026 sgd_solver.cpp:105] Iteration 24, lr = 0.00922756
I0509 21:39:51.305161 19026 solver.cpp:218] Iteration 36 (2.40883 iter/s, 4.98168s/12 iters), loss = 5.27475
I0509 21:39:51.305204 19026 solver.cpp:237]     Train net output #0: loss = 5.27475 (* 1 = 5.27475 loss)
I0509 21:39:51.305212 19026 sgd_solver.cpp:105] Iteration 36, lr = 0.00922054
I0509 21:39:56.277884 19026 solver.cpp:218] Iteration 48 (2.41318 iter/s, 4.97268s/12 iters), loss = 5.2809
I0509 21:39:56.277928 19026 solver.cpp:237]     Train net output #0: loss = 5.2809 (* 1 = 5.2809 loss)
I0509 21:39:56.277936 19026 sgd_solver.cpp:105] Iteration 48, lr = 0.00921347
I0509 21:40:01.279253 19026 solver.cpp:218] Iteration 60 (2.39936 iter/s, 5.00133s/12 iters), loss = 5.27915
I0509 21:40:01.279348 19026 solver.cpp:237]     Train net output #0: loss = 5.27915 (* 1 = 5.27915 loss)
I0509 21:40:01.279357 19026 sgd_solver.cpp:105] Iteration 60, lr = 0.00920633
I0509 21:40:06.285925 19026 solver.cpp:218] Iteration 72 (2.39684 iter/s, 5.00659s/12 iters), loss = 5.28211
I0509 21:40:06.285964 19026 solver.cpp:237]     Train net output #0: loss = 5.28211 (* 1 = 5.28211 loss)
I0509 21:40:06.285974 19026 sgd_solver.cpp:105] Iteration 72, lr = 0.00919914
I0509 21:40:11.312407 19026 solver.cpp:218] Iteration 84 (2.38737 iter/s, 5.02644s/12 iters), loss = 5.26583
I0509 21:40:11.312448 19026 solver.cpp:237]     Train net output #0: loss = 5.26583 (* 1 = 5.26583 loss)
I0509 21:40:11.312454 19026 sgd_solver.cpp:105] Iteration 84, lr = 0.00919189
I0509 21:40:16.326418 19026 solver.cpp:218] Iteration 96 (2.39331 iter/s, 5.01398s/12 iters), loss = 5.28532
I0509 21:40:16.326476 19026 solver.cpp:237]     Train net output #0: loss = 5.28532 (* 1 = 5.28532 loss)
I0509 21:40:16.326488 19026 sgd_solver.cpp:105] Iteration 96, lr = 0.00918457
I0509 21:40:18.028331 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:40:18.338757 19026 solver.cpp:330] Iteration 102, Testing net (#0)
I0509 21:40:18.338778 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:40:25.358808 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:40:25.395218 19026 solver.cpp:397]     Test net output #0: accuracy = 0.00699013
I0509 21:40:25.395265 19026 solver.cpp:397]     Test net output #1: loss = 5.29322 (* 1 = 5.29322 loss)
I0509 21:40:27.231572 19026 solver.cpp:218] Iteration 108 (1.1004 iter/s, 10.9051s/12 iters), loss = 5.29009
I0509 21:40:27.231616 19026 solver.cpp:237]     Train net output #0: loss = 5.29009 (* 1 = 5.29009 loss)
I0509 21:40:27.231623 19026 sgd_solver.cpp:105] Iteration 108, lr = 0.0091772
I0509 21:40:32.236127 19026 solver.cpp:218] Iteration 120 (2.39783 iter/s, 5.00452s/12 iters), loss = 5.30489
I0509 21:40:32.236263 19026 solver.cpp:237]     Train net output #0: loss = 5.30489 (* 1 = 5.30489 loss)
I0509 21:40:32.236272 19026 sgd_solver.cpp:105] Iteration 120, lr = 0.00916977
I0509 21:40:37.240615 19026 solver.cpp:218] Iteration 132 (2.39791 iter/s, 5.00437s/12 iters), loss = 5.2854
I0509 21:40:37.240654 19026 solver.cpp:237]     Train net output #0: loss = 5.2854 (* 1 = 5.2854 loss)
I0509 21:40:37.240661 19026 sgd_solver.cpp:105] Iteration 132, lr = 0.00916227
I0509 21:40:42.213893 19026 solver.cpp:218] Iteration 144 (2.41291 iter/s, 4.97325s/12 iters), loss = 5.27103
I0509 21:40:42.213932 19026 solver.cpp:237]     Train net output #0: loss = 5.27103 (* 1 = 5.27103 loss)
I0509 21:40:42.213938 19026 sgd_solver.cpp:105] Iteration 144, lr = 0.00915472
I0509 21:40:47.212194 19026 solver.cpp:218] Iteration 156 (2.40083 iter/s, 4.99827s/12 iters), loss = 5.21953
I0509 21:40:47.212239 19026 solver.cpp:237]     Train net output #0: loss = 5.21953 (* 1 = 5.21953 loss)
I0509 21:40:47.212246 19026 sgd_solver.cpp:105] Iteration 156, lr = 0.0091471
I0509 21:40:52.256454 19026 solver.cpp:218] Iteration 168 (2.37896 iter/s, 5.04422s/12 iters), loss = 5.21211
I0509 21:40:52.256501 19026 solver.cpp:237]     Train net output #0: loss = 5.21211 (* 1 = 5.21211 loss)
I0509 21:40:52.256510 19026 sgd_solver.cpp:105] Iteration 168, lr = 0.00913942
I0509 21:40:57.408444 19026 solver.cpp:218] Iteration 180 (2.32922 iter/s, 5.15195s/12 iters), loss = 5.24129
I0509 21:40:57.408490 19026 solver.cpp:237]     Train net output #0: loss = 5.24129 (* 1 = 5.24129 loss)
I0509 21:40:57.408504 19026 sgd_solver.cpp:105] Iteration 180, lr = 0.00913168
I0509 21:41:02.451936 19026 solver.cpp:218] Iteration 192 (2.37932 iter/s, 5.04345s/12 iters), loss = 5.22552
I0509 21:41:02.452064 19026 solver.cpp:237]     Train net output #0: loss = 5.22552 (* 1 = 5.22552 loss)
I0509 21:41:02.452072 19026 sgd_solver.cpp:105] Iteration 192, lr = 0.00912387
I0509 21:41:06.354811 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:41:07.043534 19026 solver.cpp:330] Iteration 204, Testing net (#0)
I0509 21:41:07.043552 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:41:13.886037 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:41:13.935226 19026 solver.cpp:397]     Test net output #0: accuracy = 0.011102
I0509 21:41:13.935274 19026 solver.cpp:397]     Test net output #1: loss = 5.21164 (* 1 = 5.21164 loss)
I0509 21:41:14.032668 19026 solver.cpp:218] Iteration 204 (1.03621 iter/s, 11.5806s/12 iters), loss = 5.12952
I0509 21:41:14.032716 19026 solver.cpp:237]     Train net output #0: loss = 5.12952 (* 1 = 5.12952 loss)
I0509 21:41:14.032723 19026 sgd_solver.cpp:105] Iteration 204, lr = 0.009116
I0509 21:41:18.280144 19026 solver.cpp:218] Iteration 216 (2.82524 iter/s, 4.24743s/12 iters), loss = 5.20455
I0509 21:41:18.280184 19026 solver.cpp:237]     Train net output #0: loss = 5.20455 (* 1 = 5.20455 loss)
I0509 21:41:18.280192 19026 sgd_solver.cpp:105] Iteration 216, lr = 0.00910807
I0509 21:41:23.371976 19026 solver.cpp:218] Iteration 228 (2.35673 iter/s, 5.0918s/12 iters), loss = 5.19182
I0509 21:41:23.372020 19026 solver.cpp:237]     Train net output #0: loss = 5.19182 (* 1 = 5.19182 loss)
I0509 21:41:23.372028 19026 sgd_solver.cpp:105] Iteration 228, lr = 0.00910007
I0509 21:41:28.275537 19026 solver.cpp:218] Iteration 240 (2.44722 iter/s, 4.90352s/12 iters), loss = 5.13274
I0509 21:41:28.275580 19026 solver.cpp:237]     Train net output #0: loss = 5.13274 (* 1 = 5.13274 loss)
I0509 21:41:28.275589 19026 sgd_solver.cpp:105] Iteration 240, lr = 0.00909201
I0509 21:41:33.258327 19026 solver.cpp:218] Iteration 252 (2.40831 iter/s, 4.98275s/12 iters), loss = 5.17243
I0509 21:41:33.258435 19026 solver.cpp:237]     Train net output #0: loss = 5.17243 (* 1 = 5.17243 loss)
I0509 21:41:33.258443 19026 sgd_solver.cpp:105] Iteration 252, lr = 0.00908389
I0509 21:41:38.251660 19026 solver.cpp:218] Iteration 264 (2.40325 iter/s, 4.99323s/12 iters), loss = 5.20619
I0509 21:41:38.251699 19026 solver.cpp:237]     Train net output #0: loss = 5.20619 (* 1 = 5.20619 loss)
I0509 21:41:38.251708 19026 sgd_solver.cpp:105] Iteration 264, lr = 0.0090757
I0509 21:41:43.219955 19026 solver.cpp:218] Iteration 276 (2.41533 iter/s, 4.96826s/12 iters), loss = 5.09299
I0509 21:41:43.219995 19026 solver.cpp:237]     Train net output #0: loss = 5.09299 (* 1 = 5.09299 loss)
I0509 21:41:43.220002 19026 sgd_solver.cpp:105] Iteration 276, lr = 0.00906744
I0509 21:41:48.228066 19026 solver.cpp:218] Iteration 288 (2.39613 iter/s, 5.00808s/12 iters), loss = 5.11423
I0509 21:41:48.228104 19026 solver.cpp:237]     Train net output #0: loss = 5.11423 (* 1 = 5.11423 loss)
I0509 21:41:48.228111 19026 sgd_solver.cpp:105] Iteration 288, lr = 0.00905912
I0509 21:41:53.213127 19026 solver.cpp:218] Iteration 300 (2.40721 iter/s, 4.98502s/12 iters), loss = 5.20939
I0509 21:41:53.213169 19026 solver.cpp:237]     Train net output #0: loss = 5.20939 (* 1 = 5.20939 loss)
I0509 21:41:53.213176 19026 sgd_solver.cpp:105] Iteration 300, lr = 0.00905073
I0509 21:41:54.187873 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:41:55.227147 19026 solver.cpp:330] Iteration 306, Testing net (#0)
I0509 21:41:55.227167 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:42:02.299669 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:42:02.362577 19026 solver.cpp:397]     Test net output #0: accuracy = 0.00986842
I0509 21:42:02.362627 19026 solver.cpp:397]     Test net output #1: loss = 5.16546 (* 1 = 5.16546 loss)
I0509 21:42:04.183554 19026 solver.cpp:218] Iteration 312 (1.09385 iter/s, 10.9704s/12 iters), loss = 5.19318
I0509 21:42:04.183687 19026 solver.cpp:237]     Train net output #0: loss = 5.19318 (* 1 = 5.19318 loss)
I0509 21:42:04.183696 19026 sgd_solver.cpp:105] Iteration 312, lr = 0.00904227
I0509 21:42:09.156284 19026 solver.cpp:218] Iteration 324 (2.41322 iter/s, 4.9726s/12 iters), loss = 5.10795
I0509 21:42:09.156323 19026 solver.cpp:237]     Train net output #0: loss = 5.10795 (* 1 = 5.10795 loss)
I0509 21:42:09.156332 19026 sgd_solver.cpp:105] Iteration 324, lr = 0.00903374
I0509 21:42:14.137959 19026 solver.cpp:218] Iteration 336 (2.40885 iter/s, 4.98164s/12 iters), loss = 5.16217
I0509 21:42:14.137998 19026 solver.cpp:237]     Train net output #0: loss = 5.16217 (* 1 = 5.16217 loss)
I0509 21:42:14.138006 19026 sgd_solver.cpp:105] Iteration 336, lr = 0.00902515
I0509 21:42:19.119554 19026 solver.cpp:218] Iteration 348 (2.40888 iter/s, 4.98156s/12 iters), loss = 5.11247
I0509 21:42:19.119593 19026 solver.cpp:237]     Train net output #0: loss = 5.11247 (* 1 = 5.11247 loss)
I0509 21:42:19.119602 19026 sgd_solver.cpp:105] Iteration 348, lr = 0.00901649
I0509 21:42:24.096875 19026 solver.cpp:218] Iteration 360 (2.41095 iter/s, 4.97729s/12 iters), loss = 5.10004
I0509 21:42:24.096915 19026 solver.cpp:237]     Train net output #0: loss = 5.10004 (* 1 = 5.10004 loss)
I0509 21:42:24.096930 19026 sgd_solver.cpp:105] Iteration 360, lr = 0.00900776
I0509 21:42:29.062783 19026 solver.cpp:218] Iteration 372 (2.41649 iter/s, 4.96588s/12 iters), loss = 5.11067
I0509 21:42:29.062822 19026 solver.cpp:237]     Train net output #0: loss = 5.11067 (* 1 = 5.11067 loss)
I0509 21:42:29.062830 19026 sgd_solver.cpp:105] Iteration 372, lr = 0.00899897
I0509 21:42:33.908373 19026 solver.cpp:218] Iteration 384 (2.4765 iter/s, 4.84556s/12 iters), loss = 5.10524
I0509 21:42:33.908413 19026 solver.cpp:237]     Train net output #0: loss = 5.10524 (* 1 = 5.10524 loss)
I0509 21:42:33.908422 19026 sgd_solver.cpp:105] Iteration 384, lr = 0.0089901
I0509 21:42:38.900063 19026 solver.cpp:218] Iteration 396 (2.40401 iter/s, 4.99166s/12 iters), loss = 5.13856
I0509 21:42:38.900177 19026 solver.cpp:237]     Train net output #0: loss = 5.13856 (* 1 = 5.13856 loss)
I0509 21:42:38.900184 19026 sgd_solver.cpp:105] Iteration 396, lr = 0.00898117
I0509 21:42:41.997716 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:42:43.406476 19026 solver.cpp:330] Iteration 408, Testing net (#0)
I0509 21:42:43.406497 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:42:50.388772 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:42:50.462806 19026 solver.cpp:397]     Test net output #0: accuracy = 0.015625
I0509 21:42:50.462857 19026 solver.cpp:397]     Test net output #1: loss = 5.11414 (* 1 = 5.11414 loss)
I0509 21:42:50.560052 19026 solver.cpp:218] Iteration 408 (1.02917 iter/s, 11.6599s/12 iters), loss = 5.05275
I0509 21:42:50.560101 19026 solver.cpp:237]     Train net output #0: loss = 5.05275 (* 1 = 5.05275 loss)
I0509 21:42:50.560111 19026 sgd_solver.cpp:105] Iteration 408, lr = 0.00897216
I0509 21:42:54.754772 19026 solver.cpp:218] Iteration 420 (2.86077 iter/s, 4.19467s/12 iters), loss = 5.12193
I0509 21:42:54.754810 19026 solver.cpp:237]     Train net output #0: loss = 5.12193 (* 1 = 5.12193 loss)
I0509 21:42:54.754818 19026 sgd_solver.cpp:105] Iteration 420, lr = 0.00896308
I0509 21:42:59.712487 19026 solver.cpp:218] Iteration 432 (2.42049 iter/s, 4.95768s/12 iters), loss = 5.09071
I0509 21:42:59.712571 19026 solver.cpp:237]     Train net output #0: loss = 5.09071 (* 1 = 5.09071 loss)
I0509 21:42:59.712585 19026 sgd_solver.cpp:105] Iteration 432, lr = 0.00895394
I0509 21:43:04.710347 19026 solver.cpp:218] Iteration 444 (2.40105 iter/s, 4.99781s/12 iters), loss = 5.01035
I0509 21:43:04.710383 19026 solver.cpp:237]     Train net output #0: loss = 5.01035 (* 1 = 5.01035 loss)
I0509 21:43:04.710391 19026 sgd_solver.cpp:105] Iteration 444, lr = 0.00894472
I0509 21:43:09.697695 19026 solver.cpp:218] Iteration 456 (2.4061 iter/s, 4.98732s/12 iters), loss = 5.06143
I0509 21:43:09.697831 19026 solver.cpp:237]     Train net output #0: loss = 5.06143 (* 1 = 5.06143 loss)
I0509 21:43:09.697841 19026 sgd_solver.cpp:105] Iteration 456, lr = 0.00893543
I0509 21:43:14.679327 19026 solver.cpp:218] Iteration 468 (2.40891 iter/s, 4.9815s/12 iters), loss = 5.00029
I0509 21:43:14.679365 19026 solver.cpp:237]     Train net output #0: loss = 5.00029 (* 1 = 5.00029 loss)
I0509 21:43:14.679374 19026 sgd_solver.cpp:105] Iteration 468, lr = 0.00892607
I0509 21:43:19.643909 19026 solver.cpp:218] Iteration 480 (2.41714 iter/s, 4.96455s/12 iters), loss = 4.97016
I0509 21:43:19.643944 19026 solver.cpp:237]     Train net output #0: loss = 4.97016 (* 1 = 4.97016 loss)
I0509 21:43:19.643952 19026 sgd_solver.cpp:105] Iteration 480, lr = 0.00891663
I0509 21:43:24.631152 19026 solver.cpp:218] Iteration 492 (2.40615 iter/s, 4.98722s/12 iters), loss = 5.0223
I0509 21:43:24.631186 19026 solver.cpp:237]     Train net output #0: loss = 5.0223 (* 1 = 5.0223 loss)
I0509 21:43:24.631193 19026 sgd_solver.cpp:105] Iteration 492, lr = 0.00890712
I0509 21:43:29.615597 19026 solver.cpp:218] Iteration 504 (2.4075 iter/s, 4.98442s/12 iters), loss = 4.99068
I0509 21:43:29.615638 19026 solver.cpp:237]     Train net output #0: loss = 4.99068 (* 1 = 4.99068 loss)
I0509 21:43:29.615646 19026 sgd_solver.cpp:105] Iteration 504, lr = 0.00889754
I0509 21:43:29.860051 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:43:31.637444 19026 solver.cpp:330] Iteration 510, Testing net (#0)
I0509 21:43:31.637470 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:43:38.459172 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:43:38.546437 19026 solver.cpp:397]     Test net output #0: accuracy = 0.0238487
I0509 21:43:38.546486 19026 solver.cpp:397]     Test net output #1: loss = 5.05627 (* 1 = 5.05627 loss)
I0509 21:43:40.392760 19026 solver.cpp:218] Iteration 516 (1.11347 iter/s, 10.7772s/12 iters), loss = 5.08587
I0509 21:43:40.392864 19026 solver.cpp:237]     Train net output #0: loss = 5.08587 (* 1 = 5.08587 loss)
I0509 21:43:40.392874 19026 sgd_solver.cpp:105] Iteration 516, lr = 0.00888789
I0509 21:43:45.390908 19026 solver.cpp:218] Iteration 528 (2.40094 iter/s, 4.99805s/12 iters), loss = 5.13023
I0509 21:43:45.390949 19026 solver.cpp:237]     Train net output #0: loss = 5.13023 (* 1 = 5.13023 loss)
I0509 21:43:45.390956 19026 sgd_solver.cpp:105] Iteration 528, lr = 0.00887816
I0509 21:43:50.370347 19026 solver.cpp:218] Iteration 540 (2.40993 iter/s, 4.9794s/12 iters), loss = 5.04755
I0509 21:43:50.370386 19026 solver.cpp:237]     Train net output #0: loss = 5.04755 (* 1 = 5.04755 loss)
I0509 21:43:50.370394 19026 sgd_solver.cpp:105] Iteration 540, lr = 0.00886836
I0509 21:43:55.359635 19026 solver.cpp:218] Iteration 552 (2.40517 iter/s, 4.98925s/12 iters), loss = 4.92105
I0509 21:43:55.359691 19026 solver.cpp:237]     Train net output #0: loss = 4.92105 (* 1 = 4.92105 loss)
I0509 21:43:55.359704 19026 sgd_solver.cpp:105] Iteration 552, lr = 0.00885849
I0509 21:44:00.298863 19026 solver.cpp:218] Iteration 564 (2.42955 iter/s, 4.93918s/12 iters), loss = 5.01017
I0509 21:44:00.298908 19026 solver.cpp:237]     Train net output #0: loss = 5.01017 (* 1 = 5.01017 loss)
I0509 21:44:00.298918 19026 sgd_solver.cpp:105] Iteration 564, lr = 0.00884853
I0509 21:44:05.283803 19026 solver.cpp:218] Iteration 576 (2.40727 iter/s, 4.9849s/12 iters), loss = 5.00532
I0509 21:44:05.283846 19026 solver.cpp:237]     Train net output #0: loss = 5.00532 (* 1 = 5.00532 loss)
I0509 21:44:05.283855 19026 sgd_solver.cpp:105] Iteration 576, lr = 0.00883851
I0509 21:44:07.309557 19026 blocking_queue.cpp:49] Waiting for data
I0509 21:44:10.277561 19026 solver.cpp:218] Iteration 588 (2.40302 iter/s, 4.99372s/12 iters), loss = 5.06134
I0509 21:44:10.277606 19026 solver.cpp:237]     Train net output #0: loss = 5.06134 (* 1 = 5.06134 loss)
I0509 21:44:10.277613 19026 sgd_solver.cpp:105] Iteration 588, lr = 0.0088284
I0509 21:44:15.258191 19026 solver.cpp:218] Iteration 600 (2.40935 iter/s, 4.98059s/12 iters), loss = 4.82305
I0509 21:44:15.258317 19026 solver.cpp:237]     Train net output #0: loss = 4.82305 (* 1 = 4.82305 loss)
I0509 21:44:15.258327 19026 sgd_solver.cpp:105] Iteration 600, lr = 0.00881823
I0509 21:44:17.727063 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:44:19.970650 19026 solver.cpp:330] Iteration 612, Testing net (#0)
I0509 21:44:19.970670 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:44:26.999552 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:44:27.121258 19026 solver.cpp:397]     Test net output #0: accuracy = 0.0296053
I0509 21:44:27.121296 19026 solver.cpp:397]     Test net output #1: loss = 4.95283 (* 1 = 4.95283 loss)
I0509 21:44:27.217893 19026 solver.cpp:218] Iteration 612 (1.00338 iter/s, 11.9596s/12 iters), loss = 4.8091
I0509 21:44:27.217936 19026 solver.cpp:237]     Train net output #0: loss = 4.8091 (* 1 = 4.8091 loss)
I0509 21:44:27.217942 19026 sgd_solver.cpp:105] Iteration 612, lr = 0.00880797
I0509 21:44:31.392513 19026 solver.cpp:218] Iteration 624 (2.87454 iter/s, 4.17458s/12 iters), loss = 5.05758
I0509 21:44:31.392551 19026 solver.cpp:237]     Train net output #0: loss = 5.05758 (* 1 = 5.05758 loss)
I0509 21:44:31.392560 19026 sgd_solver.cpp:105] Iteration 624, lr = 0.00879764
I0509 21:44:36.361207 19026 solver.cpp:218] Iteration 636 (2.41514 iter/s, 4.96866s/12 iters), loss = 4.9155
I0509 21:44:36.361248 19026 solver.cpp:237]     Train net output #0: loss = 4.9155 (* 1 = 4.9155 loss)
I0509 21:44:36.361255 19026 sgd_solver.cpp:105] Iteration 636, lr = 0.00878723
I0509 21:44:41.360939 19026 solver.cpp:218] Iteration 648 (2.40015 iter/s, 4.99969s/12 iters), loss = 4.86634
I0509 21:44:41.360998 19026 solver.cpp:237]     Train net output #0: loss = 4.86634 (* 1 = 4.86634 loss)
I0509 21:44:41.361012 19026 sgd_solver.cpp:105] Iteration 648, lr = 0.00877674
I0509 21:44:46.293836 19026 solver.cpp:218] Iteration 660 (2.43267 iter/s, 4.93285s/12 iters), loss = 4.8347
I0509 21:44:46.293965 19026 solver.cpp:237]     Train net output #0: loss = 4.8347 (* 1 = 4.8347 loss)
I0509 21:44:46.293974 19026 sgd_solver.cpp:105] Iteration 660, lr = 0.00876618
I0509 21:44:51.250903 19026 solver.cpp:218] Iteration 672 (2.42085 iter/s, 4.95694s/12 iters), loss = 4.9393
I0509 21:44:51.250949 19026 solver.cpp:237]     Train net output #0: loss = 4.9393 (* 1 = 4.9393 loss)
I0509 21:44:51.250957 19026 sgd_solver.cpp:105] Iteration 672, lr = 0.00875553
I0509 21:44:56.244730 19026 solver.cpp:218] Iteration 684 (2.40299 iter/s, 4.99378s/12 iters), loss = 4.77547
I0509 21:44:56.244771 19026 solver.cpp:237]     Train net output #0: loss = 4.77547 (* 1 = 4.77547 loss)
I0509 21:44:56.244779 19026 sgd_solver.cpp:105] Iteration 684, lr = 0.00874481
I0509 21:45:01.215736 19026 solver.cpp:218] Iteration 696 (2.41402 iter/s, 4.97097s/12 iters), loss = 4.85676
I0509 21:45:01.215775 19026 solver.cpp:237]     Train net output #0: loss = 4.85676 (* 1 = 4.85676 loss)
I0509 21:45:01.215782 19026 sgd_solver.cpp:105] Iteration 696, lr = 0.00873401
I0509 21:45:05.798295 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:45:06.178491 19026 solver.cpp:218] Iteration 708 (2.41803 iter/s, 4.96272s/12 iters), loss = 4.86753
I0509 21:45:06.178536 19026 solver.cpp:237]     Train net output #0: loss = 4.86753 (* 1 = 4.86753 loss)
I0509 21:45:06.178544 19026 sgd_solver.cpp:105] Iteration 708, lr = 0.00872313
I0509 21:45:08.213858 19026 solver.cpp:330] Iteration 714, Testing net (#0)
I0509 21:45:08.213878 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:45:15.399330 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:45:15.524873 19026 solver.cpp:397]     Test net output #0: accuracy = 0.0283717
I0509 21:45:15.524910 19026 solver.cpp:397]     Test net output #1: loss = 4.92066 (* 1 = 4.92066 loss)
I0509 21:45:17.374581 19026 solver.cpp:218] Iteration 720 (1.0718 iter/s, 11.1961s/12 iters), loss = 4.82216
I0509 21:45:17.374739 19026 solver.cpp:237]     Train net output #0: loss = 4.82216 (* 1 = 4.82216 loss)
I0509 21:45:17.374748 19026 sgd_solver.cpp:105] Iteration 720, lr = 0.00871217
I0509 21:45:22.393208 19026 solver.cpp:218] Iteration 732 (2.39116 iter/s, 5.01847s/12 iters), loss = 4.82974
I0509 21:45:22.393251 19026 solver.cpp:237]     Train net output #0: loss = 4.82974 (* 1 = 4.82974 loss)
I0509 21:45:22.393260 19026 sgd_solver.cpp:105] Iteration 732, lr = 0.00870113
I0509 21:45:27.345284 19026 solver.cpp:218] Iteration 744 (2.42325 iter/s, 4.95203s/12 iters), loss = 4.6736
I0509 21:45:27.345342 19026 solver.cpp:237]     Train net output #0: loss = 4.6736 (* 1 = 4.6736 loss)
I0509 21:45:27.345356 19026 sgd_solver.cpp:105] Iteration 744, lr = 0.00869001
I0509 21:45:32.326396 19026 solver.cpp:218] Iteration 756 (2.40913 iter/s, 4.98106s/12 iters), loss = 4.95243
I0509 21:45:32.326449 19026 solver.cpp:237]     Train net output #0: loss = 4.95243 (* 1 = 4.95243 loss)
I0509 21:45:32.326463 19026 sgd_solver.cpp:105] Iteration 756, lr = 0.00867881
I0509 21:45:37.314786 19026 solver.cpp:218] Iteration 768 (2.40561 iter/s, 4.98835s/12 iters), loss = 4.72615
I0509 21:45:37.314827 19026 solver.cpp:237]     Train net output #0: loss = 4.72615 (* 1 = 4.72615 loss)
I0509 21:45:37.314836 19026 sgd_solver.cpp:105] Iteration 768, lr = 0.00866753
I0509 21:45:42.337000 19026 solver.cpp:218] Iteration 780 (2.3894 iter/s, 5.02218s/12 iters), loss = 4.74385
I0509 21:45:42.337039 19026 solver.cpp:237]     Train net output #0: loss = 4.74385 (* 1 = 4.74385 loss)
I0509 21:45:42.337047 19026 sgd_solver.cpp:105] Iteration 780, lr = 0.00865617
I0509 21:45:47.321362 19026 solver.cpp:218] Iteration 792 (2.40755 iter/s, 4.98432s/12 iters), loss = 4.67111
I0509 21:45:47.321403 19026 solver.cpp:237]     Train net output #0: loss = 4.67111 (* 1 = 4.67111 loss)
I0509 21:45:47.321411 19026 sgd_solver.cpp:105] Iteration 792, lr = 0.00864472
I0509 21:45:52.301837 19026 solver.cpp:218] Iteration 804 (2.40942 iter/s, 4.98044s/12 iters), loss = 4.66395
I0509 21:45:52.301950 19026 solver.cpp:237]     Train net output #0: loss = 4.66395 (* 1 = 4.66395 loss)
I0509 21:45:52.301959 19026 sgd_solver.cpp:105] Iteration 804, lr = 0.00863319
I0509 21:45:54.079959 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:45:56.872401 19026 solver.cpp:330] Iteration 816, Testing net (#0)
I0509 21:45:56.872421 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:46:03.735884 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:46:03.873165 19026 solver.cpp:397]     Test net output #0: accuracy = 0.0444079
I0509 21:46:03.873214 19026 solver.cpp:397]     Test net output #1: loss = 4.74158 (* 1 = 4.74158 loss)
I0509 21:46:03.969787 19026 solver.cpp:218] Iteration 816 (1.02847 iter/s, 11.6679s/12 iters), loss = 4.74893
I0509 21:46:03.969843 19026 solver.cpp:237]     Train net output #0: loss = 4.74893 (* 1 = 4.74893 loss)
I0509 21:46:03.969856 19026 sgd_solver.cpp:105] Iteration 816, lr = 0.00862158
I0509 21:46:08.224261 19026 solver.cpp:218] Iteration 828 (2.82059 iter/s, 4.25442s/12 iters), loss = 4.73538
I0509 21:46:08.224305 19026 solver.cpp:237]     Train net output #0: loss = 4.73538 (* 1 = 4.73538 loss)
I0509 21:46:08.224313 19026 sgd_solver.cpp:105] Iteration 828, lr = 0.00860989
I0509 21:46:13.277462 19026 solver.cpp:218] Iteration 840 (2.37475 iter/s, 5.05317s/12 iters), loss = 4.72324
I0509 21:46:13.277501 19026 solver.cpp:237]     Train net output #0: loss = 4.72324 (* 1 = 4.72324 loss)
I0509 21:46:13.277510 19026 sgd_solver.cpp:105] Iteration 840, lr = 0.00859812
I0509 21:46:18.563644 19026 solver.cpp:218] Iteration 852 (2.27008 iter/s, 5.28615s/12 iters), loss = 4.57354
I0509 21:46:18.563684 19026 solver.cpp:237]     Train net output #0: loss = 4.57354 (* 1 = 4.57354 loss)
I0509 21:46:18.563693 19026 sgd_solver.cpp:105] Iteration 852, lr = 0.00858626
I0509 21:46:23.857822 19026 solver.cpp:218] Iteration 864 (2.26665 iter/s, 5.29415s/12 iters), loss = 4.54101
I0509 21:46:23.857969 19026 solver.cpp:237]     Train net output #0: loss = 4.54101 (* 1 = 4.54101 loss)
I0509 21:46:23.857977 19026 sgd_solver.cpp:105] Iteration 864, lr = 0.00857431
I0509 21:46:29.197190 19026 solver.cpp:218] Iteration 876 (2.24752 iter/s, 5.33923s/12 iters), loss = 4.62616
I0509 21:46:29.197230 19026 solver.cpp:237]     Train net output #0: loss = 4.62616 (* 1 = 4.62616 loss)
I0509 21:46:29.197238 19026 sgd_solver.cpp:105] Iteration 876, lr = 0.00856229
I0509 21:46:34.347751 19026 solver.cpp:218] Iteration 888 (2.32986 iter/s, 5.15053s/12 iters), loss = 4.43569
I0509 21:46:34.347782 19026 solver.cpp:237]     Train net output #0: loss = 4.43569 (* 1 = 4.43569 loss)
I0509 21:46:34.347790 19026 sgd_solver.cpp:105] Iteration 888, lr = 0.00855018
I0509 21:46:39.476776 19026 solver.cpp:218] Iteration 900 (2.33964 iter/s, 5.129s/12 iters), loss = 4.85121
I0509 21:46:39.476819 19026 solver.cpp:237]     Train net output #0: loss = 4.85121 (* 1 = 4.85121 loss)
I0509 21:46:39.476826 19026 sgd_solver.cpp:105] Iteration 900, lr = 0.00853798
I0509 21:46:43.462779 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:46:44.616999 19026 solver.cpp:218] Iteration 912 (2.33455 iter/s, 5.14019s/12 iters), loss = 4.35004
I0509 21:46:44.617040 19026 solver.cpp:237]     Train net output #0: loss = 4.35004 (* 1 = 4.35004 loss)
I0509 21:46:44.617048 19026 sgd_solver.cpp:105] Iteration 912, lr = 0.0085257
I0509 21:46:46.723634 19026 solver.cpp:330] Iteration 918, Testing net (#0)
I0509 21:46:46.723654 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:46:53.664199 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:46:53.813792 19026 solver.cpp:397]     Test net output #0: accuracy = 0.0509868
I0509 21:46:53.813839 19026 solver.cpp:397]     Test net output #1: loss = 4.62657 (* 1 = 4.62657 loss)
I0509 21:46:55.638605 19026 solver.cpp:218] Iteration 924 (1.08877 iter/s, 11.0216s/12 iters), loss = 4.77414
I0509 21:46:55.638716 19026 solver.cpp:237]     Train net output #0: loss = 4.77414 (* 1 = 4.77414 loss)
I0509 21:46:55.638725 19026 sgd_solver.cpp:105] Iteration 924, lr = 0.00851333
I0509 21:47:00.637843 19026 solver.cpp:218] Iteration 936 (2.40042 iter/s, 4.99913s/12 iters), loss = 4.49474
I0509 21:47:00.637885 19026 solver.cpp:237]     Train net output #0: loss = 4.49474 (* 1 = 4.49474 loss)
I0509 21:47:00.637893 19026 sgd_solver.cpp:105] Iteration 936, lr = 0.00850088
I0509 21:47:05.589515 19026 solver.cpp:218] Iteration 948 (2.42345 iter/s, 4.95162s/12 iters), loss = 4.56225
I0509 21:47:05.589561 19026 solver.cpp:237]     Train net output #0: loss = 4.56225 (* 1 = 4.56225 loss)
I0509 21:47:05.589570 19026 sgd_solver.cpp:105] Iteration 948, lr = 0.00848835
I0509 21:47:10.564965 19026 solver.cpp:218] Iteration 960 (2.41186 iter/s, 4.97541s/12 iters), loss = 4.52487
I0509 21:47:10.565006 19026 solver.cpp:237]     Train net output #0: loss = 4.52487 (* 1 = 4.52487 loss)
I0509 21:47:10.565014 19026 sgd_solver.cpp:105] Iteration 960, lr = 0.00847572
I0509 21:47:15.644235 19026 solver.cpp:218] Iteration 972 (2.36256 iter/s, 5.07923s/12 iters), loss = 4.53871
I0509 21:47:15.644277 19026 solver.cpp:237]     Train net output #0: loss = 4.53871 (* 1 = 4.53871 loss)
I0509 21:47:15.644284 19026 sgd_solver.cpp:105] Iteration 972, lr = 0.00846301
I0509 21:47:20.653107 19026 solver.cpp:218] Iteration 984 (2.39577 iter/s, 5.00883s/12 iters), loss = 4.49281
I0509 21:47:20.653149 19026 solver.cpp:237]     Train net output #0: loss = 4.49281 (* 1 = 4.49281 loss)
I0509 21:47:20.653158 19026 sgd_solver.cpp:105] Iteration 984, lr = 0.00845022
I0509 21:47:25.650203 19026 solver.cpp:218] Iteration 996 (2.40142 iter/s, 4.99705s/12 iters), loss = 4.24595
I0509 21:47:25.650360 19026 solver.cpp:237]     Train net output #0: loss = 4.24595 (* 1 = 4.24595 loss)
I0509 21:47:25.650369 19026 sgd_solver.cpp:105] Iteration 996, lr = 0.00843734
I0509 21:47:30.625720 19026 solver.cpp:218] Iteration 1008 (2.41189 iter/s, 4.97536s/12 iters), loss = 4.5651
I0509 21:47:30.625773 19026 solver.cpp:237]     Train net output #0: loss = 4.5651 (* 1 = 4.5651 loss)
I0509 21:47:30.625787 19026 sgd_solver.cpp:105] Iteration 1008, lr = 0.00842437
I0509 21:47:31.632338 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:47:35.120286 19026 solver.cpp:330] Iteration 1020, Testing net (#0)
I0509 21:47:35.120304 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:47:41.862360 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:47:42.022461 19026 solver.cpp:397]     Test net output #0: accuracy = 0.0534539
I0509 21:47:42.022492 19026 solver.cpp:397]     Test net output #1: loss = 4.62363 (* 1 = 4.62363 loss)
I0509 21:47:42.119757 19026 solver.cpp:218] Iteration 1020 (1.04402 iter/s, 11.494s/12 iters), loss = 4.61822
I0509 21:47:42.119822 19026 solver.cpp:237]     Train net output #0: loss = 4.61822 (* 1 = 4.61822 loss)
I0509 21:47:42.119835 19026 sgd_solver.cpp:105] Iteration 1020, lr = 0.00841131
I0509 21:47:46.286559 19026 solver.cpp:218] Iteration 1032 (2.87995 iter/s, 4.16674s/12 iters), loss = 4.48371
I0509 21:47:46.286598 19026 solver.cpp:237]     Train net output #0: loss = 4.48371 (* 1 = 4.48371 loss)
I0509 21:47:46.286607 19026 sgd_solver.cpp:105] Iteration 1032, lr = 0.00839816
I0509 21:47:51.205513 19026 solver.cpp:218] Iteration 1044 (2.43956 iter/s, 4.91892s/12 iters), loss = 4.40401
I0509 21:47:51.205550 19026 solver.cpp:237]     Train net output #0: loss = 4.40401 (* 1 = 4.40401 loss)
I0509 21:47:51.205559 19026 sgd_solver.cpp:105] Iteration 1044, lr = 0.00838493
I0509 21:47:56.112102 19026 solver.cpp:218] Iteration 1056 (2.44571 iter/s, 4.90655s/12 iters), loss = 4.29139
I0509 21:47:56.112231 19026 solver.cpp:237]     Train net output #0: loss = 4.29139 (* 1 = 4.29139 loss)
I0509 21:47:56.112239 19026 sgd_solver.cpp:105] Iteration 1056, lr = 0.00837161
I0509 21:48:01.147367 19026 solver.cpp:218] Iteration 1068 (2.38325 iter/s, 5.03514s/12 iters), loss = 4.24179
I0509 21:48:01.147406 19026 solver.cpp:237]     Train net output #0: loss = 4.24179 (* 1 = 4.24179 loss)
I0509 21:48:01.147414 19026 sgd_solver.cpp:105] Iteration 1068, lr = 0.0083582
I0509 21:48:06.218837 19026 solver.cpp:218] Iteration 1080 (2.36619 iter/s, 5.07144s/12 iters), loss = 4.14674
I0509 21:48:06.218873 19026 solver.cpp:237]     Train net output #0: loss = 4.14674 (* 1 = 4.14674 loss)
I0509 21:48:06.218881 19026 sgd_solver.cpp:105] Iteration 1080, lr = 0.0083447
I0509 21:48:11.201887 19026 solver.cpp:218] Iteration 1092 (2.40818 iter/s, 4.98302s/12 iters), loss = 4.3007
I0509 21:48:11.201925 19026 solver.cpp:237]     Train net output #0: loss = 4.3007 (* 1 = 4.3007 loss)
I0509 21:48:11.201932 19026 sgd_solver.cpp:105] Iteration 1092, lr = 0.00833112
I0509 21:48:16.212597 19026 solver.cpp:218] Iteration 1104 (2.39489 iter/s, 5.01067s/12 iters), loss = 4.2877
I0509 21:48:16.212659 19026 solver.cpp:237]     Train net output #0: loss = 4.2877 (* 1 = 4.2877 loss)
I0509 21:48:16.212669 19026 sgd_solver.cpp:105] Iteration 1104, lr = 0.00831744
I0509 21:48:19.350720 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:48:21.206482 19026 solver.cpp:218] Iteration 1116 (2.40297 iter/s, 4.99383s/12 iters), loss = 4.23801
I0509 21:48:21.206529 19026 solver.cpp:237]     Train net output #0: loss = 4.23801 (* 1 = 4.23801 loss)
I0509 21:48:21.206537 19026 sgd_solver.cpp:105] Iteration 1116, lr = 0.00830368
I0509 21:48:23.208436 19026 solver.cpp:330] Iteration 1122, Testing net (#0)
I0509 21:48:23.208456 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:48:30.285501 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:48:30.458683 19026 solver.cpp:397]     Test net output #0: accuracy = 0.0699013
I0509 21:48:30.458726 19026 solver.cpp:397]     Test net output #1: loss = 4.37394 (* 1 = 4.37394 loss)
I0509 21:48:32.354709 19026 solver.cpp:218] Iteration 1128 (1.07641 iter/s, 11.1482s/12 iters), loss = 4.32538
I0509 21:48:32.354753 19026 solver.cpp:237]     Train net output #0: loss = 4.32538 (* 1 = 4.32538 loss)
I0509 21:48:32.354760 19026 sgd_solver.cpp:105] Iteration 1128, lr = 0.00828982
I0509 21:48:37.336030 19026 solver.cpp:218] Iteration 1140 (2.40902 iter/s, 4.98128s/12 iters), loss = 4.22089
I0509 21:48:37.336071 19026 solver.cpp:237]     Train net output #0: loss = 4.22089 (* 1 = 4.22089 loss)
I0509 21:48:37.336079 19026 sgd_solver.cpp:105] Iteration 1140, lr = 0.00827588
I0509 21:48:42.245561 19026 solver.cpp:218] Iteration 1152 (2.44424 iter/s, 4.9095s/12 iters), loss = 3.91289
I0509 21:48:42.245609 19026 solver.cpp:237]     Train net output #0: loss = 3.91289 (* 1 = 3.91289 loss)
I0509 21:48:42.245616 19026 sgd_solver.cpp:105] Iteration 1152, lr = 0.00826184
I0509 21:48:45.939332 19026 blocking_queue.cpp:49] Waiting for data
I0509 21:48:47.245440 19026 solver.cpp:218] Iteration 1164 (2.40008 iter/s, 4.99983s/12 iters), loss = 4.16152
I0509 21:48:47.245481 19026 solver.cpp:237]     Train net output #0: loss = 4.16152 (* 1 = 4.16152 loss)
I0509 21:48:47.245488 19026 sgd_solver.cpp:105] Iteration 1164, lr = 0.00824772
I0509 21:48:52.229051 19026 solver.cpp:218] Iteration 1176 (2.40791 iter/s, 4.98357s/12 iters), loss = 4.02199
I0509 21:48:52.229094 19026 solver.cpp:237]     Train net output #0: loss = 4.02199 (* 1 = 4.02199 loss)
I0509 21:48:52.229102 19026 sgd_solver.cpp:105] Iteration 1176, lr = 0.00823351
I0509 21:48:57.222801 19026 solver.cpp:218] Iteration 1188 (2.40302 iter/s, 4.99371s/12 iters), loss = 4.09459
I0509 21:48:57.222843 19026 solver.cpp:237]     Train net output #0: loss = 4.09459 (* 1 = 4.09459 loss)
I0509 21:48:57.222851 19026 sgd_solver.cpp:105] Iteration 1188, lr = 0.0082192
I0509 21:49:02.197268 19026 solver.cpp:218] Iteration 1200 (2.41234 iter/s, 4.97442s/12 iters), loss = 3.72326
I0509 21:49:02.197386 19026 solver.cpp:237]     Train net output #0: loss = 3.72326 (* 1 = 3.72326 loss)
I0509 21:49:02.197394 19026 sgd_solver.cpp:105] Iteration 1200, lr = 0.00820481
I0509 21:49:07.177032 19026 solver.cpp:218] Iteration 1212 (2.40981 iter/s, 4.97965s/12 iters), loss = 4.28122
I0509 21:49:07.177074 19026 solver.cpp:237]     Train net output #0: loss = 4.28122 (* 1 = 4.28122 loss)
I0509 21:49:07.177083 19026 sgd_solver.cpp:105] Iteration 1212, lr = 0.00819032
I0509 21:49:07.451550 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:49:11.700552 19026 solver.cpp:330] Iteration 1224, Testing net (#0)
I0509 21:49:11.700572 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:49:18.487866 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:49:18.700413 19026 solver.cpp:397]     Test net output #0: accuracy = 0.0912829
I0509 21:49:18.700461 19026 solver.cpp:397]     Test net output #1: loss = 4.19724 (* 1 = 4.19724 loss)
I0509 21:49:18.797519 19026 solver.cpp:218] Iteration 1224 (1.03266 iter/s, 11.6205s/12 iters), loss = 4.23132
I0509 21:49:18.797559 19026 solver.cpp:237]     Train net output #0: loss = 4.23132 (* 1 = 4.23132 loss)
I0509 21:49:18.797566 19026 sgd_solver.cpp:105] Iteration 1224, lr = 0.00817574
I0509 21:49:22.960707 19026 solver.cpp:218] Iteration 1236 (2.88243 iter/s, 4.16316s/12 iters), loss = 4.33985
I0509 21:49:22.960739 19026 solver.cpp:237]     Train net output #0: loss = 4.33985 (* 1 = 4.33985 loss)
I0509 21:49:22.960747 19026 sgd_solver.cpp:105] Iteration 1236, lr = 0.00816108
I0509 21:49:27.913120 19026 solver.cpp:218] Iteration 1248 (2.42307 iter/s, 4.95239s/12 iters), loss = 4.3145
I0509 21:49:27.913161 19026 solver.cpp:237]     Train net output #0: loss = 4.3145 (* 1 = 4.3145 loss)
I0509 21:49:27.913169 19026 sgd_solver.cpp:105] Iteration 1248, lr = 0.00814632
I0509 21:49:32.892719 19026 solver.cpp:218] Iteration 1260 (2.40985 iter/s, 4.97956s/12 iters), loss = 3.93473
I0509 21:49:32.892880 19026 solver.cpp:237]     Train net output #0: loss = 3.93473 (* 1 = 3.93473 loss)
I0509 21:49:32.892890 19026 sgd_solver.cpp:105] Iteration 1260, lr = 0.00813147
I0509 21:49:37.892557 19026 solver.cpp:218] Iteration 1272 (2.40015 iter/s, 4.99968s/12 iters), loss = 3.66335
I0509 21:49:37.892602 19026 solver.cpp:237]     Train net output #0: loss = 3.66335 (* 1 = 3.66335 loss)
I0509 21:49:37.892616 19026 sgd_solver.cpp:105] Iteration 1272, lr = 0.00811653
I0509 21:49:42.871784 19026 solver.cpp:218] Iteration 1284 (2.41003 iter/s, 4.97919s/12 iters), loss = 4.0261
I0509 21:49:42.871829 19026 solver.cpp:237]     Train net output #0: loss = 4.0261 (* 1 = 4.0261 loss)
I0509 21:49:42.871836 19026 sgd_solver.cpp:105] Iteration 1284, lr = 0.00810149
I0509 21:49:47.834945 19026 solver.cpp:218] Iteration 1296 (2.41783 iter/s, 4.96312s/12 iters), loss = 3.77155
I0509 21:49:47.834983 19026 solver.cpp:237]     Train net output #0: loss = 3.77155 (* 1 = 3.77155 loss)
I0509 21:49:47.834991 19026 sgd_solver.cpp:105] Iteration 1296, lr = 0.00808637
I0509 21:49:52.775362 19026 solver.cpp:218] Iteration 1308 (2.42896 iter/s, 4.94038s/12 iters), loss = 3.69639
I0509 21:49:52.775408 19026 solver.cpp:237]     Train net output #0: loss = 3.69639 (* 1 = 3.69639 loss)
I0509 21:49:52.775415 19026 sgd_solver.cpp:105] Iteration 1308, lr = 0.00807115
I0509 21:49:55.253262 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:49:57.728720 19026 solver.cpp:218] Iteration 1320 (2.42262 iter/s, 4.95332s/12 iters), loss = 3.6041
I0509 21:49:57.728760 19026 solver.cpp:237]     Train net output #0: loss = 3.6041 (* 1 = 3.6041 loss)
I0509 21:49:57.728767 19026 sgd_solver.cpp:105] Iteration 1320, lr = 0.00805584
I0509 21:49:59.776965 19026 solver.cpp:330] Iteration 1326, Testing net (#0)
I0509 21:49:59.776986 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:50:06.466094 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:50:06.676606 19026 solver.cpp:397]     Test net output #0: accuracy = 0.118832
I0509 21:50:06.676656 19026 solver.cpp:397]     Test net output #1: loss = 4.04236 (* 1 = 4.04236 loss)
I0509 21:50:08.566623 19026 solver.cpp:218] Iteration 1332 (1.10723 iter/s, 10.8379s/12 iters), loss = 3.71126
I0509 21:50:08.566663 19026 solver.cpp:237]     Train net output #0: loss = 3.71126 (* 1 = 3.71126 loss)
I0509 21:50:08.566671 19026 sgd_solver.cpp:105] Iteration 1332, lr = 0.00804044
I0509 21:50:13.537946 19026 solver.cpp:218] Iteration 1344 (2.41386 iter/s, 4.97129s/12 iters), loss = 3.69175
I0509 21:50:13.537986 19026 solver.cpp:237]     Train net output #0: loss = 3.69175 (* 1 = 3.69175 loss)
I0509 21:50:13.537994 19026 sgd_solver.cpp:105] Iteration 1344, lr = 0.00802495
I0509 21:50:18.521808 19026 solver.cpp:218] Iteration 1356 (2.40779 iter/s, 4.98382s/12 iters), loss = 3.49438
I0509 21:50:18.521848 19026 solver.cpp:237]     Train net output #0: loss = 3.49438 (* 1 = 3.49438 loss)
I0509 21:50:18.521857 19026 sgd_solver.cpp:105] Iteration 1356, lr = 0.00800936
I0509 21:50:23.481231 19026 solver.cpp:218] Iteration 1368 (2.41965 iter/s, 4.95939s/12 iters), loss = 3.85005
I0509 21:50:23.481276 19026 solver.cpp:237]     Train net output #0: loss = 3.85005 (* 1 = 3.85005 loss)
I0509 21:50:23.481284 19026 sgd_solver.cpp:105] Iteration 1368, lr = 0.00799369
I0509 21:50:28.460220 19026 solver.cpp:218] Iteration 1380 (2.41015 iter/s, 4.97895s/12 iters), loss = 3.65293
I0509 21:50:28.460263 19026 solver.cpp:237]     Train net output #0: loss = 3.65293 (* 1 = 3.65293 loss)
I0509 21:50:28.460269 19026 sgd_solver.cpp:105] Iteration 1380, lr = 0.00797792
I0509 21:50:33.503190 19026 solver.cpp:218] Iteration 1392 (2.37957 iter/s, 5.04293s/12 iters), loss = 3.3992
I0509 21:50:33.503232 19026 solver.cpp:237]     Train net output #0: loss = 3.3992 (* 1 = 3.3992 loss)
I0509 21:50:33.503239 19026 sgd_solver.cpp:105] Iteration 1392, lr = 0.00796205
I0509 21:50:38.486544 19026 solver.cpp:218] Iteration 1404 (2.40803 iter/s, 4.98332s/12 iters), loss = 3.64406
I0509 21:50:38.486651 19026 solver.cpp:237]     Train net output #0: loss = 3.64406 (* 1 = 3.64406 loss)
I0509 21:50:38.486660 19026 sgd_solver.cpp:105] Iteration 1404, lr = 0.0079461
I0509 21:50:43.127420 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:50:43.476961 19026 solver.cpp:218] Iteration 1416 (2.40466 iter/s, 4.99032s/12 iters), loss = 3.54626
I0509 21:50:43.477006 19026 solver.cpp:237]     Train net output #0: loss = 3.54626 (* 1 = 3.54626 loss)
I0509 21:50:43.477015 19026 sgd_solver.cpp:105] Iteration 1416, lr = 0.00793005
I0509 21:50:47.982357 19026 solver.cpp:330] Iteration 1428, Testing net (#0)
I0509 21:50:47.982378 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:50:55.527833 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:50:55.772756 19026 solver.cpp:397]     Test net output #0: accuracy = 0.140625
I0509 21:50:55.772804 19026 solver.cpp:397]     Test net output #1: loss = 3.82059 (* 1 = 3.82059 loss)
I0509 21:50:55.868505 19026 solver.cpp:218] Iteration 1428 (0.968404 iter/s, 12.3915s/12 iters), loss = 3.76962
I0509 21:50:55.868554 19026 solver.cpp:237]     Train net output #0: loss = 3.76962 (* 1 = 3.76962 loss)
I0509 21:50:55.868564 19026 sgd_solver.cpp:105] Iteration 1428, lr = 0.00791391
I0509 21:51:00.107293 19026 solver.cpp:218] Iteration 1440 (2.83103 iter/s, 4.23874s/12 iters), loss = 3.55734
I0509 21:51:00.107347 19026 solver.cpp:237]     Train net output #0: loss = 3.55734 (* 1 = 3.55734 loss)
I0509 21:51:00.107362 19026 sgd_solver.cpp:105] Iteration 1440, lr = 0.00789768
I0509 21:51:05.114846 19026 solver.cpp:218] Iteration 1452 (2.3964 iter/s, 5.0075s/12 iters), loss = 3.58396
I0509 21:51:05.114889 19026 solver.cpp:237]     Train net output #0: loss = 3.58396 (* 1 = 3.58396 loss)
I0509 21:51:05.114897 19026 sgd_solver.cpp:105] Iteration 1452, lr = 0.00788136
I0509 21:51:10.105330 19026 solver.cpp:218] Iteration 1464 (2.40459 iter/s, 4.99045s/12 iters), loss = 3.4131
I0509 21:51:10.105420 19026 solver.cpp:237]     Train net output #0: loss = 3.4131 (* 1 = 3.4131 loss)
I0509 21:51:10.105429 19026 sgd_solver.cpp:105] Iteration 1464, lr = 0.00786494
I0509 21:51:15.096859 19026 solver.cpp:218] Iteration 1476 (2.40411 iter/s, 4.99145s/12 iters), loss = 3.52193
I0509 21:51:15.096902 19026 solver.cpp:237]     Train net output #0: loss = 3.52193 (* 1 = 3.52193 loss)
I0509 21:51:15.096911 19026 sgd_solver.cpp:105] Iteration 1476, lr = 0.00784843
I0509 21:51:20.066035 19026 solver.cpp:218] Iteration 1488 (2.41491 iter/s, 4.96914s/12 iters), loss = 3.58685
I0509 21:51:20.066078 19026 solver.cpp:237]     Train net output #0: loss = 3.58685 (* 1 = 3.58685 loss)
I0509 21:51:20.066087 19026 sgd_solver.cpp:105] Iteration 1488, lr = 0.00783183
I0509 21:51:25.072335 19026 solver.cpp:218] Iteration 1500 (2.397 iter/s, 5.00625s/12 iters), loss = 3.37283
I0509 21:51:25.072402 19026 solver.cpp:237]     Train net output #0: loss = 3.37283 (* 1 = 3.37283 loss)
I0509 21:51:25.072417 19026 sgd_solver.cpp:105] Iteration 1500, lr = 0.00781514
I0509 21:51:30.131800 19026 solver.cpp:218] Iteration 1512 (2.37182 iter/s, 5.0594s/12 iters), loss = 3.26758
I0509 21:51:30.131866 19026 solver.cpp:237]     Train net output #0: loss = 3.26758 (* 1 = 3.26758 loss)
I0509 21:51:30.131880 19026 sgd_solver.cpp:105] Iteration 1512, lr = 0.00779835
I0509 21:51:31.921723 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:51:35.121592 19026 solver.cpp:218] Iteration 1524 (2.40494 iter/s, 4.98974s/12 iters), loss = 3.17261
I0509 21:51:35.121634 19026 solver.cpp:237]     Train net output #0: loss = 3.17261 (* 1 = 3.17261 loss)
I0509 21:51:35.121642 19026 sgd_solver.cpp:105] Iteration 1524, lr = 0.00778147
I0509 21:51:37.133589 19026 solver.cpp:330] Iteration 1530, Testing net (#0)
I0509 21:51:37.133610 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:51:43.842957 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:51:44.082247 19026 solver.cpp:397]     Test net output #0: accuracy = 0.165707
I0509 21:51:44.082296 19026 solver.cpp:397]     Test net output #1: loss = 3.63025 (* 1 = 3.63025 loss)
I0509 21:51:45.893302 19026 solver.cpp:218] Iteration 1536 (1.11403 iter/s, 10.7717s/12 iters), loss = 3.04178
I0509 21:51:45.893347 19026 solver.cpp:237]     Train net output #0: loss = 3.04178 (* 1 = 3.04178 loss)
I0509 21:51:45.893355 19026 sgd_solver.cpp:105] Iteration 1536, lr = 0.0077645
I0509 21:51:50.821643 19026 solver.cpp:218] Iteration 1548 (2.43492 iter/s, 4.9283s/12 iters), loss = 3.48508
I0509 21:51:50.821681 19026 solver.cpp:237]     Train net output #0: loss = 3.48508 (* 1 = 3.48508 loss)
I0509 21:51:50.821689 19026 sgd_solver.cpp:105] Iteration 1548, lr = 0.00774744
I0509 21:51:55.805357 19026 solver.cpp:218] Iteration 1560 (2.40786 iter/s, 4.98368s/12 iters), loss = 3.09999
I0509 21:51:55.805394 19026 solver.cpp:237]     Train net output #0: loss = 3.09999 (* 1 = 3.09999 loss)
I0509 21:51:55.805402 19026 sgd_solver.cpp:105] Iteration 1560, lr = 0.00773028
I0509 21:52:00.802850 19026 solver.cpp:218] Iteration 1572 (2.40122 iter/s, 4.99746s/12 iters), loss = 2.92341
I0509 21:52:00.802891 19026 solver.cpp:237]     Train net output #0: loss = 2.92341 (* 1 = 2.92341 loss)
I0509 21:52:00.802898 19026 sgd_solver.cpp:105] Iteration 1572, lr = 0.00771304
I0509 21:52:05.694720 19026 solver.cpp:218] Iteration 1584 (2.45307 iter/s, 4.89183s/12 iters), loss = 3.15663
I0509 21:52:05.694763 19026 solver.cpp:237]     Train net output #0: loss = 3.15663 (* 1 = 3.15663 loss)
I0509 21:52:05.694772 19026 sgd_solver.cpp:105] Iteration 1584, lr = 0.0076957
I0509 21:52:10.693946 19026 solver.cpp:218] Iteration 1596 (2.40039 iter/s, 4.99919s/12 iters), loss = 3.04616
I0509 21:52:10.693987 19026 solver.cpp:237]     Train net output #0: loss = 3.04616 (* 1 = 3.04616 loss)
I0509 21:52:10.693994 19026 sgd_solver.cpp:105] Iteration 1596, lr = 0.00767826
I0509 21:52:15.678356 19026 solver.cpp:218] Iteration 1608 (2.40752 iter/s, 4.98437s/12 iters), loss = 3.45537
I0509 21:52:15.678531 19026 solver.cpp:237]     Train net output #0: loss = 3.45537 (* 1 = 3.45537 loss)
I0509 21:52:15.678547 19026 sgd_solver.cpp:105] Iteration 1608, lr = 0.00766074
I0509 21:52:19.561424 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:52:20.640156 19026 solver.cpp:218] Iteration 1620 (2.41855 iter/s, 4.96164s/12 iters), loss = 2.61016
I0509 21:52:20.640193 19026 solver.cpp:237]     Train net output #0: loss = 2.61016 (* 1 = 2.61016 loss)
I0509 21:52:20.640202 19026 sgd_solver.cpp:105] Iteration 1620, lr = 0.00764313
I0509 21:52:25.169462 19026 solver.cpp:330] Iteration 1632, Testing net (#0)
I0509 21:52:25.169481 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:52:31.813103 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:52:32.063732 19026 solver.cpp:397]     Test net output #0: accuracy = 0.187089
I0509 21:52:32.063786 19026 solver.cpp:397]     Test net output #1: loss = 3.58442 (* 1 = 3.58442 loss)
I0509 21:52:32.160856 19026 solver.cpp:218] Iteration 1632 (1.0416 iter/s, 11.5207s/12 iters), loss = 2.99966
I0509 21:52:32.160912 19026 solver.cpp:237]     Train net output #0: loss = 2.99966 (* 1 = 2.99966 loss)
I0509 21:52:32.160925 19026 sgd_solver.cpp:105] Iteration 1632, lr = 0.00762542
I0509 21:52:36.321082 19026 solver.cpp:218] Iteration 1644 (2.88451 iter/s, 4.16016s/12 iters), loss = 3.0785
I0509 21:52:36.321143 19026 solver.cpp:237]     Train net output #0: loss = 3.0785 (* 1 = 3.0785 loss)
I0509 21:52:36.321156 19026 sgd_solver.cpp:105] Iteration 1644, lr = 0.00760762
I0509 21:52:41.315613 19026 solver.cpp:218] Iteration 1656 (2.40265 iter/s, 4.99448s/12 iters), loss = 2.94681
I0509 21:52:41.315652 19026 solver.cpp:237]     Train net output #0: loss = 2.94681 (* 1 = 2.94681 loss)
I0509 21:52:41.315660 19026 sgd_solver.cpp:105] Iteration 1656, lr = 0.00758973
I0509 21:52:46.326479 19026 solver.cpp:218] Iteration 1668 (2.39481 iter/s, 5.01083s/12 iters), loss = 2.85011
I0509 21:52:46.326632 19026 solver.cpp:237]     Train net output #0: loss = 2.85011 (* 1 = 2.85011 loss)
I0509 21:52:46.326642 19026 sgd_solver.cpp:105] Iteration 1668, lr = 0.00757175
I0509 21:52:51.265674 19026 solver.cpp:218] Iteration 1680 (2.42962 iter/s, 4.93905s/12 iters), loss = 2.88312
I0509 21:52:51.265717 19026 solver.cpp:237]     Train net output #0: loss = 2.88312 (* 1 = 2.88312 loss)
I0509 21:52:51.265727 19026 sgd_solver.cpp:105] Iteration 1680, lr = 0.00755368
I0509 21:52:56.250248 19026 solver.cpp:218] Iteration 1692 (2.40745 iter/s, 4.98453s/12 iters), loss = 3.30948
I0509 21:52:56.250293 19026 solver.cpp:237]     Train net output #0: loss = 3.30948 (* 1 = 3.30948 loss)
I0509 21:52:56.250300 19026 sgd_solver.cpp:105] Iteration 1692, lr = 0.00753552
I0509 21:53:01.245708 19026 solver.cpp:218] Iteration 1704 (2.4022 iter/s, 4.99542s/12 iters), loss = 2.70584
I0509 21:53:01.245751 19026 solver.cpp:237]     Train net output #0: loss = 2.70584 (* 1 = 2.70584 loss)
I0509 21:53:01.245759 19026 sgd_solver.cpp:105] Iteration 1704, lr = 0.00751727
I0509 21:53:06.217361 19026 solver.cpp:218] Iteration 1716 (2.4137 iter/s, 4.97162s/12 iters), loss = 2.63031
I0509 21:53:06.217402 19026 solver.cpp:237]     Train net output #0: loss = 2.63031 (* 1 = 2.63031 loss)
I0509 21:53:06.217411 19026 sgd_solver.cpp:105] Iteration 1716, lr = 0.00749893
I0509 21:53:07.250888 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:53:11.135288 19026 solver.cpp:218] Iteration 1728 (2.44007 iter/s, 4.91789s/12 iters), loss = 3.21838
I0509 21:53:11.135329 19026 solver.cpp:237]     Train net output #0: loss = 3.21838 (* 1 = 3.21838 loss)
I0509 21:53:11.135337 19026 sgd_solver.cpp:105] Iteration 1728, lr = 0.00748049
I0509 21:53:13.147958 19026 solver.cpp:330] Iteration 1734, Testing net (#0)
I0509 21:53:13.147987 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:53:19.955669 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:53:20.241215 19026 solver.cpp:397]     Test net output #0: accuracy = 0.244243
I0509 21:53:20.241263 19026 solver.cpp:397]     Test net output #1: loss = 3.18253 (* 1 = 3.18253 loss)
I0509 21:53:22.052302 19026 solver.cpp:218] Iteration 1740 (1.0992 iter/s, 10.917s/12 iters), loss = 2.45756
I0509 21:53:22.052345 19026 solver.cpp:237]     Train net output #0: loss = 2.45756 (* 1 = 2.45756 loss)
I0509 21:53:22.052353 19026 sgd_solver.cpp:105] Iteration 1740, lr = 0.00746197
I0509 21:53:22.409651 19026 blocking_queue.cpp:49] Waiting for data
I0509 21:53:27.019392 19026 solver.cpp:218] Iteration 1752 (2.41592 iter/s, 4.96705s/12 iters), loss = 2.81128
I0509 21:53:27.019438 19026 solver.cpp:237]     Train net output #0: loss = 2.81128 (* 1 = 2.81128 loss)
I0509 21:53:27.019445 19026 sgd_solver.cpp:105] Iteration 1752, lr = 0.00744336
I0509 21:53:31.986512 19026 solver.cpp:218] Iteration 1764 (2.41591 iter/s, 4.96707s/12 iters), loss = 2.92157
I0509 21:53:31.986565 19026 solver.cpp:237]     Train net output #0: loss = 2.92157 (* 1 = 2.92157 loss)
I0509 21:53:31.986578 19026 sgd_solver.cpp:105] Iteration 1764, lr = 0.00742466
I0509 21:53:36.981856 19026 solver.cpp:218] Iteration 1776 (2.40226 iter/s, 4.9953s/12 iters), loss = 2.70048
I0509 21:53:36.981896 19026 solver.cpp:237]     Train net output #0: loss = 2.70048 (* 1 = 2.70048 loss)
I0509 21:53:36.981904 19026 sgd_solver.cpp:105] Iteration 1776, lr = 0.00740587
I0509 21:53:41.938431 19026 solver.cpp:218] Iteration 1788 (2.42104 iter/s, 4.95654s/12 iters), loss = 2.33366
I0509 21:53:41.938472 19026 solver.cpp:237]     Train net output #0: loss = 2.33366 (* 1 = 2.33366 loss)
I0509 21:53:41.938479 19026 sgd_solver.cpp:105] Iteration 1788, lr = 0.00738699
I0509 21:53:46.932118 19026 solver.cpp:218] Iteration 1800 (2.40305 iter/s, 4.99366s/12 iters), loss = 2.8358
I0509 21:53:46.932158 19026 solver.cpp:237]     Train net output #0: loss = 2.8358 (* 1 = 2.8358 loss)
I0509 21:53:46.932166 19026 sgd_solver.cpp:105] Iteration 1800, lr = 0.00736802
I0509 21:53:51.853752 19026 solver.cpp:218] Iteration 1812 (2.43823 iter/s, 4.9216s/12 iters), loss = 2.60557
I0509 21:53:51.853905 19026 solver.cpp:237]     Train net output #0: loss = 2.60557 (* 1 = 2.60557 loss)
I0509 21:53:51.853914 19026 sgd_solver.cpp:105] Iteration 1812, lr = 0.00734896
I0509 21:53:55.010545 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:53:56.820943 19026 solver.cpp:218] Iteration 1824 (2.41592 iter/s, 4.96704s/12 iters), loss = 2.58521
I0509 21:53:56.820986 19026 solver.cpp:237]     Train net output #0: loss = 2.58521 (* 1 = 2.58521 loss)
I0509 21:53:56.820993 19026 sgd_solver.cpp:105] Iteration 1824, lr = 0.00732982
I0509 21:54:01.340114 19026 solver.cpp:330] Iteration 1836, Testing net (#0)
I0509 21:54:01.340134 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:54:07.896404 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:54:08.171790 19026 solver.cpp:397]     Test net output #0: accuracy = 0.28125
I0509 21:54:08.171828 19026 solver.cpp:397]     Test net output #1: loss = 3.03803 (* 1 = 3.03803 loss)
I0509 21:54:08.268819 19026 solver.cpp:218] Iteration 1836 (1.04823 iter/s, 11.4479s/12 iters), loss = 2.50164
I0509 21:54:08.268872 19026 solver.cpp:237]     Train net output #0: loss = 2.50164 (* 1 = 2.50164 loss)
I0509 21:54:08.268882 19026 sgd_solver.cpp:105] Iteration 1836, lr = 0.00731059
I0509 21:54:12.433538 19026 solver.cpp:218] Iteration 1848 (2.88138 iter/s, 4.16467s/12 iters), loss = 2.74766
I0509 21:54:12.433583 19026 solver.cpp:237]     Train net output #0: loss = 2.74766 (* 1 = 2.74766 loss)
I0509 21:54:12.433593 19026 sgd_solver.cpp:105] Iteration 1848, lr = 0.00729127
I0509 21:54:17.388304 19026 solver.cpp:218] Iteration 1860 (2.42193 iter/s, 4.95473s/12 iters), loss = 2.47499
I0509 21:54:17.388340 19026 solver.cpp:237]     Train net output #0: loss = 2.47499 (* 1 = 2.47499 loss)
I0509 21:54:17.388348 19026 sgd_solver.cpp:105] Iteration 1860, lr = 0.00727186
I0509 21:54:22.347100 19026 solver.cpp:218] Iteration 1872 (2.41996 iter/s, 4.95877s/12 iters), loss = 2.21117
I0509 21:54:22.347213 19026 solver.cpp:237]     Train net output #0: loss = 2.21117 (* 1 = 2.21117 loss)
I0509 21:54:22.347223 19026 sgd_solver.cpp:105] Iteration 1872, lr = 0.00725237
I0509 21:54:27.330996 19026 solver.cpp:218] Iteration 1884 (2.40781 iter/s, 4.98379s/12 iters), loss = 2.49081
I0509 21:54:27.331043 19026 solver.cpp:237]     Train net output #0: loss = 2.49081 (* 1 = 2.49081 loss)
I0509 21:54:27.331051 19026 sgd_solver.cpp:105] Iteration 1884, lr = 0.00723279
I0509 21:54:32.330509 19026 solver.cpp:218] Iteration 1896 (2.40025 iter/s, 4.99947s/12 iters), loss = 2.80276
I0509 21:54:32.330551 19026 solver.cpp:237]     Train net output #0: loss = 2.80276 (* 1 = 2.80276 loss)
I0509 21:54:32.330559 19026 sgd_solver.cpp:105] Iteration 1896, lr = 0.00721312
I0509 21:54:37.292871 19026 solver.cpp:218] Iteration 1908 (2.41822 iter/s, 4.96232s/12 iters), loss = 2.45156
I0509 21:54:37.292917 19026 solver.cpp:237]     Train net output #0: loss = 2.45156 (* 1 = 2.45156 loss)
I0509 21:54:37.292927 19026 sgd_solver.cpp:105] Iteration 1908, lr = 0.00719337
I0509 21:54:42.270898 19026 solver.cpp:218] Iteration 1920 (2.41061 iter/s, 4.97798s/12 iters), loss = 2.33431
I0509 21:54:42.270941 19026 solver.cpp:237]     Train net output #0: loss = 2.33431 (* 1 = 2.33431 loss)
I0509 21:54:42.270948 19026 sgd_solver.cpp:105] Iteration 1920, lr = 0.00717354
I0509 21:54:42.575377 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:54:47.260066 19026 solver.cpp:218] Iteration 1932 (2.40523 iter/s, 4.98913s/12 iters), loss = 2.44839
I0509 21:54:47.260105 19026 solver.cpp:237]     Train net output #0: loss = 2.44839 (* 1 = 2.44839 loss)
I0509 21:54:47.260113 19026 sgd_solver.cpp:105] Iteration 1932, lr = 0.00715362
I0509 21:54:49.269230 19026 solver.cpp:330] Iteration 1938, Testing net (#0)
I0509 21:54:49.269248 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:54:55.861244 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:54:56.162156 19026 solver.cpp:397]     Test net output #0: accuracy = 0.278783
I0509 21:54:56.162202 19026 solver.cpp:397]     Test net output #1: loss = 3.01596 (* 1 = 3.01596 loss)
I0509 21:54:57.982434 19026 solver.cpp:218] Iteration 1944 (1.11916 iter/s, 10.7224s/12 iters), loss = 2.42328
I0509 21:54:57.982476 19026 solver.cpp:237]     Train net output #0: loss = 2.42328 (* 1 = 2.42328 loss)
I0509 21:54:57.982486 19026 sgd_solver.cpp:105] Iteration 1944, lr = 0.00713361
I0509 21:55:02.965449 19026 solver.cpp:218] Iteration 1956 (2.4082 iter/s, 4.98298s/12 iters), loss = 2.6479
I0509 21:55:02.965489 19026 solver.cpp:237]     Train net output #0: loss = 2.6479 (* 1 = 2.6479 loss)
I0509 21:55:02.965497 19026 sgd_solver.cpp:105] Iteration 1956, lr = 0.00711352
I0509 21:55:07.950703 19026 solver.cpp:218] Iteration 1968 (2.40711 iter/s, 4.98522s/12 iters), loss = 2.29835
I0509 21:55:07.950742 19026 solver.cpp:237]     Train net output #0: loss = 2.29835 (* 1 = 2.29835 loss)
I0509 21:55:07.950750 19026 sgd_solver.cpp:105] Iteration 1968, lr = 0.00709335
I0509 21:55:12.973518 19026 solver.cpp:218] Iteration 1980 (2.38911 iter/s, 5.02278s/12 iters), loss = 2.25282
I0509 21:55:12.973558 19026 solver.cpp:237]     Train net output #0: loss = 2.25282 (* 1 = 2.25282 loss)
I0509 21:55:12.973567 19026 sgd_solver.cpp:105] Iteration 1980, lr = 0.0070731
I0509 21:55:17.924643 19026 solver.cpp:218] Iteration 1992 (2.42371 iter/s, 4.95109s/12 iters), loss = 2.24684
I0509 21:55:17.924690 19026 solver.cpp:237]     Train net output #0: loss = 2.24684 (* 1 = 2.24684 loss)
I0509 21:55:17.924700 19026 sgd_solver.cpp:105] Iteration 1992, lr = 0.00705276
I0509 21:55:22.908473 19026 solver.cpp:218] Iteration 2004 (2.4078 iter/s, 4.98379s/12 iters), loss = 2.06912
I0509 21:55:22.908516 19026 solver.cpp:237]     Train net output #0: loss = 2.06912 (* 1 = 2.06912 loss)
I0509 21:55:22.908524 19026 sgd_solver.cpp:105] Iteration 2004, lr = 0.00703234
I0509 21:55:27.905824 19026 solver.cpp:218] Iteration 2016 (2.40129 iter/s, 4.99732s/12 iters), loss = 2.07924
I0509 21:55:27.905947 19026 solver.cpp:237]     Train net output #0: loss = 2.07924 (* 1 = 2.07924 loss)
I0509 21:55:27.905956 19026 sgd_solver.cpp:105] Iteration 2016, lr = 0.00701184
I0509 21:55:30.425712 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:55:32.911495 19026 solver.cpp:218] Iteration 2028 (2.39734 iter/s, 5.00556s/12 iters), loss = 2.09212
I0509 21:55:32.911536 19026 solver.cpp:237]     Train net output #0: loss = 2.09212 (* 1 = 2.09212 loss)
I0509 21:55:32.911545 19026 sgd_solver.cpp:105] Iteration 2028, lr = 0.00699126
I0509 21:55:37.433938 19026 solver.cpp:330] Iteration 2040, Testing net (#0)
I0509 21:55:37.433959 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:55:44.018882 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:55:44.330451 19026 solver.cpp:397]     Test net output #0: accuracy = 0.304688
I0509 21:55:44.330497 19026 solver.cpp:397]     Test net output #1: loss = 2.9491 (* 1 = 2.9491 loss)
I0509 21:55:44.427297 19026 solver.cpp:218] Iteration 2040 (1.04205 iter/s, 11.5158s/12 iters), loss = 1.99819
I0509 21:55:44.427340 19026 solver.cpp:237]     Train net output #0: loss = 1.99819 (* 1 = 1.99819 loss)
I0509 21:55:44.427347 19026 sgd_solver.cpp:105] Iteration 2040, lr = 0.00697059
I0509 21:55:48.796555 19026 solver.cpp:218] Iteration 2052 (2.74649 iter/s, 4.36922s/12 iters), loss = 1.91652
I0509 21:55:48.796600 19026 solver.cpp:237]     Train net output #0: loss = 1.91652 (* 1 = 1.91652 loss)
I0509 21:55:48.796608 19026 sgd_solver.cpp:105] Iteration 2052, lr = 0.00694985
I0509 21:55:53.753731 19026 solver.cpp:218] Iteration 2064 (2.42075 iter/s, 4.95713s/12 iters), loss = 2.29924
I0509 21:55:53.753774 19026 solver.cpp:237]     Train net output #0: loss = 2.29924 (* 1 = 2.29924 loss)
I0509 21:55:53.753782 19026 sgd_solver.cpp:105] Iteration 2064, lr = 0.00692903
I0509 21:55:58.697162 19026 solver.cpp:218] Iteration 2076 (2.42749 iter/s, 4.94338s/12 iters), loss = 2.41321
I0509 21:55:58.697325 19026 solver.cpp:237]     Train net output #0: loss = 2.41321 (* 1 = 2.41321 loss)
I0509 21:55:58.697342 19026 sgd_solver.cpp:105] Iteration 2076, lr = 0.00690813
I0509 21:56:03.726784 19026 solver.cpp:218] Iteration 2088 (2.38593 iter/s, 5.02948s/12 iters), loss = 2.19439
I0509 21:56:03.726822 19026 solver.cpp:237]     Train net output #0: loss = 2.19439 (* 1 = 2.19439 loss)
I0509 21:56:03.726830 19026 sgd_solver.cpp:105] Iteration 2088, lr = 0.00688715
I0509 21:56:08.938763 19026 solver.cpp:218] Iteration 2100 (2.3024 iter/s, 5.21195s/12 iters), loss = 2.13971
I0509 21:56:08.938807 19026 solver.cpp:237]     Train net output #0: loss = 2.13971 (* 1 = 2.13971 loss)
I0509 21:56:08.938817 19026 sgd_solver.cpp:105] Iteration 2100, lr = 0.00686609
I0509 21:56:13.970470 19026 solver.cpp:218] Iteration 2112 (2.38489 iter/s, 5.03167s/12 iters), loss = 1.90917
I0509 21:56:13.970508 19026 solver.cpp:237]     Train net output #0: loss = 1.90917 (* 1 = 1.90917 loss)
I0509 21:56:13.970517 19026 sgd_solver.cpp:105] Iteration 2112, lr = 0.00684496
I0509 21:56:18.613327 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:56:18.935621 19026 solver.cpp:218] Iteration 2124 (2.41686 iter/s, 4.96512s/12 iters), loss = 1.82963
I0509 21:56:18.935662 19026 solver.cpp:237]     Train net output #0: loss = 1.82963 (* 1 = 1.82963 loss)
I0509 21:56:18.935669 19026 sgd_solver.cpp:105] Iteration 2124, lr = 0.00682375
I0509 21:56:23.926240 19026 solver.cpp:218] Iteration 2136 (2.40453 iter/s, 4.99058s/12 iters), loss = 2.08809
I0509 21:56:23.926278 19026 solver.cpp:237]     Train net output #0: loss = 2.08809 (* 1 = 2.08809 loss)
I0509 21:56:23.926285 19026 sgd_solver.cpp:105] Iteration 2136, lr = 0.00680246
I0509 21:56:25.949932 19026 solver.cpp:330] Iteration 2142, Testing net (#0)
I0509 21:56:25.949952 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:56:32.424321 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:56:32.749390 19026 solver.cpp:397]     Test net output #0: accuracy = 0.324424
I0509 21:56:32.749425 19026 solver.cpp:397]     Test net output #1: loss = 2.86953 (* 1 = 2.86953 loss)
I0509 21:56:34.586449 19026 solver.cpp:218] Iteration 2148 (1.12568 iter/s, 10.6602s/12 iters), loss = 1.88246
I0509 21:56:34.586489 19026 solver.cpp:237]     Train net output #0: loss = 1.88246 (* 1 = 1.88246 loss)
I0509 21:56:34.586498 19026 sgd_solver.cpp:105] Iteration 2148, lr = 0.0067811
I0509 21:56:39.508067 19026 solver.cpp:218] Iteration 2160 (2.43824 iter/s, 4.92158s/12 iters), loss = 2.10228
I0509 21:56:39.508108 19026 solver.cpp:237]     Train net output #0: loss = 2.10228 (* 1 = 2.10228 loss)
I0509 21:56:39.508116 19026 sgd_solver.cpp:105] Iteration 2160, lr = 0.00675966
I0509 21:56:44.469727 19026 solver.cpp:218] Iteration 2172 (2.41856 iter/s, 4.96163s/12 iters), loss = 2.32381
I0509 21:56:44.469770 19026 solver.cpp:237]     Train net output #0: loss = 2.32381 (* 1 = 2.32381 loss)
I0509 21:56:44.469777 19026 sgd_solver.cpp:105] Iteration 2172, lr = 0.00673815
I0509 21:56:49.462596 19026 solver.cpp:218] Iteration 2184 (2.40344 iter/s, 4.99283s/12 iters), loss = 2.41089
I0509 21:56:49.462632 19026 solver.cpp:237]     Train net output #0: loss = 2.41089 (* 1 = 2.41089 loss)
I0509 21:56:49.462641 19026 sgd_solver.cpp:105] Iteration 2184, lr = 0.00671656
I0509 21:56:54.428354 19026 solver.cpp:218] Iteration 2196 (2.41656 iter/s, 4.96573s/12 iters), loss = 1.78601
I0509 21:56:54.428392 19026 solver.cpp:237]     Train net output #0: loss = 1.78601 (* 1 = 1.78601 loss)
I0509 21:56:54.428400 19026 sgd_solver.cpp:105] Iteration 2196, lr = 0.00669491
I0509 21:56:59.387091 19026 solver.cpp:218] Iteration 2208 (2.41999 iter/s, 4.9587s/12 iters), loss = 1.70419
I0509 21:56:59.387132 19026 solver.cpp:237]     Train net output #0: loss = 1.70419 (* 1 = 1.70419 loss)
I0509 21:56:59.387140 19026 sgd_solver.cpp:105] Iteration 2208, lr = 0.00667318
I0509 21:57:04.386417 19026 solver.cpp:218] Iteration 2220 (2.40034 iter/s, 4.99929s/12 iters), loss = 2.34242
I0509 21:57:04.386577 19026 solver.cpp:237]     Train net output #0: loss = 2.34242 (* 1 = 2.34242 loss)
I0509 21:57:04.386586 19026 sgd_solver.cpp:105] Iteration 2220, lr = 0.00665138
I0509 21:57:06.173218 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:57:09.373364 19026 solver.cpp:218] Iteration 2232 (2.40635 iter/s, 4.9868s/12 iters), loss = 1.86794
I0509 21:57:09.373405 19026 solver.cpp:237]     Train net output #0: loss = 1.86794 (* 1 = 1.86794 loss)
I0509 21:57:09.373412 19026 sgd_solver.cpp:105] Iteration 2232, lr = 0.00662951
I0509 21:57:13.879694 19026 solver.cpp:330] Iteration 2244, Testing net (#0)
I0509 21:57:13.879714 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:57:20.508282 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:57:20.847121 19026 solver.cpp:397]     Test net output #0: accuracy = 0.34375
I0509 21:57:20.847169 19026 solver.cpp:397]     Test net output #1: loss = 2.77076 (* 1 = 2.77076 loss)
I0509 21:57:20.944465 19026 solver.cpp:218] Iteration 2244 (1.03707 iter/s, 11.5711s/12 iters), loss = 1.66794
I0509 21:57:20.944521 19026 solver.cpp:237]     Train net output #0: loss = 1.66794 (* 1 = 1.66794 loss)
I0509 21:57:20.944531 19026 sgd_solver.cpp:105] Iteration 2244, lr = 0.00660756
I0509 21:57:25.110348 19026 solver.cpp:218] Iteration 2256 (2.88058 iter/s, 4.16583s/12 iters), loss = 1.78361
I0509 21:57:25.110385 19026 solver.cpp:237]     Train net output #0: loss = 1.78361 (* 1 = 1.78361 loss)
I0509 21:57:25.110394 19026 sgd_solver.cpp:105] Iteration 2256, lr = 0.00658555
I0509 21:57:30.100028 19026 solver.cpp:218] Iteration 2268 (2.40498 iter/s, 4.98965s/12 iters), loss = 1.87458
I0509 21:57:30.100069 19026 solver.cpp:237]     Train net output #0: loss = 1.87458 (* 1 = 1.87458 loss)
I0509 21:57:30.100077 19026 sgd_solver.cpp:105] Iteration 2268, lr = 0.00656347
I0509 21:57:35.120548 19026 solver.cpp:218] Iteration 2280 (2.39021 iter/s, 5.02049s/12 iters), loss = 1.5878
I0509 21:57:35.120635 19026 solver.cpp:237]     Train net output #0: loss = 1.5878 (* 1 = 1.5878 loss)
I0509 21:57:35.120645 19026 sgd_solver.cpp:105] Iteration 2280, lr = 0.00654133
I0509 21:57:40.024567 19026 solver.cpp:218] Iteration 2292 (2.44702 iter/s, 4.90393s/12 iters), loss = 1.81039
I0509 21:57:40.024606 19026 solver.cpp:237]     Train net output #0: loss = 1.81039 (* 1 = 1.81039 loss)
I0509 21:57:40.024614 19026 sgd_solver.cpp:105] Iteration 2292, lr = 0.00651911
I0509 21:57:45.113550 19026 solver.cpp:218] Iteration 2304 (2.35805 iter/s, 5.08895s/12 iters), loss = 1.80388
I0509 21:57:45.113588 19026 solver.cpp:237]     Train net output #0: loss = 1.80388 (* 1 = 1.80388 loss)
I0509 21:57:45.113597 19026 sgd_solver.cpp:105] Iteration 2304, lr = 0.00649683
I0509 21:57:50.159453 19026 solver.cpp:218] Iteration 2316 (2.37818 iter/s, 5.04587s/12 iters), loss = 1.72158
I0509 21:57:50.159497 19026 solver.cpp:237]     Train net output #0: loss = 1.72158 (* 1 = 1.72158 loss)
I0509 21:57:50.159505 19026 sgd_solver.cpp:105] Iteration 2316, lr = 0.00647449
I0509 21:57:54.127959 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:57:55.191591 19026 solver.cpp:218] Iteration 2328 (2.38469 iter/s, 5.0321s/12 iters), loss = 1.52656
I0509 21:57:55.191632 19026 solver.cpp:237]     Train net output #0: loss = 1.52656 (* 1 = 1.52656 loss)
I0509 21:57:55.191639 19026 sgd_solver.cpp:105] Iteration 2328, lr = 0.00645208
I0509 21:58:00.232074 19026 solver.cpp:218] Iteration 2340 (2.38074 iter/s, 5.04045s/12 iters), loss = 1.55824
I0509 21:58:00.232115 19026 solver.cpp:237]     Train net output #0: loss = 1.55824 (* 1 = 1.55824 loss)
I0509 21:58:00.232122 19026 sgd_solver.cpp:105] Iteration 2340, lr = 0.0064296
I0509 21:58:02.300704 19026 solver.cpp:330] Iteration 2346, Testing net (#0)
I0509 21:58:02.300735 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:58:06.772998 19026 blocking_queue.cpp:49] Waiting for data
I0509 21:58:08.932579 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:58:09.287986 19026 solver.cpp:397]     Test net output #0: accuracy = 0.349095
I0509 21:58:09.288033 19026 solver.cpp:397]     Test net output #1: loss = 2.80071 (* 1 = 2.80071 loss)
I0509 21:58:11.153210 19026 solver.cpp:218] Iteration 2352 (1.09879 iter/s, 10.9211s/12 iters), loss = 1.57336
I0509 21:58:11.153252 19026 solver.cpp:237]     Train net output #0: loss = 1.57336 (* 1 = 1.57336 loss)
I0509 21:58:11.153260 19026 sgd_solver.cpp:105] Iteration 2352, lr = 0.00640706
I0509 21:58:16.092537 19026 solver.cpp:218] Iteration 2364 (2.4295 iter/s, 4.93929s/12 iters), loss = 1.56478
I0509 21:58:16.092579 19026 solver.cpp:237]     Train net output #0: loss = 1.56478 (* 1 = 1.56478 loss)
I0509 21:58:16.092587 19026 sgd_solver.cpp:105] Iteration 2364, lr = 0.00638446
I0509 21:58:21.110002 19026 solver.cpp:218] Iteration 2376 (2.39166 iter/s, 5.01743s/12 iters), loss = 1.44034
I0509 21:58:21.110041 19026 solver.cpp:237]     Train net output #0: loss = 1.44034 (* 1 = 1.44034 loss)
I0509 21:58:21.110049 19026 sgd_solver.cpp:105] Iteration 2376, lr = 0.0063618
I0509 21:58:26.120931 19026 solver.cpp:218] Iteration 2388 (2.39478 iter/s, 5.01089s/12 iters), loss = 1.64596
I0509 21:58:26.120987 19026 solver.cpp:237]     Train net output #0: loss = 1.64596 (* 1 = 1.64596 loss)
I0509 21:58:26.120999 19026 sgd_solver.cpp:105] Iteration 2388, lr = 0.00633908
I0509 21:58:31.168567 19026 solver.cpp:218] Iteration 2400 (2.37737 iter/s, 5.04759s/12 iters), loss = 1.61115
I0509 21:58:31.168610 19026 solver.cpp:237]     Train net output #0: loss = 1.61115 (* 1 = 1.61115 loss)
I0509 21:58:31.168619 19026 sgd_solver.cpp:105] Iteration 2400, lr = 0.0063163
I0509 21:58:36.183168 19026 solver.cpp:218] Iteration 2412 (2.39303 iter/s, 5.01457s/12 iters), loss = 1.7043
I0509 21:58:36.183213 19026 solver.cpp:237]     Train net output #0: loss = 1.7043 (* 1 = 1.7043 loss)
I0509 21:58:36.183223 19026 sgd_solver.cpp:105] Iteration 2412, lr = 0.00629346
I0509 21:58:41.190733 19026 solver.cpp:218] Iteration 2424 (2.39639 iter/s, 5.00753s/12 iters), loss = 1.24334
I0509 21:58:41.190825 19026 solver.cpp:237]     Train net output #0: loss = 1.24334 (* 1 = 1.24334 loss)
I0509 21:58:41.190834 19026 sgd_solver.cpp:105] Iteration 2424, lr = 0.00627056
I0509 21:58:42.260794 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:58:46.219453 19026 solver.cpp:218] Iteration 2436 (2.38634 iter/s, 5.02863s/12 iters), loss = 1.57898
I0509 21:58:46.219512 19026 solver.cpp:237]     Train net output #0: loss = 1.57898 (* 1 = 1.57898 loss)
I0509 21:58:46.219527 19026 sgd_solver.cpp:105] Iteration 2436, lr = 0.00624761
I0509 21:58:50.725541 19026 solver.cpp:330] Iteration 2448, Testing net (#0)
I0509 21:58:50.725562 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:58:57.807188 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:58:58.199635 19026 solver.cpp:397]     Test net output #0: accuracy = 0.363487
I0509 21:58:58.199681 19026 solver.cpp:397]     Test net output #1: loss = 2.75618 (* 1 = 2.75618 loss)
I0509 21:58:58.296550 19026 solver.cpp:218] Iteration 2448 (0.993618 iter/s, 12.0771s/12 iters), loss = 1.78106
I0509 21:58:58.296617 19026 solver.cpp:237]     Train net output #0: loss = 1.78106 (* 1 = 1.78106 loss)
I0509 21:58:58.296629 19026 sgd_solver.cpp:105] Iteration 2448, lr = 0.00622459
I0509 21:59:02.420459 19026 solver.cpp:218] Iteration 2460 (2.9099 iter/s, 4.12385s/12 iters), loss = 1.5401
I0509 21:59:02.420503 19026 solver.cpp:237]     Train net output #0: loss = 1.5401 (* 1 = 1.5401 loss)
I0509 21:59:02.420511 19026 sgd_solver.cpp:105] Iteration 2460, lr = 0.00620153
I0509 21:59:07.463276 19026 solver.cpp:218] Iteration 2472 (2.37964 iter/s, 5.04278s/12 iters), loss = 1.39656
I0509 21:59:07.463315 19026 solver.cpp:237]     Train net output #0: loss = 1.39656 (* 1 = 1.39656 loss)
I0509 21:59:07.463322 19026 sgd_solver.cpp:105] Iteration 2472, lr = 0.0061784
I0509 21:59:12.461822 19026 solver.cpp:218] Iteration 2484 (2.40071 iter/s, 4.99852s/12 iters), loss = 1.50681
I0509 21:59:12.461961 19026 solver.cpp:237]     Train net output #0: loss = 1.50681 (* 1 = 1.50681 loss)
I0509 21:59:12.461971 19026 sgd_solver.cpp:105] Iteration 2484, lr = 0.00615523
I0509 21:59:17.447281 19026 solver.cpp:218] Iteration 2496 (2.40706 iter/s, 4.98533s/12 iters), loss = 1.41334
I0509 21:59:17.447319 19026 solver.cpp:237]     Train net output #0: loss = 1.41334 (* 1 = 1.41334 loss)
I0509 21:59:17.447327 19026 sgd_solver.cpp:105] Iteration 2496, lr = 0.006132
I0509 21:59:22.443668 19026 solver.cpp:218] Iteration 2508 (2.40175 iter/s, 4.99636s/12 iters), loss = 1.56251
I0509 21:59:22.443714 19026 solver.cpp:237]     Train net output #0: loss = 1.56251 (* 1 = 1.56251 loss)
I0509 21:59:22.443722 19026 sgd_solver.cpp:105] Iteration 2508, lr = 0.00610872
I0509 21:59:27.451014 19026 solver.cpp:218] Iteration 2520 (2.3965 iter/s, 5.00731s/12 iters), loss = 1.52443
I0509 21:59:27.451054 19026 solver.cpp:237]     Train net output #0: loss = 1.52443 (* 1 = 1.52443 loss)
I0509 21:59:27.451062 19026 sgd_solver.cpp:105] Iteration 2520, lr = 0.00608539
I0509 21:59:30.636010 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:59:32.537294 19026 solver.cpp:218] Iteration 2532 (2.3593 iter/s, 5.08625s/12 iters), loss = 1.29812
I0509 21:59:32.537334 19026 solver.cpp:237]     Train net output #0: loss = 1.29812 (* 1 = 1.29812 loss)
I0509 21:59:32.537343 19026 sgd_solver.cpp:105] Iteration 2532, lr = 0.00606201
I0509 21:59:37.590986 19026 solver.cpp:218] Iteration 2544 (2.37452 iter/s, 5.05366s/12 iters), loss = 1.31642
I0509 21:59:37.591027 19026 solver.cpp:237]     Train net output #0: loss = 1.31642 (* 1 = 1.31642 loss)
I0509 21:59:37.591034 19026 sgd_solver.cpp:105] Iteration 2544, lr = 0.00603859
I0509 21:59:39.600615 19026 solver.cpp:330] Iteration 2550, Testing net (#0)
I0509 21:59:39.600632 19026 net.cpp:676] Ignoring source layer train-data
I0509 21:59:46.090224 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 21:59:46.482590 19026 solver.cpp:397]     Test net output #0: accuracy = 0.359375
I0509 21:59:46.482631 19026 solver.cpp:397]     Test net output #1: loss = 2.84331 (* 1 = 2.84331 loss)
I0509 21:59:48.294170 19026 solver.cpp:218] Iteration 2556 (1.12116 iter/s, 10.7032s/12 iters), loss = 1.6946
I0509 21:59:48.294209 19026 solver.cpp:237]     Train net output #0: loss = 1.6946 (* 1 = 1.6946 loss)
I0509 21:59:48.294216 19026 sgd_solver.cpp:105] Iteration 2556, lr = 0.00601511
I0509 21:59:53.276193 19026 solver.cpp:218] Iteration 2568 (2.40868 iter/s, 4.98199s/12 iters), loss = 1.08573
I0509 21:59:53.276233 19026 solver.cpp:237]     Train net output #0: loss = 1.08573 (* 1 = 1.08573 loss)
I0509 21:59:53.276242 19026 sgd_solver.cpp:105] Iteration 2568, lr = 0.00599159
I0509 21:59:58.360184 19026 solver.cpp:218] Iteration 2580 (2.36037 iter/s, 5.08396s/12 iters), loss = 1.25891
I0509 21:59:58.360221 19026 solver.cpp:237]     Train net output #0: loss = 1.25891 (* 1 = 1.25891 loss)
I0509 21:59:58.360229 19026 sgd_solver.cpp:105] Iteration 2580, lr = 0.00596802
I0509 22:00:03.516480 19026 solver.cpp:218] Iteration 2592 (2.32727 iter/s, 5.15626s/12 iters), loss = 1.50062
I0509 22:00:03.516527 19026 solver.cpp:237]     Train net output #0: loss = 1.50062 (* 1 = 1.50062 loss)
I0509 22:00:03.516535 19026 sgd_solver.cpp:105] Iteration 2592, lr = 0.0059444
I0509 22:00:08.477933 19026 solver.cpp:218] Iteration 2604 (2.41866 iter/s, 4.96142s/12 iters), loss = 1.38954
I0509 22:00:08.477972 19026 solver.cpp:237]     Train net output #0: loss = 1.38954 (* 1 = 1.38954 loss)
I0509 22:00:08.477978 19026 sgd_solver.cpp:105] Iteration 2604, lr = 0.00592075
I0509 22:00:13.488004 19026 solver.cpp:218] Iteration 2616 (2.39519 iter/s, 5.01004s/12 iters), loss = 1.35792
I0509 22:00:13.488039 19026 solver.cpp:237]     Train net output #0: loss = 1.35792 (* 1 = 1.35792 loss)
I0509 22:00:13.488047 19026 sgd_solver.cpp:105] Iteration 2616, lr = 0.00589705
I0509 22:00:18.462585 19026 solver.cpp:218] Iteration 2628 (2.41228 iter/s, 4.97455s/12 iters), loss = 1.22387
I0509 22:00:18.462745 19026 solver.cpp:237]     Train net output #0: loss = 1.22387 (* 1 = 1.22387 loss)
I0509 22:00:18.462759 19026 sgd_solver.cpp:105] Iteration 2628, lr = 0.00587331
I0509 22:00:18.894387 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:00:23.466728 19026 solver.cpp:218] Iteration 2640 (2.39808 iter/s, 5.00399s/12 iters), loss = 1.43559
I0509 22:00:23.466771 19026 solver.cpp:237]     Train net output #0: loss = 1.43559 (* 1 = 1.43559 loss)
I0509 22:00:23.466780 19026 sgd_solver.cpp:105] Iteration 2640, lr = 0.00584952
I0509 22:00:27.969924 19026 solver.cpp:330] Iteration 2652, Testing net (#0)
I0509 22:00:27.969944 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:00:34.804044 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:00:35.205194 19026 solver.cpp:397]     Test net output #0: accuracy = 0.363898
I0509 22:00:35.205241 19026 solver.cpp:397]     Test net output #1: loss = 2.75892 (* 1 = 2.75892 loss)
I0509 22:00:35.302037 19026 solver.cpp:218] Iteration 2652 (1.01392 iter/s, 11.8353s/12 iters), loss = 1.26421
I0509 22:00:35.302078 19026 solver.cpp:237]     Train net output #0: loss = 1.26421 (* 1 = 1.26421 loss)
I0509 22:00:35.302085 19026 sgd_solver.cpp:105] Iteration 2652, lr = 0.0058257
I0509 22:00:39.446600 19026 solver.cpp:218] Iteration 2664 (2.89539 iter/s, 4.14453s/12 iters), loss = 1.52615
I0509 22:00:39.446645 19026 solver.cpp:237]     Train net output #0: loss = 1.52615 (* 1 = 1.52615 loss)
I0509 22:00:39.446653 19026 sgd_solver.cpp:105] Iteration 2664, lr = 0.00580184
I0509 22:00:44.435935 19026 solver.cpp:218] Iteration 2676 (2.40515 iter/s, 4.98929s/12 iters), loss = 1.10582
I0509 22:00:44.435976 19026 solver.cpp:237]     Train net output #0: loss = 1.10582 (* 1 = 1.10582 loss)
I0509 22:00:44.435984 19026 sgd_solver.cpp:105] Iteration 2676, lr = 0.00577794
I0509 22:00:49.351117 19026 solver.cpp:218] Iteration 2688 (2.44143 iter/s, 4.91515s/12 iters), loss = 1.32011
I0509 22:00:49.351225 19026 solver.cpp:237]     Train net output #0: loss = 1.32011 (* 1 = 1.32011 loss)
I0509 22:00:49.351234 19026 sgd_solver.cpp:105] Iteration 2688, lr = 0.00575401
I0509 22:00:54.331408 19026 solver.cpp:218] Iteration 2700 (2.40955 iter/s, 4.98019s/12 iters), loss = 1.23619
I0509 22:00:54.331451 19026 solver.cpp:237]     Train net output #0: loss = 1.23619 (* 1 = 1.23619 loss)
I0509 22:00:54.331459 19026 sgd_solver.cpp:105] Iteration 2700, lr = 0.00573004
I0509 22:00:59.316424 19026 solver.cpp:218] Iteration 2712 (2.40723 iter/s, 4.98498s/12 iters), loss = 1.4275
I0509 22:00:59.316463 19026 solver.cpp:237]     Train net output #0: loss = 1.4275 (* 1 = 1.4275 loss)
I0509 22:00:59.316471 19026 sgd_solver.cpp:105] Iteration 2712, lr = 0.00570603
I0509 22:01:04.294093 19026 solver.cpp:218] Iteration 2724 (2.41078 iter/s, 4.97764s/12 iters), loss = 0.974931
I0509 22:01:04.294131 19026 solver.cpp:237]     Train net output #0: loss = 0.974931 (* 1 = 0.974931 loss)
I0509 22:01:04.294139 19026 sgd_solver.cpp:105] Iteration 2724, lr = 0.005682
I0509 22:01:06.829726 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:01:09.230473 19026 solver.cpp:218] Iteration 2736 (2.43095 iter/s, 4.93635s/12 iters), loss = 1.16175
I0509 22:01:09.230512 19026 solver.cpp:237]     Train net output #0: loss = 1.16175 (* 1 = 1.16175 loss)
I0509 22:01:09.230520 19026 sgd_solver.cpp:105] Iteration 2736, lr = 0.00565793
I0509 22:01:14.235940 19026 solver.cpp:218] Iteration 2748 (2.39739 iter/s, 5.00544s/12 iters), loss = 1.05611
I0509 22:01:14.235980 19026 solver.cpp:237]     Train net output #0: loss = 1.05611 (* 1 = 1.05611 loss)
I0509 22:01:14.235988 19026 sgd_solver.cpp:105] Iteration 2748, lr = 0.00563383
I0509 22:01:16.246546 19026 solver.cpp:330] Iteration 2754, Testing net (#0)
I0509 22:01:16.246567 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:01:22.960348 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:01:23.377578 19026 solver.cpp:397]     Test net output #0: accuracy = 0.378701
I0509 22:01:23.377622 19026 solver.cpp:397]     Test net output #1: loss = 2.73825 (* 1 = 2.73825 loss)
I0509 22:01:25.186623 19026 solver.cpp:218] Iteration 2760 (1.09582 iter/s, 10.9507s/12 iters), loss = 1.20104
I0509 22:01:25.186661 19026 solver.cpp:237]     Train net output #0: loss = 1.20104 (* 1 = 1.20104 loss)
I0509 22:01:25.186668 19026 sgd_solver.cpp:105] Iteration 2760, lr = 0.0056097
I0509 22:01:30.176595 19026 solver.cpp:218] Iteration 2772 (2.40484 iter/s, 4.98993s/12 iters), loss = 1.13961
I0509 22:01:30.176640 19026 solver.cpp:237]     Train net output #0: loss = 1.13961 (* 1 = 1.13961 loss)
I0509 22:01:30.176647 19026 sgd_solver.cpp:105] Iteration 2772, lr = 0.00558554
I0509 22:01:35.186688 19026 solver.cpp:218] Iteration 2784 (2.39518 iter/s, 5.01005s/12 iters), loss = 1.15995
I0509 22:01:35.186729 19026 solver.cpp:237]     Train net output #0: loss = 1.15995 (* 1 = 1.15995 loss)
I0509 22:01:35.186738 19026 sgd_solver.cpp:105] Iteration 2784, lr = 0.00556135
I0509 22:01:40.217921 19026 solver.cpp:218] Iteration 2796 (2.38512 iter/s, 5.03119s/12 iters), loss = 1.14101
I0509 22:01:40.217977 19026 solver.cpp:237]     Train net output #0: loss = 1.14101 (* 1 = 1.14101 loss)
I0509 22:01:40.217988 19026 sgd_solver.cpp:105] Iteration 2796, lr = 0.00553714
I0509 22:01:45.233044 19026 solver.cpp:218] Iteration 2808 (2.39279 iter/s, 5.01507s/12 iters), loss = 1.03102
I0509 22:01:45.233100 19026 solver.cpp:237]     Train net output #0: loss = 1.03102 (* 1 = 1.03102 loss)
I0509 22:01:45.233110 19026 sgd_solver.cpp:105] Iteration 2808, lr = 0.0055129
I0509 22:01:50.208665 19026 solver.cpp:218] Iteration 2820 (2.41179 iter/s, 4.97557s/12 iters), loss = 1.0802
I0509 22:01:50.208720 19026 solver.cpp:237]     Train net output #0: loss = 1.0802 (* 1 = 1.0802 loss)
I0509 22:01:50.208732 19026 sgd_solver.cpp:105] Iteration 2820, lr = 0.00548863
I0509 22:01:54.886648 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:01:55.177755 19026 solver.cpp:218] Iteration 2832 (2.41495 iter/s, 4.96904s/12 iters), loss = 0.988173
I0509 22:01:55.177819 19026 solver.cpp:237]     Train net output #0: loss = 0.988173 (* 1 = 0.988173 loss)
I0509 22:01:55.177831 19026 sgd_solver.cpp:105] Iteration 2832, lr = 0.00546434
I0509 22:02:00.153998 19026 solver.cpp:218] Iteration 2844 (2.41149 iter/s, 4.97618s/12 iters), loss = 0.857152
I0509 22:02:00.154054 19026 solver.cpp:237]     Train net output #0: loss = 0.857152 (* 1 = 0.857152 loss)
I0509 22:02:00.154067 19026 sgd_solver.cpp:105] Iteration 2844, lr = 0.00544003
I0509 22:02:04.680349 19026 solver.cpp:330] Iteration 2856, Testing net (#0)
I0509 22:02:04.680375 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:02:11.120107 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:02:11.549151 19026 solver.cpp:397]     Test net output #0: accuracy = 0.374178
I0509 22:02:11.549199 19026 solver.cpp:397]     Test net output #1: loss = 2.73059 (* 1 = 2.73059 loss)
I0509 22:02:11.643666 19026 solver.cpp:218] Iteration 2856 (1.04442 iter/s, 11.4897s/12 iters), loss = 1.03012
I0509 22:02:11.643703 19026 solver.cpp:237]     Train net output #0: loss = 1.03012 (* 1 = 1.03012 loss)
I0509 22:02:11.643712 19026 sgd_solver.cpp:105] Iteration 2856, lr = 0.0054157
I0509 22:02:15.797480 19026 solver.cpp:218] Iteration 2868 (2.88894 iter/s, 4.15378s/12 iters), loss = 0.985939
I0509 22:02:15.797524 19026 solver.cpp:237]     Train net output #0: loss = 0.985939 (* 1 = 0.985939 loss)
I0509 22:02:15.797533 19026 sgd_solver.cpp:105] Iteration 2868, lr = 0.00539135
I0509 22:02:20.770352 19026 solver.cpp:218] Iteration 2880 (2.41311 iter/s, 4.97283s/12 iters), loss = 1.19414
I0509 22:02:20.770397 19026 solver.cpp:237]     Train net output #0: loss = 1.19414 (* 1 = 1.19414 loss)
I0509 22:02:20.770406 19026 sgd_solver.cpp:105] Iteration 2880, lr = 0.00536699
I0509 22:02:25.755609 19026 solver.cpp:218] Iteration 2892 (2.40712 iter/s, 4.98521s/12 iters), loss = 1.29933
I0509 22:02:25.755810 19026 solver.cpp:237]     Train net output #0: loss = 1.29933 (* 1 = 1.29933 loss)
I0509 22:02:25.755825 19026 sgd_solver.cpp:105] Iteration 2892, lr = 0.0053426
I0509 22:02:30.716409 19026 solver.cpp:218] Iteration 2904 (2.41906 iter/s, 4.96061s/12 iters), loss = 0.833886
I0509 22:02:30.716452 19026 solver.cpp:237]     Train net output #0: loss = 0.833886 (* 1 = 0.833886 loss)
I0509 22:02:30.716461 19026 sgd_solver.cpp:105] Iteration 2904, lr = 0.0053182
I0509 22:02:35.630915 19026 solver.cpp:218] Iteration 2916 (2.44177 iter/s, 4.91446s/12 iters), loss = 1.10618
I0509 22:02:35.630967 19026 solver.cpp:237]     Train net output #0: loss = 1.10618 (* 1 = 1.10618 loss)
I0509 22:02:35.630980 19026 sgd_solver.cpp:105] Iteration 2916, lr = 0.00529378
I0509 22:02:40.570899 19026 solver.cpp:218] Iteration 2928 (2.42918 iter/s, 4.93993s/12 iters), loss = 0.970836
I0509 22:02:40.570953 19026 solver.cpp:237]     Train net output #0: loss = 0.970836 (* 1 = 0.970836 loss)
I0509 22:02:40.570967 19026 sgd_solver.cpp:105] Iteration 2928, lr = 0.00526935
I0509 22:02:42.382513 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:02:45.542026 19026 solver.cpp:218] Iteration 2940 (2.41396 iter/s, 4.97108s/12 iters), loss = 0.78549
I0509 22:02:45.542065 19026 solver.cpp:237]     Train net output #0: loss = 0.78549 (* 1 = 0.78549 loss)
I0509 22:02:45.542073 19026 sgd_solver.cpp:105] Iteration 2940, lr = 0.0052449
I0509 22:02:50.507745 19026 solver.cpp:218] Iteration 2952 (2.41659 iter/s, 4.96568s/12 iters), loss = 0.834734
I0509 22:02:50.507805 19026 solver.cpp:237]     Train net output #0: loss = 0.834734 (* 1 = 0.834734 loss)
I0509 22:02:50.507818 19026 sgd_solver.cpp:105] Iteration 2952, lr = 0.00522045
I0509 22:02:52.526731 19026 solver.cpp:330] Iteration 2958, Testing net (#0)
I0509 22:02:52.526751 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:02:53.941431 19026 blocking_queue.cpp:49] Waiting for data
I0509 22:02:58.978016 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:02:59.416843 19026 solver.cpp:397]     Test net output #0: accuracy = 0.390625
I0509 22:02:59.416880 19026 solver.cpp:397]     Test net output #1: loss = 2.74774 (* 1 = 2.74774 loss)
I0509 22:03:01.241446 19026 solver.cpp:218] Iteration 2964 (1.11798 iter/s, 10.7337s/12 iters), loss = 0.923513
I0509 22:03:01.241485 19026 solver.cpp:237]     Train net output #0: loss = 0.923513 (* 1 = 0.923513 loss)
I0509 22:03:01.241492 19026 sgd_solver.cpp:105] Iteration 2964, lr = 0.00519598
I0509 22:03:06.203610 19026 solver.cpp:218] Iteration 2976 (2.41832 iter/s, 4.96213s/12 iters), loss = 1.27006
I0509 22:03:06.203650 19026 solver.cpp:237]     Train net output #0: loss = 1.27006 (* 1 = 1.27006 loss)
I0509 22:03:06.203658 19026 sgd_solver.cpp:105] Iteration 2976, lr = 0.0051715
I0509 22:03:11.202127 19026 solver.cpp:218] Iteration 2988 (2.40073 iter/s, 4.99848s/12 iters), loss = 0.942629
I0509 22:03:11.202181 19026 solver.cpp:237]     Train net output #0: loss = 0.942629 (* 1 = 0.942629 loss)
I0509 22:03:11.202193 19026 sgd_solver.cpp:105] Iteration 2988, lr = 0.00514702
I0509 22:03:16.219424 19026 solver.cpp:218] Iteration 3000 (2.39175 iter/s, 5.01726s/12 iters), loss = 0.819899
I0509 22:03:16.219465 19026 solver.cpp:237]     Train net output #0: loss = 0.819899 (* 1 = 0.819899 loss)
I0509 22:03:16.219472 19026 sgd_solver.cpp:105] Iteration 3000, lr = 0.00512252
I0509 22:03:21.210824 19026 solver.cpp:218] Iteration 3012 (2.40415 iter/s, 4.99136s/12 iters), loss = 0.893276
I0509 22:03:21.210870 19026 solver.cpp:237]     Train net output #0: loss = 0.893276 (* 1 = 0.893276 loss)
I0509 22:03:21.210878 19026 sgd_solver.cpp:105] Iteration 3012, lr = 0.00509803
I0509 22:03:26.160347 19026 solver.cpp:218] Iteration 3024 (2.4245 iter/s, 4.94948s/12 iters), loss = 0.965107
I0509 22:03:26.160387 19026 solver.cpp:237]     Train net output #0: loss = 0.965107 (* 1 = 0.965107 loss)
I0509 22:03:26.160395 19026 sgd_solver.cpp:105] Iteration 3024, lr = 0.00507352
I0509 22:03:30.135540 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:03:31.154145 19026 solver.cpp:218] Iteration 3036 (2.403 iter/s, 4.99376s/12 iters), loss = 0.920544
I0509 22:03:31.154182 19026 solver.cpp:237]     Train net output #0: loss = 0.920544 (* 1 = 0.920544 loss)
I0509 22:03:31.154189 19026 sgd_solver.cpp:105] Iteration 3036, lr = 0.00504902
I0509 22:03:36.137974 19026 solver.cpp:218] Iteration 3048 (2.4078 iter/s, 4.9838s/12 iters), loss = 0.987517
I0509 22:03:36.138021 19026 solver.cpp:237]     Train net output #0: loss = 0.987517 (* 1 = 0.987517 loss)
I0509 22:03:36.138031 19026 sgd_solver.cpp:105] Iteration 3048, lr = 0.00502451
I0509 22:03:40.646405 19026 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_3060.caffemodel
I0509 22:03:43.862761 19026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3060.solverstate
I0509 22:03:46.502687 19026 solver.cpp:330] Iteration 3060, Testing net (#0)
I0509 22:03:46.502708 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:03:53.089097 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:03:53.536443 19026 solver.cpp:397]     Test net output #0: accuracy = 0.39227
I0509 22:03:53.536485 19026 solver.cpp:397]     Test net output #1: loss = 2.7053 (* 1 = 2.7053 loss)
I0509 22:03:53.633294 19026 solver.cpp:218] Iteration 3060 (0.685897 iter/s, 17.4953s/12 iters), loss = 1.09491
I0509 22:03:53.633337 19026 solver.cpp:237]     Train net output #0: loss = 1.09491 (* 1 = 1.09491 loss)
I0509 22:03:53.633345 19026 sgd_solver.cpp:105] Iteration 3060, lr = 0.005
I0509 22:03:57.818693 19026 solver.cpp:218] Iteration 3072 (2.86714 iter/s, 4.18535s/12 iters), loss = 1.00188
I0509 22:03:57.818747 19026 solver.cpp:237]     Train net output #0: loss = 1.00188 (* 1 = 1.00188 loss)
I0509 22:03:57.818761 19026 sgd_solver.cpp:105] Iteration 3072, lr = 0.00497549
I0509 22:04:02.775070 19026 solver.cpp:218] Iteration 3084 (2.42115 iter/s, 4.95633s/12 iters), loss = 0.860573
I0509 22:04:02.775198 19026 solver.cpp:237]     Train net output #0: loss = 0.860573 (* 1 = 0.860573 loss)
I0509 22:04:02.775207 19026 sgd_solver.cpp:105] Iteration 3084, lr = 0.00495098
I0509 22:04:07.823737 19026 solver.cpp:218] Iteration 3096 (2.37692 iter/s, 5.04855s/12 iters), loss = 1.13818
I0509 22:04:07.823777 19026 solver.cpp:237]     Train net output #0: loss = 1.13818 (* 1 = 1.13818 loss)
I0509 22:04:07.823786 19026 sgd_solver.cpp:105] Iteration 3096, lr = 0.00492648
I0509 22:04:12.797258 19026 solver.cpp:218] Iteration 3108 (2.4128 iter/s, 4.97348s/12 iters), loss = 0.830104
I0509 22:04:12.797302 19026 solver.cpp:237]     Train net output #0: loss = 0.830104 (* 1 = 0.830104 loss)
I0509 22:04:12.797309 19026 sgd_solver.cpp:105] Iteration 3108, lr = 0.00490197
I0509 22:04:17.795356 19026 solver.cpp:218] Iteration 3120 (2.40093 iter/s, 4.99806s/12 iters), loss = 0.669808
I0509 22:04:17.795395 19026 solver.cpp:237]     Train net output #0: loss = 0.669808 (* 1 = 0.669808 loss)
I0509 22:04:17.795403 19026 sgd_solver.cpp:105] Iteration 3120, lr = 0.00487748
I0509 22:04:22.771000 19026 solver.cpp:218] Iteration 3132 (2.41177 iter/s, 4.9756s/12 iters), loss = 0.611759
I0509 22:04:22.771047 19026 solver.cpp:237]     Train net output #0: loss = 0.611759 (* 1 = 0.611759 loss)
I0509 22:04:22.771056 19026 sgd_solver.cpp:105] Iteration 3132, lr = 0.00485298
I0509 22:04:23.858711 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:04:27.722136 19026 solver.cpp:218] Iteration 3144 (2.42371 iter/s, 4.95109s/12 iters), loss = 1.13422
I0509 22:04:27.722177 19026 solver.cpp:237]     Train net output #0: loss = 1.13422 (* 1 = 1.13422 loss)
I0509 22:04:27.722185 19026 sgd_solver.cpp:105] Iteration 3144, lr = 0.0048285
I0509 22:04:32.771287 19026 solver.cpp:218] Iteration 3156 (2.37665 iter/s, 5.04912s/12 iters), loss = 0.746317
I0509 22:04:32.771327 19026 solver.cpp:237]     Train net output #0: loss = 0.746317 (* 1 = 0.746317 loss)
I0509 22:04:32.771335 19026 sgd_solver.cpp:105] Iteration 3156, lr = 0.00480402
I0509 22:04:34.870637 19026 solver.cpp:330] Iteration 3162, Testing net (#0)
I0509 22:04:34.870800 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:04:41.385876 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:04:41.862792 19026 solver.cpp:397]     Test net output #0: accuracy = 0.400082
I0509 22:04:41.862833 19026 solver.cpp:397]     Test net output #1: loss = 2.75841 (* 1 = 2.75841 loss)
I0509 22:04:43.761504 19026 solver.cpp:218] Iteration 3168 (1.09188 iter/s, 10.9902s/12 iters), loss = 0.670365
I0509 22:04:43.761548 19026 solver.cpp:237]     Train net output #0: loss = 0.670365 (* 1 = 0.670365 loss)
I0509 22:04:43.761555 19026 sgd_solver.cpp:105] Iteration 3168, lr = 0.00477955
I0509 22:04:48.745036 19026 solver.cpp:218] Iteration 3180 (2.40795 iter/s, 4.98349s/12 iters), loss = 0.731649
I0509 22:04:48.745080 19026 solver.cpp:237]     Train net output #0: loss = 0.731649 (* 1 = 0.731649 loss)
I0509 22:04:48.745090 19026 sgd_solver.cpp:105] Iteration 3180, lr = 0.0047551
I0509 22:04:53.710840 19026 solver.cpp:218] Iteration 3192 (2.41655 iter/s, 4.96577s/12 iters), loss = 0.695157
I0509 22:04:53.710881 19026 solver.cpp:237]     Train net output #0: loss = 0.695157 (* 1 = 0.695157 loss)
I0509 22:04:53.710891 19026 sgd_solver.cpp:105] Iteration 3192, lr = 0.00473065
I0509 22:04:58.689220 19026 solver.cpp:218] Iteration 3204 (2.41044 iter/s, 4.97834s/12 iters), loss = 0.86771
I0509 22:04:58.689260 19026 solver.cpp:237]     Train net output #0: loss = 0.86771 (* 1 = 0.86771 loss)
I0509 22:04:58.689268 19026 sgd_solver.cpp:105] Iteration 3204, lr = 0.00470622
I0509 22:05:03.676367 19026 solver.cpp:218] Iteration 3216 (2.4062 iter/s, 4.98711s/12 iters), loss = 0.72231
I0509 22:05:03.676406 19026 solver.cpp:237]     Train net output #0: loss = 0.72231 (* 1 = 0.72231 loss)
I0509 22:05:03.676415 19026 sgd_solver.cpp:105] Iteration 3216, lr = 0.0046818
I0509 22:05:08.633332 19026 solver.cpp:218] Iteration 3228 (2.42086 iter/s, 4.95693s/12 iters), loss = 0.687042
I0509 22:05:08.633461 19026 solver.cpp:237]     Train net output #0: loss = 0.687042 (* 1 = 0.687042 loss)
I0509 22:05:08.633471 19026 sgd_solver.cpp:105] Iteration 3228, lr = 0.0046574
I0509 22:05:11.861148 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:05:13.606793 19026 solver.cpp:218] Iteration 3240 (2.41287 iter/s, 4.97334s/12 iters), loss = 0.657304
I0509 22:05:13.606833 19026 solver.cpp:237]     Train net output #0: loss = 0.657304 (* 1 = 0.657304 loss)
I0509 22:05:13.606842 19026 sgd_solver.cpp:105] Iteration 3240, lr = 0.00463301
I0509 22:05:18.559520 19026 solver.cpp:218] Iteration 3252 (2.42292 iter/s, 4.95269s/12 iters), loss = 0.640139
I0509 22:05:18.559561 19026 solver.cpp:237]     Train net output #0: loss = 0.640139 (* 1 = 0.640139 loss)
I0509 22:05:18.559571 19026 sgd_solver.cpp:105] Iteration 3252, lr = 0.00460865
I0509 22:05:23.040448 19026 solver.cpp:330] Iteration 3264, Testing net (#0)
I0509 22:05:23.040468 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:05:29.387516 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:05:29.872071 19026 solver.cpp:397]     Test net output #0: accuracy = 0.407484
I0509 22:05:29.872105 19026 solver.cpp:397]     Test net output #1: loss = 2.72695 (* 1 = 2.72695 loss)
I0509 22:05:29.969112 19026 solver.cpp:218] Iteration 3264 (1.05175 iter/s, 11.4096s/12 iters), loss = 0.754318
I0509 22:05:29.969180 19026 solver.cpp:237]     Train net output #0: loss = 0.754318 (* 1 = 0.754318 loss)
I0509 22:05:29.969197 19026 sgd_solver.cpp:105] Iteration 3264, lr = 0.0045843
I0509 22:05:34.104180 19026 solver.cpp:218] Iteration 3276 (2.90205 iter/s, 4.135s/12 iters), loss = 0.48119
I0509 22:05:34.104220 19026 solver.cpp:237]     Train net output #0: loss = 0.48119 (* 1 = 0.48119 loss)
I0509 22:05:34.104228 19026 sgd_solver.cpp:105] Iteration 3276, lr = 0.00455996
I0509 22:05:39.092975 19026 solver.cpp:218] Iteration 3288 (2.40541 iter/s, 4.98876s/12 iters), loss = 0.457658
I0509 22:05:39.093118 19026 solver.cpp:237]     Train net output #0: loss = 0.457658 (* 1 = 0.457658 loss)
I0509 22:05:39.093127 19026 sgd_solver.cpp:105] Iteration 3288, lr = 0.00453566
I0509 22:05:44.079020 19026 solver.cpp:218] Iteration 3300 (2.40678 iter/s, 4.98591s/12 iters), loss = 0.844179
I0509 22:05:44.079059 19026 solver.cpp:237]     Train net output #0: loss = 0.844179 (* 1 = 0.844179 loss)
I0509 22:05:44.079067 19026 sgd_solver.cpp:105] Iteration 3300, lr = 0.00451137
I0509 22:05:49.050971 19026 solver.cpp:218] Iteration 3312 (2.41356 iter/s, 4.97192s/12 iters), loss = 0.639673
I0509 22:05:49.051014 19026 solver.cpp:237]     Train net output #0: loss = 0.639673 (* 1 = 0.639673 loss)
I0509 22:05:49.051023 19026 sgd_solver.cpp:105] Iteration 3312, lr = 0.0044871
I0509 22:05:54.079936 19026 solver.cpp:218] Iteration 3324 (2.38619 iter/s, 5.02893s/12 iters), loss = 0.595316
I0509 22:05:54.079977 19026 solver.cpp:237]     Train net output #0: loss = 0.595316 (* 1 = 0.595316 loss)
I0509 22:05:54.079986 19026 sgd_solver.cpp:105] Iteration 3324, lr = 0.00446286
I0509 22:05:59.066522 19026 solver.cpp:218] Iteration 3336 (2.40648 iter/s, 4.98655s/12 iters), loss = 0.894444
I0509 22:05:59.066565 19026 solver.cpp:237]     Train net output #0: loss = 0.894444 (* 1 = 0.894444 loss)
I0509 22:05:59.066573 19026 sgd_solver.cpp:105] Iteration 3336, lr = 0.00443865
I0509 22:05:59.528910 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:06:04.064141 19026 solver.cpp:218] Iteration 3348 (2.40116 iter/s, 4.99758s/12 iters), loss = 0.537168
I0509 22:06:04.064179 19026 solver.cpp:237]     Train net output #0: loss = 0.537168 (* 1 = 0.537168 loss)
I0509 22:06:04.064188 19026 sgd_solver.cpp:105] Iteration 3348, lr = 0.00441446
I0509 22:06:09.023779 19026 solver.cpp:218] Iteration 3360 (2.41955 iter/s, 4.9596s/12 iters), loss = 0.789333
I0509 22:06:09.023833 19026 solver.cpp:237]     Train net output #0: loss = 0.789333 (* 1 = 0.789333 loss)
I0509 22:06:09.023844 19026 sgd_solver.cpp:105] Iteration 3360, lr = 0.0043903
I0509 22:06:11.040560 19026 solver.cpp:330] Iteration 3366, Testing net (#0)
I0509 22:06:11.040640 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:06:17.587059 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:06:18.088351 19026 solver.cpp:397]     Test net output #0: accuracy = 0.397204
I0509 22:06:18.088398 19026 solver.cpp:397]     Test net output #1: loss = 2.81737 (* 1 = 2.81737 loss)
I0509 22:06:19.809981 19026 solver.cpp:218] Iteration 3372 (1.11253 iter/s, 10.7862s/12 iters), loss = 0.732604
I0509 22:06:19.810022 19026 solver.cpp:237]     Train net output #0: loss = 0.732604 (* 1 = 0.732604 loss)
I0509 22:06:19.810030 19026 sgd_solver.cpp:105] Iteration 3372, lr = 0.00436617
I0509 22:06:24.805058 19026 solver.cpp:218] Iteration 3384 (2.40239 iter/s, 4.99504s/12 iters), loss = 0.509543
I0509 22:06:24.805101 19026 solver.cpp:237]     Train net output #0: loss = 0.509543 (* 1 = 0.509543 loss)
I0509 22:06:24.805112 19026 sgd_solver.cpp:105] Iteration 3384, lr = 0.00434207
I0509 22:06:29.802994 19026 solver.cpp:218] Iteration 3396 (2.40101 iter/s, 4.9979s/12 iters), loss = 0.625787
I0509 22:06:29.803035 19026 solver.cpp:237]     Train net output #0: loss = 0.625787 (* 1 = 0.625787 loss)
I0509 22:06:29.803042 19026 sgd_solver.cpp:105] Iteration 3396, lr = 0.004318
I0509 22:06:34.763239 19026 solver.cpp:218] Iteration 3408 (2.41925 iter/s, 4.96021s/12 iters), loss = 0.924506
I0509 22:06:34.763279 19026 solver.cpp:237]     Train net output #0: loss = 0.924506 (* 1 = 0.924506 loss)
I0509 22:06:34.763288 19026 sgd_solver.cpp:105] Iteration 3408, lr = 0.00429397
I0509 22:06:39.771436 19026 solver.cpp:218] Iteration 3420 (2.39609 iter/s, 5.00816s/12 iters), loss = 0.676833
I0509 22:06:39.771479 19026 solver.cpp:237]     Train net output #0: loss = 0.676833 (* 1 = 0.676833 loss)
I0509 22:06:39.771488 19026 sgd_solver.cpp:105] Iteration 3420, lr = 0.00426996
I0509 22:06:44.830404 19026 solver.cpp:218] Iteration 3432 (2.37204 iter/s, 5.05893s/12 iters), loss = 0.599727
I0509 22:06:44.830502 19026 solver.cpp:237]     Train net output #0: loss = 0.599727 (* 1 = 0.599727 loss)
I0509 22:06:44.830510 19026 sgd_solver.cpp:105] Iteration 3432, lr = 0.00424599
I0509 22:06:47.429404 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:06:49.820864 19026 solver.cpp:218] Iteration 3444 (2.40463 iter/s, 4.99037s/12 iters), loss = 0.835275
I0509 22:06:49.820912 19026 solver.cpp:237]     Train net output #0: loss = 0.835275 (* 1 = 0.835275 loss)
I0509 22:06:49.820924 19026 sgd_solver.cpp:105] Iteration 3444, lr = 0.00422206
I0509 22:06:54.830279 19026 solver.cpp:218] Iteration 3456 (2.39551 iter/s, 5.00938s/12 iters), loss = 0.471741
I0509 22:06:54.830320 19026 solver.cpp:237]     Train net output #0: loss = 0.471741 (* 1 = 0.471741 loss)
I0509 22:06:54.830328 19026 sgd_solver.cpp:105] Iteration 3456, lr = 0.00419816
I0509 22:06:59.360684 19026 solver.cpp:330] Iteration 3468, Testing net (#0)
I0509 22:06:59.360704 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:07:05.900171 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:07:06.434368 19026 solver.cpp:397]     Test net output #0: accuracy = 0.429276
I0509 22:07:06.434418 19026 solver.cpp:397]     Test net output #1: loss = 2.71388 (* 1 = 2.71388 loss)
I0509 22:07:06.530817 19026 solver.cpp:218] Iteration 3468 (1.02559 iter/s, 11.7005s/12 iters), loss = 0.507651
I0509 22:07:06.530861 19026 solver.cpp:237]     Train net output #0: loss = 0.507651 (* 1 = 0.507651 loss)
I0509 22:07:06.530870 19026 sgd_solver.cpp:105] Iteration 3468, lr = 0.0041743
I0509 22:07:10.680131 19026 solver.cpp:218] Iteration 3480 (2.89207 iter/s, 4.14927s/12 iters), loss = 0.676812
I0509 22:07:10.680174 19026 solver.cpp:237]     Train net output #0: loss = 0.676812 (* 1 = 0.676812 loss)
I0509 22:07:10.680182 19026 sgd_solver.cpp:105] Iteration 3480, lr = 0.00415048
I0509 22:07:15.769239 19026 solver.cpp:218] Iteration 3492 (2.35799 iter/s, 5.08907s/12 iters), loss = 0.478999
I0509 22:07:15.769323 19026 solver.cpp:237]     Train net output #0: loss = 0.478999 (* 1 = 0.478999 loss)
I0509 22:07:15.769332 19026 sgd_solver.cpp:105] Iteration 3492, lr = 0.00412669
I0509 22:07:20.914980 19026 solver.cpp:218] Iteration 3504 (2.33206 iter/s, 5.14566s/12 iters), loss = 0.652703
I0509 22:07:20.915020 19026 solver.cpp:237]     Train net output #0: loss = 0.652703 (* 1 = 0.652703 loss)
I0509 22:07:20.915028 19026 sgd_solver.cpp:105] Iteration 3504, lr = 0.00410295
I0509 22:07:25.918748 19026 solver.cpp:218] Iteration 3516 (2.39821 iter/s, 5.00373s/12 iters), loss = 0.73737
I0509 22:07:25.918788 19026 solver.cpp:237]     Train net output #0: loss = 0.73737 (* 1 = 0.73737 loss)
I0509 22:07:25.918795 19026 sgd_solver.cpp:105] Iteration 3516, lr = 0.00407925
I0509 22:07:30.912772 19026 solver.cpp:218] Iteration 3528 (2.40289 iter/s, 4.99399s/12 iters), loss = 0.568058
I0509 22:07:30.912813 19026 solver.cpp:237]     Train net output #0: loss = 0.568058 (* 1 = 0.568058 loss)
I0509 22:07:30.912822 19026 sgd_solver.cpp:105] Iteration 3528, lr = 0.0040556
I0509 22:07:35.693441 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:07:35.960641 19026 solver.cpp:218] Iteration 3540 (2.37726 iter/s, 5.04783s/12 iters), loss = 0.786977
I0509 22:07:35.960685 19026 solver.cpp:237]     Train net output #0: loss = 0.786977 (* 1 = 0.786977 loss)
I0509 22:07:35.960695 19026 sgd_solver.cpp:105] Iteration 3540, lr = 0.00403198
I0509 22:07:40.495170 19026 blocking_queue.cpp:49] Waiting for data
I0509 22:07:40.958326 19026 solver.cpp:218] Iteration 3552 (2.40113 iter/s, 4.99765s/12 iters), loss = 0.469024
I0509 22:07:40.958364 19026 solver.cpp:237]     Train net output #0: loss = 0.469024 (* 1 = 0.469024 loss)
I0509 22:07:40.958372 19026 sgd_solver.cpp:105] Iteration 3552, lr = 0.00400841
I0509 22:07:45.959303 19026 solver.cpp:218] Iteration 3564 (2.39955 iter/s, 5.00095s/12 iters), loss = 0.427965
I0509 22:07:45.959411 19026 solver.cpp:237]     Train net output #0: loss = 0.427965 (* 1 = 0.427965 loss)
I0509 22:07:45.959420 19026 sgd_solver.cpp:105] Iteration 3564, lr = 0.00398489
I0509 22:07:47.961405 19026 solver.cpp:330] Iteration 3570, Testing net (#0)
I0509 22:07:47.961429 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:07:54.301214 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:07:54.821707 19026 solver.cpp:397]     Test net output #0: accuracy = 0.434211
I0509 22:07:54.821745 19026 solver.cpp:397]     Test net output #1: loss = 2.71141 (* 1 = 2.71141 loss)
I0509 22:07:56.656965 19026 solver.cpp:218] Iteration 3576 (1.12175 iter/s, 10.6976s/12 iters), loss = 0.748577
I0509 22:07:56.657007 19026 solver.cpp:237]     Train net output #0: loss = 0.748577 (* 1 = 0.748577 loss)
I0509 22:07:56.657016 19026 sgd_solver.cpp:105] Iteration 3576, lr = 0.00396141
I0509 22:08:01.634531 19026 solver.cpp:218] Iteration 3588 (2.41083 iter/s, 4.97753s/12 iters), loss = 0.512379
I0509 22:08:01.634570 19026 solver.cpp:237]     Train net output #0: loss = 0.512379 (* 1 = 0.512379 loss)
I0509 22:08:01.634578 19026 sgd_solver.cpp:105] Iteration 3588, lr = 0.00393799
I0509 22:08:06.619307 19026 solver.cpp:218] Iteration 3600 (2.40735 iter/s, 4.98474s/12 iters), loss = 0.595548
I0509 22:08:06.619350 19026 solver.cpp:237]     Train net output #0: loss = 0.595548 (* 1 = 0.595548 loss)
I0509 22:08:06.619359 19026 sgd_solver.cpp:105] Iteration 3600, lr = 0.00391461
I0509 22:08:11.573593 19026 solver.cpp:218] Iteration 3612 (2.42216 iter/s, 4.95425s/12 iters), loss = 0.701158
I0509 22:08:11.573637 19026 solver.cpp:237]     Train net output #0: loss = 0.701158 (* 1 = 0.701158 loss)
I0509 22:08:11.573644 19026 sgd_solver.cpp:105] Iteration 3612, lr = 0.00389128
I0509 22:08:16.513486 19026 solver.cpp:218] Iteration 3624 (2.42922 iter/s, 4.93986s/12 iters), loss = 0.386736
I0509 22:08:16.513576 19026 solver.cpp:237]     Train net output #0: loss = 0.386736 (* 1 = 0.386736 loss)
I0509 22:08:16.513586 19026 sgd_solver.cpp:105] Iteration 3624, lr = 0.003868
I0509 22:08:21.477103 19026 solver.cpp:218] Iteration 3636 (2.41763 iter/s, 4.96353s/12 iters), loss = 0.745584
I0509 22:08:21.477145 19026 solver.cpp:237]     Train net output #0: loss = 0.745584 (* 1 = 0.745584 loss)
I0509 22:08:21.477152 19026 sgd_solver.cpp:105] Iteration 3636, lr = 0.00384477
I0509 22:08:23.348325 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:08:26.466444 19026 solver.cpp:218] Iteration 3648 (2.40515 iter/s, 4.9893s/12 iters), loss = 0.528913
I0509 22:08:26.466481 19026 solver.cpp:237]     Train net output #0: loss = 0.528913 (* 1 = 0.528913 loss)
I0509 22:08:26.466490 19026 sgd_solver.cpp:105] Iteration 3648, lr = 0.0038216
I0509 22:08:31.460891 19026 solver.cpp:218] Iteration 3660 (2.40268 iter/s, 4.99441s/12 iters), loss = 0.567369
I0509 22:08:31.460935 19026 solver.cpp:237]     Train net output #0: loss = 0.567369 (* 1 = 0.567369 loss)
I0509 22:08:31.460943 19026 sgd_solver.cpp:105] Iteration 3660, lr = 0.00379847
I0509 22:08:35.975616 19026 solver.cpp:330] Iteration 3672, Testing net (#0)
I0509 22:08:35.975636 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:08:42.337294 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:08:42.871754 19026 solver.cpp:397]     Test net output #0: accuracy = 0.430099
I0509 22:08:42.871799 19026 solver.cpp:397]     Test net output #1: loss = 2.6901 (* 1 = 2.6901 loss)
I0509 22:08:42.966223 19026 solver.cpp:218] Iteration 3672 (1.043 iter/s, 11.5053s/12 iters), loss = 0.516897
I0509 22:08:42.966269 19026 solver.cpp:237]     Train net output #0: loss = 0.516897 (* 1 = 0.516897 loss)
I0509 22:08:42.966279 19026 sgd_solver.cpp:105] Iteration 3672, lr = 0.00377541
I0509 22:08:47.121798 19026 solver.cpp:218] Iteration 3684 (2.88772 iter/s, 4.15553s/12 iters), loss = 0.452769
I0509 22:08:47.121943 19026 solver.cpp:237]     Train net output #0: loss = 0.452769 (* 1 = 0.452769 loss)
I0509 22:08:47.121953 19026 sgd_solver.cpp:105] Iteration 3684, lr = 0.00375239
I0509 22:08:52.100508 19026 solver.cpp:218] Iteration 3696 (2.41033 iter/s, 4.97857s/12 iters), loss = 0.436601
I0509 22:08:52.100548 19026 solver.cpp:237]     Train net output #0: loss = 0.436601 (* 1 = 0.436601 loss)
I0509 22:08:52.100556 19026 sgd_solver.cpp:105] Iteration 3696, lr = 0.00372944
I0509 22:08:57.063307 19026 solver.cpp:218] Iteration 3708 (2.41801 iter/s, 4.96277s/12 iters), loss = 0.469175
I0509 22:08:57.063347 19026 solver.cpp:237]     Train net output #0: loss = 0.469175 (* 1 = 0.469175 loss)
I0509 22:08:57.063356 19026 sgd_solver.cpp:105] Iteration 3708, lr = 0.00370654
I0509 22:09:02.071575 19026 solver.cpp:218] Iteration 3720 (2.39605 iter/s, 5.00824s/12 iters), loss = 0.406309
I0509 22:09:02.071617 19026 solver.cpp:237]     Train net output #0: loss = 0.406309 (* 1 = 0.406309 loss)
I0509 22:09:02.071625 19026 sgd_solver.cpp:105] Iteration 3720, lr = 0.0036837
I0509 22:09:07.055701 19026 solver.cpp:218] Iteration 3732 (2.40766 iter/s, 4.98409s/12 iters), loss = 0.481517
I0509 22:09:07.055740 19026 solver.cpp:237]     Train net output #0: loss = 0.481517 (* 1 = 0.481517 loss)
I0509 22:09:07.055749 19026 sgd_solver.cpp:105] Iteration 3732, lr = 0.00366092
I0509 22:09:11.038151 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:09:12.060581 19026 solver.cpp:218] Iteration 3744 (2.39767 iter/s, 5.00485s/12 iters), loss = 0.527017
I0509 22:09:12.060622 19026 solver.cpp:237]     Train net output #0: loss = 0.527017 (* 1 = 0.527017 loss)
I0509 22:09:12.060629 19026 sgd_solver.cpp:105] Iteration 3744, lr = 0.0036382
I0509 22:09:17.023090 19026 solver.cpp:218] Iteration 3756 (2.41815 iter/s, 4.96247s/12 iters), loss = 0.315762
I0509 22:09:17.023138 19026 solver.cpp:237]     Train net output #0: loss = 0.315762 (* 1 = 0.315762 loss)
I0509 22:09:17.023146 19026 sgd_solver.cpp:105] Iteration 3756, lr = 0.00361554
I0509 22:09:22.029125 19026 solver.cpp:218] Iteration 3768 (2.39713 iter/s, 5.00599s/12 iters), loss = 0.36823
I0509 22:09:22.029225 19026 solver.cpp:237]     Train net output #0: loss = 0.36823 (* 1 = 0.36823 loss)
I0509 22:09:22.029233 19026 sgd_solver.cpp:105] Iteration 3768, lr = 0.00359294
I0509 22:09:24.030143 19026 solver.cpp:330] Iteration 3774, Testing net (#0)
I0509 22:09:24.030162 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:09:30.633518 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:09:31.180929 19026 solver.cpp:397]     Test net output #0: accuracy = 0.439145
I0509 22:09:31.180977 19026 solver.cpp:397]     Test net output #1: loss = 2.65008 (* 1 = 2.65008 loss)
I0509 22:09:32.978509 19026 solver.cpp:218] Iteration 3780 (1.09596 iter/s, 10.9493s/12 iters), loss = 0.399149
I0509 22:09:32.978550 19026 solver.cpp:237]     Train net output #0: loss = 0.399149 (* 1 = 0.399149 loss)
I0509 22:09:32.978557 19026 sgd_solver.cpp:105] Iteration 3780, lr = 0.0035704
I0509 22:09:37.911947 19026 solver.cpp:218] Iteration 3792 (2.4324 iter/s, 4.9334s/12 iters), loss = 0.304252
I0509 22:09:37.911983 19026 solver.cpp:237]     Train net output #0: loss = 0.304252 (* 1 = 0.304252 loss)
I0509 22:09:37.911991 19026 sgd_solver.cpp:105] Iteration 3792, lr = 0.00354792
I0509 22:09:42.901085 19026 solver.cpp:218] Iteration 3804 (2.40524 iter/s, 4.98911s/12 iters), loss = 0.454233
I0509 22:09:42.901125 19026 solver.cpp:237]     Train net output #0: loss = 0.454233 (* 1 = 0.454233 loss)
I0509 22:09:42.901134 19026 sgd_solver.cpp:105] Iteration 3804, lr = 0.00352551
I0509 22:09:47.895334 19026 solver.cpp:218] Iteration 3816 (2.40278 iter/s, 4.99422s/12 iters), loss = 0.460485
I0509 22:09:47.895366 19026 solver.cpp:237]     Train net output #0: loss = 0.460485 (* 1 = 0.460485 loss)
I0509 22:09:47.895375 19026 sgd_solver.cpp:105] Iteration 3816, lr = 0.00350317
I0509 22:09:52.862699 19026 solver.cpp:218] Iteration 3828 (2.41578 iter/s, 4.96734s/12 iters), loss = 0.50493
I0509 22:09:52.862855 19026 solver.cpp:237]     Train net output #0: loss = 0.50493 (* 1 = 0.50493 loss)
I0509 22:09:52.862865 19026 sgd_solver.cpp:105] Iteration 3828, lr = 0.00348089
I0509 22:09:57.857076 19026 solver.cpp:218] Iteration 3840 (2.40278 iter/s, 4.99422s/12 iters), loss = 0.549971
I0509 22:09:57.857120 19026 solver.cpp:237]     Train net output #0: loss = 0.549971 (* 1 = 0.549971 loss)
I0509 22:09:57.857128 19026 sgd_solver.cpp:105] Iteration 3840, lr = 0.00345867
I0509 22:09:58.980785 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:10:02.845746 19026 solver.cpp:218] Iteration 3852 (2.40547 iter/s, 4.98863s/12 iters), loss = 0.400275
I0509 22:10:02.845788 19026 solver.cpp:237]     Train net output #0: loss = 0.400275 (* 1 = 0.400275 loss)
I0509 22:10:02.845794 19026 sgd_solver.cpp:105] Iteration 3852, lr = 0.00343653
I0509 22:10:07.846483 19026 solver.cpp:218] Iteration 3864 (2.39966 iter/s, 5.0007s/12 iters), loss = 0.387566
I0509 22:10:07.846524 19026 solver.cpp:237]     Train net output #0: loss = 0.387566 (* 1 = 0.387566 loss)
I0509 22:10:07.846532 19026 sgd_solver.cpp:105] Iteration 3864, lr = 0.00341445
I0509 22:10:12.336858 19026 solver.cpp:330] Iteration 3876, Testing net (#0)
I0509 22:10:12.336874 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:10:18.805850 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:10:19.379887 19026 solver.cpp:397]     Test net output #0: accuracy = 0.440378
I0509 22:10:19.379935 19026 solver.cpp:397]     Test net output #1: loss = 2.78689 (* 1 = 2.78689 loss)
I0509 22:10:19.478603 19026 solver.cpp:218] Iteration 3876 (1.03163 iter/s, 11.6321s/12 iters), loss = 0.348602
I0509 22:10:19.478665 19026 solver.cpp:237]     Train net output #0: loss = 0.348602 (* 1 = 0.348602 loss)
I0509 22:10:19.478677 19026 sgd_solver.cpp:105] Iteration 3876, lr = 0.00339244
I0509 22:10:23.608218 19026 solver.cpp:218] Iteration 3888 (2.90588 iter/s, 4.12956s/12 iters), loss = 0.306632
I0509 22:10:23.608319 19026 solver.cpp:237]     Train net output #0: loss = 0.306632 (* 1 = 0.306632 loss)
I0509 22:10:23.608328 19026 sgd_solver.cpp:105] Iteration 3888, lr = 0.00337049
I0509 22:10:28.590624 19026 solver.cpp:218] Iteration 3900 (2.40852 iter/s, 4.98232s/12 iters), loss = 0.551022
I0509 22:10:28.590664 19026 solver.cpp:237]     Train net output #0: loss = 0.551022 (* 1 = 0.551022 loss)
I0509 22:10:28.590672 19026 sgd_solver.cpp:105] Iteration 3900, lr = 0.00334862
I0509 22:10:33.544064 19026 solver.cpp:218] Iteration 3912 (2.42258 iter/s, 4.9534s/12 iters), loss = 0.326436
I0509 22:10:33.544107 19026 solver.cpp:237]     Train net output #0: loss = 0.326436 (* 1 = 0.326436 loss)
I0509 22:10:33.544116 19026 sgd_solver.cpp:105] Iteration 3912, lr = 0.00332682
I0509 22:10:38.543328 19026 solver.cpp:218] Iteration 3924 (2.40038 iter/s, 4.99921s/12 iters), loss = 0.358954
I0509 22:10:38.543385 19026 solver.cpp:237]     Train net output #0: loss = 0.358954 (* 1 = 0.358954 loss)
I0509 22:10:38.543399 19026 sgd_solver.cpp:105] Iteration 3924, lr = 0.00330509
I0509 22:10:43.528977 19026 solver.cpp:218] Iteration 3936 (2.40693 iter/s, 4.9856s/12 iters), loss = 0.306461
I0509 22:10:43.529018 19026 solver.cpp:237]     Train net output #0: loss = 0.306461 (* 1 = 0.306461 loss)
I0509 22:10:43.529026 19026 sgd_solver.cpp:105] Iteration 3936, lr = 0.00328344
I0509 22:10:46.867357 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:10:48.527488 19026 solver.cpp:218] Iteration 3948 (2.40073 iter/s, 4.99847s/12 iters), loss = 0.326558
I0509 22:10:48.527531 19026 solver.cpp:237]     Train net output #0: loss = 0.326558 (* 1 = 0.326558 loss)
I0509 22:10:48.527539 19026 sgd_solver.cpp:105] Iteration 3948, lr = 0.00326185
I0509 22:10:53.505808 19026 solver.cpp:218] Iteration 3960 (2.41047 iter/s, 4.97828s/12 iters), loss = 0.495007
I0509 22:10:53.505851 19026 solver.cpp:237]     Train net output #0: loss = 0.495007 (* 1 = 0.495007 loss)
I0509 22:10:53.505859 19026 sgd_solver.cpp:105] Iteration 3960, lr = 0.00324034
I0509 22:10:58.495723 19026 solver.cpp:218] Iteration 3972 (2.40487 iter/s, 4.98987s/12 iters), loss = 0.535362
I0509 22:10:58.495887 19026 solver.cpp:237]     Train net output #0: loss = 0.535362 (* 1 = 0.535362 loss)
I0509 22:10:58.495896 19026 sgd_solver.cpp:105] Iteration 3972, lr = 0.0032189
I0509 22:11:00.497442 19026 solver.cpp:330] Iteration 3978, Testing net (#0)
I0509 22:11:00.497460 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:11:06.974472 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:11:07.557240 19026 solver.cpp:397]     Test net output #0: accuracy = 0.446957
I0509 22:11:07.557291 19026 solver.cpp:397]     Test net output #1: loss = 2.65441 (* 1 = 2.65441 loss)
I0509 22:11:09.382187 19026 solver.cpp:218] Iteration 3984 (1.1023 iter/s, 10.8863s/12 iters), loss = 0.292687
I0509 22:11:09.382234 19026 solver.cpp:237]     Train net output #0: loss = 0.292687 (* 1 = 0.292687 loss)
I0509 22:11:09.382242 19026 sgd_solver.cpp:105] Iteration 3984, lr = 0.00319754
I0509 22:11:14.379353 19026 solver.cpp:218] Iteration 3996 (2.40138 iter/s, 4.99713s/12 iters), loss = 0.344774
I0509 22:11:14.379390 19026 solver.cpp:237]     Train net output #0: loss = 0.344774 (* 1 = 0.344774 loss)
I0509 22:11:14.379400 19026 sgd_solver.cpp:105] Iteration 3996, lr = 0.00317625
I0509 22:11:19.360939 19026 solver.cpp:218] Iteration 4008 (2.40889 iter/s, 4.98156s/12 iters), loss = 0.437402
I0509 22:11:19.360976 19026 solver.cpp:237]     Train net output #0: loss = 0.437402 (* 1 = 0.437402 loss)
I0509 22:11:19.360983 19026 sgd_solver.cpp:105] Iteration 4008, lr = 0.00315504
I0509 22:11:24.349905 19026 solver.cpp:218] Iteration 4020 (2.40533 iter/s, 4.98893s/12 iters), loss = 0.335952
I0509 22:11:24.349951 19026 solver.cpp:237]     Train net output #0: loss = 0.335952 (* 1 = 0.335952 loss)
I0509 22:11:24.349958 19026 sgd_solver.cpp:105] Iteration 4020, lr = 0.00313391
I0509 22:11:29.319072 19026 solver.cpp:218] Iteration 4032 (2.41491 iter/s, 4.96912s/12 iters), loss = 0.370361
I0509 22:11:29.319185 19026 solver.cpp:237]     Train net output #0: loss = 0.370361 (* 1 = 0.370361 loss)
I0509 22:11:29.319195 19026 sgd_solver.cpp:105] Iteration 4032, lr = 0.00311285
I0509 22:11:34.331132 19026 solver.cpp:218] Iteration 4044 (2.39428 iter/s, 5.01195s/12 iters), loss = 0.335459
I0509 22:11:34.331179 19026 solver.cpp:237]     Train net output #0: loss = 0.335459 (* 1 = 0.335459 loss)
I0509 22:11:34.331187 19026 sgd_solver.cpp:105] Iteration 4044, lr = 0.00309187
I0509 22:11:34.820842 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:11:39.327991 19026 solver.cpp:218] Iteration 4056 (2.40153 iter/s, 4.99682s/12 iters), loss = 0.317146
I0509 22:11:39.328033 19026 solver.cpp:237]     Train net output #0: loss = 0.317146 (* 1 = 0.317146 loss)
I0509 22:11:39.328042 19026 sgd_solver.cpp:105] Iteration 4056, lr = 0.00307097
I0509 22:11:44.307143 19026 solver.cpp:218] Iteration 4068 (2.41007 iter/s, 4.97911s/12 iters), loss = 0.413434
I0509 22:11:44.307184 19026 solver.cpp:237]     Train net output #0: loss = 0.413434 (* 1 = 0.413434 loss)
I0509 22:11:44.307193 19026 sgd_solver.cpp:105] Iteration 4068, lr = 0.00305015
I0509 22:11:48.797142 19026 solver.cpp:330] Iteration 4080, Testing net (#0)
I0509 22:11:48.797163 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:11:55.493333 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:11:56.133069 19026 solver.cpp:397]     Test net output #0: accuracy = 0.448602
I0509 22:11:56.133117 19026 solver.cpp:397]     Test net output #1: loss = 2.70497 (* 1 = 2.70497 loss)
I0509 22:11:56.230751 19026 solver.cpp:218] Iteration 4080 (1.00641 iter/s, 11.9236s/12 iters), loss = 0.368938
I0509 22:11:56.230794 19026 solver.cpp:237]     Train net output #0: loss = 0.368938 (* 1 = 0.368938 loss)
I0509 22:11:56.230803 19026 sgd_solver.cpp:105] Iteration 4080, lr = 0.00302941
I0509 22:12:00.420861 19026 solver.cpp:218] Iteration 4092 (2.86391 iter/s, 4.19007s/12 iters), loss = 0.218394
I0509 22:12:00.421003 19026 solver.cpp:237]     Train net output #0: loss = 0.218394 (* 1 = 0.218394 loss)
I0509 22:12:00.421013 19026 sgd_solver.cpp:105] Iteration 4092, lr = 0.00300874
I0509 22:12:05.468674 19026 solver.cpp:218] Iteration 4104 (2.37733 iter/s, 5.04768s/12 iters), loss = 0.370683
I0509 22:12:05.468716 19026 solver.cpp:237]     Train net output #0: loss = 0.370683 (* 1 = 0.370683 loss)
I0509 22:12:05.468724 19026 sgd_solver.cpp:105] Iteration 4104, lr = 0.00298816
I0509 22:12:10.531563 19026 solver.cpp:218] Iteration 4116 (2.3702 iter/s, 5.06286s/12 iters), loss = 0.294955
I0509 22:12:10.531603 19026 solver.cpp:237]     Train net output #0: loss = 0.294955 (* 1 = 0.294955 loss)
I0509 22:12:10.531611 19026 sgd_solver.cpp:105] Iteration 4116, lr = 0.00296766
I0509 22:12:15.524636 19026 solver.cpp:218] Iteration 4128 (2.40335 iter/s, 4.99304s/12 iters), loss = 0.313914
I0509 22:12:15.524677 19026 solver.cpp:237]     Train net output #0: loss = 0.313914 (* 1 = 0.313914 loss)
I0509 22:12:15.524685 19026 sgd_solver.cpp:105] Iteration 4128, lr = 0.00294724
I0509 22:12:16.713826 19026 blocking_queue.cpp:49] Waiting for data
I0509 22:12:20.521229 19026 solver.cpp:218] Iteration 4140 (2.40165 iter/s, 4.99656s/12 iters), loss = 0.445994
I0509 22:12:20.521275 19026 solver.cpp:237]     Train net output #0: loss = 0.445994 (* 1 = 0.445994 loss)
I0509 22:12:20.521283 19026 sgd_solver.cpp:105] Iteration 4140, lr = 0.0029269
I0509 22:12:23.131268 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:12:25.474824 19026 solver.cpp:218] Iteration 4152 (2.4225 iter/s, 4.95356s/12 iters), loss = 0.347794
I0509 22:12:25.474870 19026 solver.cpp:237]     Train net output #0: loss = 0.347794 (* 1 = 0.347794 loss)
I0509 22:12:25.474879 19026 sgd_solver.cpp:105] Iteration 4152, lr = 0.00290665
I0509 22:12:30.488319 19026 solver.cpp:218] Iteration 4164 (2.39356 iter/s, 5.01345s/12 iters), loss = 0.295786
I0509 22:12:30.488451 19026 solver.cpp:237]     Train net output #0: loss = 0.295786 (* 1 = 0.295786 loss)
I0509 22:12:30.488459 19026 sgd_solver.cpp:105] Iteration 4164, lr = 0.00288648
I0509 22:12:35.480253 19026 solver.cpp:218] Iteration 4176 (2.40394 iter/s, 4.99181s/12 iters), loss = 0.339518
I0509 22:12:35.480295 19026 solver.cpp:237]     Train net output #0: loss = 0.339518 (* 1 = 0.339518 loss)
I0509 22:12:35.480304 19026 sgd_solver.cpp:105] Iteration 4176, lr = 0.00286639
I0509 22:12:37.489797 19026 solver.cpp:330] Iteration 4182, Testing net (#0)
I0509 22:12:37.489818 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:12:43.842737 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:12:44.450949 19026 solver.cpp:397]     Test net output #0: accuracy = 0.459704
I0509 22:12:44.451022 19026 solver.cpp:397]     Test net output #1: loss = 2.72337 (* 1 = 2.72337 loss)
I0509 22:12:46.284442 19026 solver.cpp:218] Iteration 4188 (1.11068 iter/s, 10.8042s/12 iters), loss = 0.259468
I0509 22:12:46.284488 19026 solver.cpp:237]     Train net output #0: loss = 0.259468 (* 1 = 0.259468 loss)
I0509 22:12:46.284500 19026 sgd_solver.cpp:105] Iteration 4188, lr = 0.00284638
I0509 22:12:51.251401 19026 solver.cpp:218] Iteration 4200 (2.41598 iter/s, 4.96692s/12 iters), loss = 0.392943
I0509 22:12:51.251442 19026 solver.cpp:237]     Train net output #0: loss = 0.392943 (* 1 = 0.392943 loss)
I0509 22:12:51.251451 19026 sgd_solver.cpp:105] Iteration 4200, lr = 0.00282646
I0509 22:12:56.236490 19026 solver.cpp:218] Iteration 4212 (2.4072 iter/s, 4.98505s/12 iters), loss = 0.318741
I0509 22:12:56.236536 19026 solver.cpp:237]     Train net output #0: loss = 0.318741 (* 1 = 0.318741 loss)
I0509 22:12:56.236543 19026 sgd_solver.cpp:105] Iteration 4212, lr = 0.00280663
I0509 22:13:01.230065 19026 solver.cpp:218] Iteration 4224 (2.40311 iter/s, 4.99353s/12 iters), loss = 0.227144
I0509 22:13:01.230190 19026 solver.cpp:237]     Train net output #0: loss = 0.227144 (* 1 = 0.227144 loss)
I0509 22:13:01.230198 19026 sgd_solver.cpp:105] Iteration 4224, lr = 0.00278688
I0509 22:13:06.212999 19026 solver.cpp:218] Iteration 4236 (2.40828 iter/s, 4.98281s/12 iters), loss = 0.364728
I0509 22:13:06.213060 19026 solver.cpp:237]     Train net output #0: loss = 0.364728 (* 1 = 0.364728 loss)
I0509 22:13:06.213073 19026 sgd_solver.cpp:105] Iteration 4236, lr = 0.00276721
I0509 22:13:10.955555 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:13:11.187202 19026 solver.cpp:218] Iteration 4248 (2.41247 iter/s, 4.97415s/12 iters), loss = 0.422275
I0509 22:13:11.187242 19026 solver.cpp:237]     Train net output #0: loss = 0.422275 (* 1 = 0.422275 loss)
I0509 22:13:11.187252 19026 sgd_solver.cpp:105] Iteration 4248, lr = 0.00274763
I0509 22:13:16.189154 19026 solver.cpp:218] Iteration 4260 (2.39908 iter/s, 5.00192s/12 iters), loss = 0.367294
I0509 22:13:16.189194 19026 solver.cpp:237]     Train net output #0: loss = 0.367294 (* 1 = 0.367294 loss)
I0509 22:13:16.189203 19026 sgd_solver.cpp:105] Iteration 4260, lr = 0.00272814
I0509 22:13:21.184155 19026 solver.cpp:218] Iteration 4272 (2.40242 iter/s, 4.99496s/12 iters), loss = 0.241551
I0509 22:13:21.184199 19026 solver.cpp:237]     Train net output #0: loss = 0.241551 (* 1 = 0.241551 loss)
I0509 22:13:21.184207 19026 sgd_solver.cpp:105] Iteration 4272, lr = 0.00270873
I0509 22:13:25.687942 19026 solver.cpp:330] Iteration 4284, Testing net (#0)
I0509 22:13:25.687963 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:13:32.103817 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:13:32.727226 19026 solver.cpp:397]     Test net output #0: accuracy = 0.462582
I0509 22:13:32.727275 19026 solver.cpp:397]     Test net output #1: loss = 2.72045 (* 1 = 2.72045 loss)
I0509 22:13:32.823678 19026 solver.cpp:218] Iteration 4284 (1.03097 iter/s, 11.6395s/12 iters), loss = 0.289676
I0509 22:13:32.823719 19026 solver.cpp:237]     Train net output #0: loss = 0.289676 (* 1 = 0.289676 loss)
I0509 22:13:32.823727 19026 sgd_solver.cpp:105] Iteration 4284, lr = 0.00268941
I0509 22:13:36.997773 19026 solver.cpp:218] Iteration 4296 (2.8749 iter/s, 4.17405s/12 iters), loss = 0.238818
I0509 22:13:36.997813 19026 solver.cpp:237]     Train net output #0: loss = 0.238818 (* 1 = 0.238818 loss)
I0509 22:13:36.997822 19026 sgd_solver.cpp:105] Iteration 4296, lr = 0.00267018
I0509 22:13:41.982501 19026 solver.cpp:218] Iteration 4308 (2.40737 iter/s, 4.98468s/12 iters), loss = 0.357833
I0509 22:13:41.982545 19026 solver.cpp:237]     Train net output #0: loss = 0.357833 (* 1 = 0.357833 loss)
I0509 22:13:41.982553 19026 sgd_solver.cpp:105] Iteration 4308, lr = 0.00265104
I0509 22:13:46.962146 19026 solver.cpp:218] Iteration 4320 (2.40983 iter/s, 4.9796s/12 iters), loss = 0.321053
I0509 22:13:46.962188 19026 solver.cpp:237]     Train net output #0: loss = 0.321053 (* 1 = 0.321053 loss)
I0509 22:13:46.962196 19026 sgd_solver.cpp:105] Iteration 4320, lr = 0.00263198
I0509 22:13:51.960569 19026 solver.cpp:218] Iteration 4332 (2.40078 iter/s, 4.99838s/12 iters), loss = 0.24818
I0509 22:13:51.960611 19026 solver.cpp:237]     Train net output #0: loss = 0.24818 (* 1 = 0.24818 loss)
I0509 22:13:51.960619 19026 sgd_solver.cpp:105] Iteration 4332, lr = 0.00261301
I0509 22:13:56.943073 19026 solver.cpp:218] Iteration 4344 (2.40845 iter/s, 4.98247s/12 iters), loss = 0.300816
I0509 22:13:56.943112 19026 solver.cpp:237]     Train net output #0: loss = 0.300816 (* 1 = 0.300816 loss)
I0509 22:13:56.943120 19026 sgd_solver.cpp:105] Iteration 4344, lr = 0.00259413
I0509 22:13:58.821523 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:14:01.909524 19026 solver.cpp:218] Iteration 4356 (2.41623 iter/s, 4.96642s/12 iters), loss = 0.215516
I0509 22:14:01.909564 19026 solver.cpp:237]     Train net output #0: loss = 0.215516 (* 1 = 0.215516 loss)
I0509 22:14:01.909572 19026 sgd_solver.cpp:105] Iteration 4356, lr = 0.00257534
I0509 22:14:06.912351 19026 solver.cpp:218] Iteration 4368 (2.39866 iter/s, 5.00279s/12 iters), loss = 0.257104
I0509 22:14:06.912479 19026 solver.cpp:237]     Train net output #0: loss = 0.257104 (* 1 = 0.257104 loss)
I0509 22:14:06.912488 19026 sgd_solver.cpp:105] Iteration 4368, lr = 0.00255664
I0509 22:14:11.831065 19026 solver.cpp:218] Iteration 4380 (2.43972 iter/s, 4.91859s/12 iters), loss = 0.189722
I0509 22:14:11.831101 19026 solver.cpp:237]     Train net output #0: loss = 0.189722 (* 1 = 0.189722 loss)
I0509 22:14:11.831109 19026 sgd_solver.cpp:105] Iteration 4380, lr = 0.00253803
I0509 22:14:13.847142 19026 solver.cpp:330] Iteration 4386, Testing net (#0)
I0509 22:14:13.847163 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:14:20.415141 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:14:21.100452 19026 solver.cpp:397]     Test net output #0: accuracy = 0.456003
I0509 22:14:21.100520 19026 solver.cpp:397]     Test net output #1: loss = 2.76921 (* 1 = 2.76921 loss)
I0509 22:14:22.935470 19026 solver.cpp:218] Iteration 4392 (1.08065 iter/s, 11.1044s/12 iters), loss = 0.242144
I0509 22:14:22.935515 19026 solver.cpp:237]     Train net output #0: loss = 0.242144 (* 1 = 0.242144 loss)
I0509 22:14:22.935523 19026 sgd_solver.cpp:105] Iteration 4392, lr = 0.00251951
I0509 22:14:27.943279 19026 solver.cpp:218] Iteration 4404 (2.39628 iter/s, 5.00777s/12 iters), loss = 0.180455
I0509 22:14:27.943323 19026 solver.cpp:237]     Train net output #0: loss = 0.180455 (* 1 = 0.180455 loss)
I0509 22:14:27.943331 19026 sgd_solver.cpp:105] Iteration 4404, lr = 0.00250107
I0509 22:14:32.895752 19026 solver.cpp:218] Iteration 4416 (2.42305 iter/s, 4.95243s/12 iters), loss = 0.22189
I0509 22:14:32.895794 19026 solver.cpp:237]     Train net output #0: loss = 0.22189 (* 1 = 0.22189 loss)
I0509 22:14:32.895803 19026 sgd_solver.cpp:105] Iteration 4416, lr = 0.00248273
I0509 22:14:37.907292 19026 solver.cpp:218] Iteration 4428 (2.39449 iter/s, 5.01151s/12 iters), loss = 0.111101
I0509 22:14:37.907410 19026 solver.cpp:237]     Train net output #0: loss = 0.111101 (* 1 = 0.111101 loss)
I0509 22:14:37.907419 19026 sgd_solver.cpp:105] Iteration 4428, lr = 0.00246448
I0509 22:14:42.962141 19026 solver.cpp:218] Iteration 4440 (2.37401 iter/s, 5.05474s/12 iters), loss = 0.223392
I0509 22:14:42.962182 19026 solver.cpp:237]     Train net output #0: loss = 0.223392 (* 1 = 0.223392 loss)
I0509 22:14:42.962189 19026 sgd_solver.cpp:105] Iteration 4440, lr = 0.00244632
I0509 22:14:47.007731 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:14:47.967262 19026 solver.cpp:218] Iteration 4452 (2.39756 iter/s, 5.00509s/12 iters), loss = 0.283691
I0509 22:14:47.967303 19026 solver.cpp:237]     Train net output #0: loss = 0.283691 (* 1 = 0.283691 loss)
I0509 22:14:47.967311 19026 sgd_solver.cpp:105] Iteration 4452, lr = 0.00242825
I0509 22:14:52.961329 19026 solver.cpp:218] Iteration 4464 (2.40287 iter/s, 4.99403s/12 iters), loss = 0.2785
I0509 22:14:52.961369 19026 solver.cpp:237]     Train net output #0: loss = 0.2785 (* 1 = 0.2785 loss)
I0509 22:14:52.961376 19026 sgd_solver.cpp:105] Iteration 4464, lr = 0.00241027
I0509 22:14:57.969017 19026 solver.cpp:218] Iteration 4476 (2.39633 iter/s, 5.00765s/12 iters), loss = 0.394855
I0509 22:14:57.969066 19026 solver.cpp:237]     Train net output #0: loss = 0.394855 (* 1 = 0.394855 loss)
I0509 22:14:57.969074 19026 sgd_solver.cpp:105] Iteration 4476, lr = 0.00239238
I0509 22:15:02.471596 19026 solver.cpp:330] Iteration 4488, Testing net (#0)
I0509 22:15:02.471614 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:15:08.693915 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:15:09.352998 19026 solver.cpp:397]     Test net output #0: accuracy = 0.471628
I0509 22:15:09.353032 19026 solver.cpp:397]     Test net output #1: loss = 2.6768 (* 1 = 2.6768 loss)
I0509 22:15:09.449692 19026 solver.cpp:218] Iteration 4488 (1.04524 iter/s, 11.4807s/12 iters), loss = 0.157071
I0509 22:15:09.449734 19026 solver.cpp:237]     Train net output #0: loss = 0.157071 (* 1 = 0.157071 loss)
I0509 22:15:09.449743 19026 sgd_solver.cpp:105] Iteration 4488, lr = 0.00237458
I0509 22:15:13.563299 19026 solver.cpp:218] Iteration 4500 (2.91718 iter/s, 4.11357s/12 iters), loss = 0.232294
I0509 22:15:13.563346 19026 solver.cpp:237]     Train net output #0: loss = 0.232294 (* 1 = 0.232294 loss)
I0509 22:15:13.563354 19026 sgd_solver.cpp:105] Iteration 4500, lr = 0.00235687
I0509 22:15:18.564097 19026 solver.cpp:218] Iteration 4512 (2.39964 iter/s, 5.00075s/12 iters), loss = 0.0985753
I0509 22:15:18.564141 19026 solver.cpp:237]     Train net output #0: loss = 0.0985753 (* 1 = 0.0985753 loss)
I0509 22:15:18.564147 19026 sgd_solver.cpp:105] Iteration 4512, lr = 0.00233926
I0509 22:15:23.580106 19026 solver.cpp:218] Iteration 4524 (2.39236 iter/s, 5.01597s/12 iters), loss = 0.343208
I0509 22:15:23.580145 19026 solver.cpp:237]     Train net output #0: loss = 0.343208 (* 1 = 0.343208 loss)
I0509 22:15:23.580153 19026 sgd_solver.cpp:105] Iteration 4524, lr = 0.00232174
I0509 22:15:28.597375 19026 solver.cpp:218] Iteration 4536 (2.39175 iter/s, 5.01724s/12 iters), loss = 0.174484
I0509 22:15:28.597414 19026 solver.cpp:237]     Train net output #0: loss = 0.174484 (* 1 = 0.174484 loss)
I0509 22:15:28.597422 19026 sgd_solver.cpp:105] Iteration 4536, lr = 0.0023043
I0509 22:15:33.567410 19026 solver.cpp:218] Iteration 4548 (2.41449 iter/s, 4.97s/12 iters), loss = 0.2201
I0509 22:15:33.567451 19026 solver.cpp:237]     Train net output #0: loss = 0.2201 (* 1 = 0.2201 loss)
I0509 22:15:33.567459 19026 sgd_solver.cpp:105] Iteration 4548, lr = 0.00228696
I0509 22:15:34.810818 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:15:38.521415 19026 solver.cpp:218] Iteration 4560 (2.4223 iter/s, 4.95397s/12 iters), loss = 0.178997
I0509 22:15:38.521462 19026 solver.cpp:237]     Train net output #0: loss = 0.178997 (* 1 = 0.178997 loss)
I0509 22:15:38.521471 19026 sgd_solver.cpp:105] Iteration 4560, lr = 0.00226972
I0509 22:15:43.405452 19026 solver.cpp:218] Iteration 4572 (2.45701 iter/s, 4.88399s/12 iters), loss = 0.275989
I0509 22:15:43.405580 19026 solver.cpp:237]     Train net output #0: loss = 0.275989 (* 1 = 0.275989 loss)
I0509 22:15:43.405589 19026 sgd_solver.cpp:105] Iteration 4572, lr = 0.00225256
I0509 22:15:48.302657 19026 solver.cpp:218] Iteration 4584 (2.45044 iter/s, 4.89709s/12 iters), loss = 0.138491
I0509 22:15:48.302696 19026 solver.cpp:237]     Train net output #0: loss = 0.138491 (* 1 = 0.138491 loss)
I0509 22:15:48.302704 19026 sgd_solver.cpp:105] Iteration 4584, lr = 0.0022355
I0509 22:15:50.317822 19026 solver.cpp:330] Iteration 4590, Testing net (#0)
I0509 22:15:50.317840 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:15:56.597734 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:15:57.270408 19026 solver.cpp:397]     Test net output #0: accuracy = 0.471217
I0509 22:15:57.270457 19026 solver.cpp:397]     Test net output #1: loss = 2.73076 (* 1 = 2.73076 loss)
I0509 22:15:59.093235 19026 solver.cpp:218] Iteration 4596 (1.11208 iter/s, 10.7906s/12 iters), loss = 0.21242
I0509 22:15:59.093277 19026 solver.cpp:237]     Train net output #0: loss = 0.21242 (* 1 = 0.21242 loss)
I0509 22:15:59.093286 19026 sgd_solver.cpp:105] Iteration 4596, lr = 0.00221853
I0509 22:16:04.071151 19026 solver.cpp:218] Iteration 4608 (2.41066 iter/s, 4.97788s/12 iters), loss = 0.239748
I0509 22:16:04.071189 19026 solver.cpp:237]     Train net output #0: loss = 0.239748 (* 1 = 0.239748 loss)
I0509 22:16:04.071197 19026 sgd_solver.cpp:105] Iteration 4608, lr = 0.00220165
I0509 22:16:09.069470 19026 solver.cpp:218] Iteration 4620 (2.40082 iter/s, 4.99829s/12 iters), loss = 0.221639
I0509 22:16:09.069509 19026 solver.cpp:237]     Train net output #0: loss = 0.221639 (* 1 = 0.221639 loss)
I0509 22:16:09.069519 19026 sgd_solver.cpp:105] Iteration 4620, lr = 0.00218486
I0509 22:16:14.046388 19026 solver.cpp:218] Iteration 4632 (2.41115 iter/s, 4.97688s/12 iters), loss = 0.236196
I0509 22:16:14.046514 19026 solver.cpp:237]     Train net output #0: loss = 0.236196 (* 1 = 0.236196 loss)
I0509 22:16:14.046521 19026 sgd_solver.cpp:105] Iteration 4632, lr = 0.00216817
I0509 22:16:19.049470 19026 solver.cpp:218] Iteration 4644 (2.39858 iter/s, 5.00296s/12 iters), loss = 0.203862
I0509 22:16:19.049515 19026 solver.cpp:237]     Train net output #0: loss = 0.203862 (* 1 = 0.203862 loss)
I0509 22:16:19.049522 19026 sgd_solver.cpp:105] Iteration 4644, lr = 0.00215157
I0509 22:16:22.480203 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:16:24.098453 19026 solver.cpp:218] Iteration 4656 (2.37674 iter/s, 5.04894s/12 iters), loss = 0.18953
I0509 22:16:24.098497 19026 solver.cpp:237]     Train net output #0: loss = 0.18953 (* 1 = 0.18953 loss)
I0509 22:16:24.098505 19026 sgd_solver.cpp:105] Iteration 4656, lr = 0.00213506
I0509 22:16:29.072507 19026 solver.cpp:218] Iteration 4668 (2.41254 iter/s, 4.974s/12 iters), loss = 0.263949
I0509 22:16:29.072557 19026 solver.cpp:237]     Train net output #0: loss = 0.263949 (* 1 = 0.263949 loss)
I0509 22:16:29.072566 19026 sgd_solver.cpp:105] Iteration 4668, lr = 0.00211864
I0509 22:16:34.066772 19026 solver.cpp:218] Iteration 4680 (2.40278 iter/s, 4.99422s/12 iters), loss = 0.250979
I0509 22:16:34.066818 19026 solver.cpp:237]     Train net output #0: loss = 0.250979 (* 1 = 0.250979 loss)
I0509 22:16:34.066828 19026 sgd_solver.cpp:105] Iteration 4680, lr = 0.00210232
I0509 22:16:38.594017 19026 solver.cpp:330] Iteration 4692, Testing net (#0)
I0509 22:16:38.594038 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:16:44.831522 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:16:45.520012 19026 solver.cpp:397]     Test net output #0: accuracy = 0.474095
I0509 22:16:45.520068 19026 solver.cpp:397]     Test net output #1: loss = 2.80643 (* 1 = 2.80643 loss)
I0509 22:16:45.617164 19026 solver.cpp:218] Iteration 4692 (1.03893 iter/s, 11.5504s/12 iters), loss = 0.13657
I0509 22:16:45.617225 19026 solver.cpp:237]     Train net output #0: loss = 0.13657 (* 1 = 0.13657 loss)
I0509 22:16:45.617238 19026 sgd_solver.cpp:105] Iteration 4692, lr = 0.00208609
I0509 22:16:49.757436 19026 solver.cpp:218] Iteration 4704 (2.8984 iter/s, 4.14021s/12 iters), loss = 0.224292
I0509 22:16:49.757488 19026 solver.cpp:237]     Train net output #0: loss = 0.224292 (* 1 = 0.224292 loss)
I0509 22:16:49.757501 19026 sgd_solver.cpp:105] Iteration 4704, lr = 0.00206995
I0509 22:16:52.633502 19026 blocking_queue.cpp:49] Waiting for data
I0509 22:16:54.748631 19026 solver.cpp:218] Iteration 4716 (2.40426 iter/s, 4.99114s/12 iters), loss = 0.219714
I0509 22:16:54.748687 19026 solver.cpp:237]     Train net output #0: loss = 0.219714 (* 1 = 0.219714 loss)
I0509 22:16:54.748700 19026 sgd_solver.cpp:105] Iteration 4716, lr = 0.0020539
I0509 22:16:59.747758 19026 solver.cpp:218] Iteration 4728 (2.40044 iter/s, 4.99908s/12 iters), loss = 0.102867
I0509 22:16:59.747802 19026 solver.cpp:237]     Train net output #0: loss = 0.102867 (* 1 = 0.102867 loss)
I0509 22:16:59.747809 19026 sgd_solver.cpp:105] Iteration 4728, lr = 0.00203794
I0509 22:17:04.753414 19026 solver.cpp:218] Iteration 4740 (2.39731 iter/s, 5.00562s/12 iters), loss = 0.129178
I0509 22:17:04.753454 19026 solver.cpp:237]     Train net output #0: loss = 0.129178 (* 1 = 0.129178 loss)
I0509 22:17:04.753463 19026 sgd_solver.cpp:105] Iteration 4740, lr = 0.00202208
I0509 22:17:09.729760 19026 solver.cpp:218] Iteration 4752 (2.41143 iter/s, 4.97631s/12 iters), loss = 0.3142
I0509 22:17:09.729802 19026 solver.cpp:237]     Train net output #0: loss = 0.3142 (* 1 = 0.3142 loss)
I0509 22:17:09.729810 19026 sgd_solver.cpp:105] Iteration 4752, lr = 0.00200631
I0509 22:17:10.252058 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:17:14.710335 19026 solver.cpp:218] Iteration 4764 (2.40938 iter/s, 4.98054s/12 iters), loss = 0.316969
I0509 22:17:14.710379 19026 solver.cpp:237]     Train net output #0: loss = 0.316969 (* 1 = 0.316969 loss)
I0509 22:17:14.710387 19026 sgd_solver.cpp:105] Iteration 4764, lr = 0.00199064
I0509 22:17:19.696938 19026 solver.cpp:218] Iteration 4776 (2.40647 iter/s, 4.98656s/12 iters), loss = 0.134512
I0509 22:17:19.697050 19026 solver.cpp:237]     Train net output #0: loss = 0.134512 (* 1 = 0.134512 loss)
I0509 22:17:19.697059 19026 sgd_solver.cpp:105] Iteration 4776, lr = 0.00197505
I0509 22:17:24.683655 19026 solver.cpp:218] Iteration 4788 (2.40644 iter/s, 4.98661s/12 iters), loss = 0.219283
I0509 22:17:24.683696 19026 solver.cpp:237]     Train net output #0: loss = 0.219283 (* 1 = 0.219283 loss)
I0509 22:17:24.683704 19026 sgd_solver.cpp:105] Iteration 4788, lr = 0.00195956
I0509 22:17:26.699003 19026 solver.cpp:330] Iteration 4794, Testing net (#0)
I0509 22:17:26.699024 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:17:33.004498 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:17:33.704386 19026 solver.cpp:397]     Test net output #0: accuracy = 0.471628
I0509 22:17:33.704418 19026 solver.cpp:397]     Test net output #1: loss = 2.78426 (* 1 = 2.78426 loss)
I0509 22:17:35.535346 19026 solver.cpp:218] Iteration 4800 (1.10582 iter/s, 10.8517s/12 iters), loss = 0.142006
I0509 22:17:35.535388 19026 solver.cpp:237]     Train net output #0: loss = 0.142006 (* 1 = 0.142006 loss)
I0509 22:17:35.535396 19026 sgd_solver.cpp:105] Iteration 4800, lr = 0.00194416
I0509 22:17:40.523608 19026 solver.cpp:218] Iteration 4812 (2.40566 iter/s, 4.98823s/12 iters), loss = 0.294442
I0509 22:17:40.523648 19026 solver.cpp:237]     Train net output #0: loss = 0.294442 (* 1 = 0.294442 loss)
I0509 22:17:40.523656 19026 sgd_solver.cpp:105] Iteration 4812, lr = 0.00192885
I0509 22:17:45.510056 19026 solver.cpp:218] Iteration 4824 (2.40654 iter/s, 4.98641s/12 iters), loss = 0.0965995
I0509 22:17:45.510094 19026 solver.cpp:237]     Train net output #0: loss = 0.0965995 (* 1 = 0.0965995 loss)
I0509 22:17:45.510102 19026 sgd_solver.cpp:105] Iteration 4824, lr = 0.00191363
I0509 22:17:50.506647 19026 solver.cpp:218] Iteration 4836 (2.40165 iter/s, 4.99656s/12 iters), loss = 0.149531
I0509 22:17:50.506755 19026 solver.cpp:237]     Train net output #0: loss = 0.149531 (* 1 = 0.149531 loss)
I0509 22:17:50.506765 19026 sgd_solver.cpp:105] Iteration 4836, lr = 0.00189851
I0509 22:17:55.516386 19026 solver.cpp:218] Iteration 4848 (2.39539 iter/s, 5.00963s/12 iters), loss = 0.207828
I0509 22:17:55.516427 19026 solver.cpp:237]     Train net output #0: loss = 0.207828 (* 1 = 0.207828 loss)
I0509 22:17:55.516434 19026 sgd_solver.cpp:105] Iteration 4848, lr = 0.00188347
I0509 22:17:58.162652 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:18:00.504654 19026 solver.cpp:218] Iteration 4860 (2.40566 iter/s, 4.98823s/12 iters), loss = 0.149715
I0509 22:18:00.504698 19026 solver.cpp:237]     Train net output #0: loss = 0.149715 (* 1 = 0.149715 loss)
I0509 22:18:00.504704 19026 sgd_solver.cpp:105] Iteration 4860, lr = 0.00186853
I0509 22:18:05.587054 19026 solver.cpp:218] Iteration 4872 (2.36111 iter/s, 5.08236s/12 iters), loss = 0.151081
I0509 22:18:05.587095 19026 solver.cpp:237]     Train net output #0: loss = 0.151081 (* 1 = 0.151081 loss)
I0509 22:18:05.587102 19026 sgd_solver.cpp:105] Iteration 4872, lr = 0.00185368
I0509 22:18:10.621932 19026 solver.cpp:218] Iteration 4884 (2.38339 iter/s, 5.03484s/12 iters), loss = 0.214459
I0509 22:18:10.621971 19026 solver.cpp:237]     Train net output #0: loss = 0.214459 (* 1 = 0.214459 loss)
I0509 22:18:10.621979 19026 sgd_solver.cpp:105] Iteration 4884, lr = 0.00183892
I0509 22:18:15.278908 19026 solver.cpp:330] Iteration 4896, Testing net (#0)
I0509 22:18:15.278930 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:18:21.640360 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:18:22.351263 19026 solver.cpp:397]     Test net output #0: accuracy = 0.481497
I0509 22:18:22.351312 19026 solver.cpp:397]     Test net output #1: loss = 2.75167 (* 1 = 2.75167 loss)
I0509 22:18:22.447738 19026 solver.cpp:218] Iteration 4896 (1.01473 iter/s, 11.8258s/12 iters), loss = 0.164631
I0509 22:18:22.447785 19026 solver.cpp:237]     Train net output #0: loss = 0.164631 (* 1 = 0.164631 loss)
I0509 22:18:22.447793 19026 sgd_solver.cpp:105] Iteration 4896, lr = 0.00182426
I0509 22:18:26.640736 19026 solver.cpp:218] Iteration 4908 (2.86195 iter/s, 4.19295s/12 iters), loss = 0.123539
I0509 22:18:26.640781 19026 solver.cpp:237]     Train net output #0: loss = 0.123539 (* 1 = 0.123539 loss)
I0509 22:18:26.640789 19026 sgd_solver.cpp:105] Iteration 4908, lr = 0.00180968
I0509 22:18:31.763836 19026 solver.cpp:218] Iteration 4920 (2.34235 iter/s, 5.12306s/12 iters), loss = 0.167476
I0509 22:18:31.763878 19026 solver.cpp:237]     Train net output #0: loss = 0.167476 (* 1 = 0.167476 loss)
I0509 22:18:31.763886 19026 sgd_solver.cpp:105] Iteration 4920, lr = 0.00179519
I0509 22:18:36.781761 19026 solver.cpp:218] Iteration 4932 (2.39145 iter/s, 5.01788s/12 iters), loss = 0.199602
I0509 22:18:36.781821 19026 solver.cpp:237]     Train net output #0: loss = 0.199602 (* 1 = 0.199602 loss)
I0509 22:18:36.781833 19026 sgd_solver.cpp:105] Iteration 4932, lr = 0.0017808
I0509 22:18:41.764042 19026 solver.cpp:218] Iteration 4944 (2.40856 iter/s, 4.98222s/12 iters), loss = 0.176415
I0509 22:18:41.764099 19026 solver.cpp:237]     Train net output #0: loss = 0.176415 (* 1 = 0.176415 loss)
I0509 22:18:41.764114 19026 sgd_solver.cpp:105] Iteration 4944, lr = 0.00176649
I0509 22:18:46.468219 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:18:46.669430 19026 solver.cpp:218] Iteration 4956 (2.44632 iter/s, 4.90533s/12 iters), loss = 0.193097
I0509 22:18:46.669493 19026 solver.cpp:237]     Train net output #0: loss = 0.193097 (* 1 = 0.193097 loss)
I0509 22:18:46.669505 19026 sgd_solver.cpp:105] Iteration 4956, lr = 0.00175228
I0509 22:18:51.656386 19026 solver.cpp:218] Iteration 4968 (2.4063 iter/s, 4.9869s/12 iters), loss = 0.229563
I0509 22:18:51.656544 19026 solver.cpp:237]     Train net output #0: loss = 0.229563 (* 1 = 0.229563 loss)
I0509 22:18:51.656556 19026 sgd_solver.cpp:105] Iteration 4968, lr = 0.00173816
I0509 22:18:56.702646 19026 solver.cpp:218] Iteration 4980 (2.37807 iter/s, 5.04611s/12 iters), loss = 0.242936
I0509 22:18:56.702694 19026 solver.cpp:237]     Train net output #0: loss = 0.242936 (* 1 = 0.242936 loss)
I0509 22:18:56.702705 19026 sgd_solver.cpp:105] Iteration 4980, lr = 0.00172412
I0509 22:19:01.678656 19026 solver.cpp:218] Iteration 4992 (2.41159 iter/s, 4.97597s/12 iters), loss = 0.168575
I0509 22:19:01.678697 19026 solver.cpp:237]     Train net output #0: loss = 0.168575 (* 1 = 0.168575 loss)
I0509 22:19:01.678705 19026 sgd_solver.cpp:105] Iteration 4992, lr = 0.00171018
I0509 22:19:03.651784 19026 solver.cpp:330] Iteration 4998, Testing net (#0)
I0509 22:19:03.651804 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:19:09.804208 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:19:10.526060 19026 solver.cpp:397]     Test net output #0: accuracy = 0.49301
I0509 22:19:10.526109 19026 solver.cpp:397]     Test net output #1: loss = 2.66638 (* 1 = 2.66638 loss)
I0509 22:19:12.420625 19026 solver.cpp:218] Iteration 5004 (1.11711 iter/s, 10.742s/12 iters), loss = 0.102888
I0509 22:19:12.420668 19026 solver.cpp:237]     Train net output #0: loss = 0.102888 (* 1 = 0.102888 loss)
I0509 22:19:12.420676 19026 sgd_solver.cpp:105] Iteration 5004, lr = 0.00169632
I0509 22:19:17.684509 19026 solver.cpp:218] Iteration 5016 (2.2797 iter/s, 5.26384s/12 iters), loss = 0.198627
I0509 22:19:17.684553 19026 solver.cpp:237]     Train net output #0: loss = 0.198627 (* 1 = 0.198627 loss)
I0509 22:19:17.684561 19026 sgd_solver.cpp:105] Iteration 5016, lr = 0.00168256
I0509 22:19:22.706326 19026 solver.cpp:218] Iteration 5028 (2.38959 iter/s, 5.02177s/12 iters), loss = 0.170547
I0509 22:19:22.706461 19026 solver.cpp:237]     Train net output #0: loss = 0.170547 (* 1 = 0.170547 loss)
I0509 22:19:22.706471 19026 sgd_solver.cpp:105] Iteration 5028, lr = 0.00166888
I0509 22:19:27.697348 19026 solver.cpp:218] Iteration 5040 (2.40438 iter/s, 4.99089s/12 iters), loss = 0.153349
I0509 22:19:27.697388 19026 solver.cpp:237]     Train net output #0: loss = 0.153349 (* 1 = 0.153349 loss)
I0509 22:19:27.697397 19026 sgd_solver.cpp:105] Iteration 5040, lr = 0.0016553
I0509 22:19:32.671404 19026 solver.cpp:218] Iteration 5052 (2.41254 iter/s, 4.97402s/12 iters), loss = 0.219977
I0509 22:19:32.671444 19026 solver.cpp:237]     Train net output #0: loss = 0.219977 (* 1 = 0.219977 loss)
I0509 22:19:32.671452 19026 sgd_solver.cpp:105] Iteration 5052, lr = 0.0016418
I0509 22:19:34.594666 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:19:37.648686 19026 solver.cpp:218] Iteration 5064 (2.41097 iter/s, 4.97724s/12 iters), loss = 0.0924638
I0509 22:19:37.648725 19026 solver.cpp:237]     Train net output #0: loss = 0.0924638 (* 1 = 0.0924638 loss)
I0509 22:19:37.648735 19026 sgd_solver.cpp:105] Iteration 5064, lr = 0.00162839
I0509 22:19:42.632086 19026 solver.cpp:218] Iteration 5076 (2.40802 iter/s, 4.98336s/12 iters), loss = 0.157796
I0509 22:19:42.632140 19026 solver.cpp:237]     Train net output #0: loss = 0.157796 (* 1 = 0.157796 loss)
I0509 22:19:42.632150 19026 sgd_solver.cpp:105] Iteration 5076, lr = 0.00161507
I0509 22:19:47.652637 19026 solver.cpp:218] Iteration 5088 (2.3902 iter/s, 5.0205s/12 iters), loss = 0.158539
I0509 22:19:47.652676 19026 solver.cpp:237]     Train net output #0: loss = 0.158539 (* 1 = 0.158539 loss)
I0509 22:19:47.652684 19026 sgd_solver.cpp:105] Iteration 5088, lr = 0.00160184
I0509 22:19:52.172230 19026 solver.cpp:330] Iteration 5100, Testing net (#0)
I0509 22:19:52.172250 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:19:58.484221 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:19:59.261871 19026 solver.cpp:397]     Test net output #0: accuracy = 0.49301
I0509 22:19:59.261921 19026 solver.cpp:397]     Test net output #1: loss = 2.67431 (* 1 = 2.67431 loss)
I0509 22:19:59.358561 19026 solver.cpp:218] Iteration 5100 (1.02512 iter/s, 11.7059s/12 iters), loss = 0.139883
I0509 22:19:59.358608 19026 solver.cpp:237]     Train net output #0: loss = 0.139883 (* 1 = 0.139883 loss)
I0509 22:19:59.358615 19026 sgd_solver.cpp:105] Iteration 5100, lr = 0.00158869
I0509 22:20:03.541622 19026 solver.cpp:218] Iteration 5112 (2.86874 iter/s, 4.18302s/12 iters), loss = 0.142761
I0509 22:20:03.541664 19026 solver.cpp:237]     Train net output #0: loss = 0.142761 (* 1 = 0.142761 loss)
I0509 22:20:03.541672 19026 sgd_solver.cpp:105] Iteration 5112, lr = 0.00157563
I0509 22:20:08.529006 19026 solver.cpp:218] Iteration 5124 (2.40609 iter/s, 4.98735s/12 iters), loss = 0.193907
I0509 22:20:08.529047 19026 solver.cpp:237]     Train net output #0: loss = 0.193907 (* 1 = 0.193907 loss)
I0509 22:20:08.529054 19026 sgd_solver.cpp:105] Iteration 5124, lr = 0.00156266
I0509 22:20:13.512748 19026 solver.cpp:218] Iteration 5136 (2.40785 iter/s, 4.9837s/12 iters), loss = 0.160953
I0509 22:20:13.512790 19026 solver.cpp:237]     Train net output #0: loss = 0.160953 (* 1 = 0.160953 loss)
I0509 22:20:13.512799 19026 sgd_solver.cpp:105] Iteration 5136, lr = 0.00154978
I0509 22:20:18.504971 19026 solver.cpp:218] Iteration 5148 (2.40376 iter/s, 4.99218s/12 iters), loss = 0.0576967
I0509 22:20:18.505012 19026 solver.cpp:237]     Train net output #0: loss = 0.0576967 (* 1 = 0.0576967 loss)
I0509 22:20:18.505019 19026 sgd_solver.cpp:105] Iteration 5148, lr = 0.00153699
I0509 22:20:22.571125 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:20:23.498968 19026 solver.cpp:218] Iteration 5160 (2.4029 iter/s, 4.99396s/12 iters), loss = 0.105802
I0509 22:20:23.499011 19026 solver.cpp:237]     Train net output #0: loss = 0.105802 (* 1 = 0.105802 loss)
I0509 22:20:23.499019 19026 sgd_solver.cpp:105] Iteration 5160, lr = 0.00152428
I0509 22:20:28.507617 19026 solver.cpp:218] Iteration 5172 (2.39588 iter/s, 5.00861s/12 iters), loss = 0.169969
I0509 22:20:28.507732 19026 solver.cpp:237]     Train net output #0: loss = 0.169969 (* 1 = 0.169969 loss)
I0509 22:20:28.507741 19026 sgd_solver.cpp:105] Iteration 5172, lr = 0.00151165
I0509 22:20:33.454901 19026 solver.cpp:218] Iteration 5184 (2.42563 iter/s, 4.94717s/12 iters), loss = 0.197065
I0509 22:20:33.454944 19026 solver.cpp:237]     Train net output #0: loss = 0.197065 (* 1 = 0.197065 loss)
I0509 22:20:33.454953 19026 sgd_solver.cpp:105] Iteration 5184, lr = 0.00149912
I0509 22:20:38.424650 19026 solver.cpp:218] Iteration 5196 (2.41463 iter/s, 4.96971s/12 iters), loss = 0.0976215
I0509 22:20:38.424690 19026 solver.cpp:237]     Train net output #0: loss = 0.0976215 (* 1 = 0.0976215 loss)
I0509 22:20:38.424696 19026 sgd_solver.cpp:105] Iteration 5196, lr = 0.00148667
I0509 22:20:40.464013 19026 solver.cpp:330] Iteration 5202, Testing net (#0)
I0509 22:20:40.464032 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:20:46.653823 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:20:47.414388 19026 solver.cpp:397]     Test net output #0: accuracy = 0.497122
I0509 22:20:47.414436 19026 solver.cpp:397]     Test net output #1: loss = 2.69183 (* 1 = 2.69183 loss)
I0509 22:20:49.242830 19026 solver.cpp:218] Iteration 5208 (1.10924 iter/s, 10.8182s/12 iters), loss = 0.169688
I0509 22:20:49.242873 19026 solver.cpp:237]     Train net output #0: loss = 0.169688 (* 1 = 0.169688 loss)
I0509 22:20:49.242882 19026 sgd_solver.cpp:105] Iteration 5208, lr = 0.0014743
I0509 22:20:54.236734 19026 solver.cpp:218] Iteration 5220 (2.40295 iter/s, 4.99387s/12 iters), loss = 0.2257
I0509 22:20:54.236778 19026 solver.cpp:237]     Train net output #0: loss = 0.2257 (* 1 = 0.2257 loss)
I0509 22:20:54.236786 19026 sgd_solver.cpp:105] Iteration 5220, lr = 0.00146202
I0509 22:20:59.206045 19026 solver.cpp:218] Iteration 5232 (2.41484 iter/s, 4.96927s/12 iters), loss = 0.181357
I0509 22:20:59.206210 19026 solver.cpp:237]     Train net output #0: loss = 0.181357 (* 1 = 0.181357 loss)
I0509 22:20:59.206220 19026 sgd_solver.cpp:105] Iteration 5232, lr = 0.00144982
I0509 22:21:04.195333 19026 solver.cpp:218] Iteration 5244 (2.40523 iter/s, 4.98913s/12 iters), loss = 0.0999362
I0509 22:21:04.195374 19026 solver.cpp:237]     Train net output #0: loss = 0.0999362 (* 1 = 0.0999362 loss)
I0509 22:21:04.195382 19026 sgd_solver.cpp:105] Iteration 5244, lr = 0.00143771
I0509 22:21:09.181421 19026 solver.cpp:218] Iteration 5256 (2.40671 iter/s, 4.98605s/12 iters), loss = 0.0744384
I0509 22:21:09.181458 19026 solver.cpp:237]     Train net output #0: loss = 0.0744384 (* 1 = 0.0744384 loss)
I0509 22:21:09.181466 19026 sgd_solver.cpp:105] Iteration 5256, lr = 0.00142569
I0509 22:21:10.458657 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:21:14.154363 19026 solver.cpp:218] Iteration 5268 (2.41308 iter/s, 4.9729s/12 iters), loss = 0.0805949
I0509 22:21:14.154422 19026 solver.cpp:237]     Train net output #0: loss = 0.0805949 (* 1 = 0.0805949 loss)
I0509 22:21:14.154434 19026 sgd_solver.cpp:105] Iteration 5268, lr = 0.00141374
I0509 22:21:19.127660 19026 solver.cpp:218] Iteration 5280 (2.41291 iter/s, 4.97325s/12 iters), loss = 0.108875
I0509 22:21:19.127702 19026 solver.cpp:237]     Train net output #0: loss = 0.108875 (* 1 = 0.108875 loss)
I0509 22:21:19.127712 19026 sgd_solver.cpp:105] Iteration 5280, lr = 0.00140188
I0509 22:21:24.124184 19026 solver.cpp:218] Iteration 5292 (2.40169 iter/s, 4.99649s/12 iters), loss = 0.0713004
I0509 22:21:24.124223 19026 solver.cpp:237]     Train net output #0: loss = 0.0713003 (* 1 = 0.0713003 loss)
I0509 22:21:24.124233 19026 sgd_solver.cpp:105] Iteration 5292, lr = 0.00139011
I0509 22:21:28.653265 19026 solver.cpp:330] Iteration 5304, Testing net (#0)
I0509 22:21:28.653285 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:21:34.201974 19026 blocking_queue.cpp:49] Waiting for data
I0509 22:21:34.807983 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:21:35.577939 19026 solver.cpp:397]     Test net output #0: accuracy = 0.487253
I0509 22:21:35.577986 19026 solver.cpp:397]     Test net output #1: loss = 2.70973 (* 1 = 2.70973 loss)
I0509 22:21:35.674396 19026 solver.cpp:218] Iteration 5304 (1.03894 iter/s, 11.5502s/12 iters), loss = 0.0960084
I0509 22:21:35.674443 19026 solver.cpp:237]     Train net output #0: loss = 0.0960083 (* 1 = 0.0960083 loss)
I0509 22:21:35.674451 19026 sgd_solver.cpp:105] Iteration 5304, lr = 0.00137842
I0509 22:21:39.807160 19026 solver.cpp:218] Iteration 5316 (2.90366 iter/s, 4.13271s/12 iters), loss = 0.165833
I0509 22:21:39.807209 19026 solver.cpp:237]     Train net output #0: loss = 0.165833 (* 1 = 0.165833 loss)
I0509 22:21:39.807215 19026 sgd_solver.cpp:105] Iteration 5316, lr = 0.00136681
I0509 22:21:44.756496 19026 solver.cpp:218] Iteration 5328 (2.42459 iter/s, 4.94929s/12 iters), loss = 0.0891409
I0509 22:21:44.756537 19026 solver.cpp:237]     Train net output #0: loss = 0.0891409 (* 1 = 0.0891409 loss)
I0509 22:21:44.756546 19026 sgd_solver.cpp:105] Iteration 5328, lr = 0.00135528
I0509 22:21:49.697819 19026 solver.cpp:218] Iteration 5340 (2.42852 iter/s, 4.94128s/12 iters), loss = 0.0898345
I0509 22:21:49.697857 19026 solver.cpp:237]     Train net output #0: loss = 0.0898345 (* 1 = 0.0898345 loss)
I0509 22:21:49.697865 19026 sgd_solver.cpp:105] Iteration 5340, lr = 0.00134383
I0509 22:21:54.666525 19026 solver.cpp:218] Iteration 5352 (2.41514 iter/s, 4.96866s/12 iters), loss = 0.0802408
I0509 22:21:54.666579 19026 solver.cpp:237]     Train net output #0: loss = 0.0802408 (* 1 = 0.0802408 loss)
I0509 22:21:54.666592 19026 sgd_solver.cpp:105] Iteration 5352, lr = 0.00133247
I0509 22:21:58.047595 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:21:59.598170 19026 solver.cpp:218] Iteration 5364 (2.43329 iter/s, 4.9316s/12 iters), loss = 0.103051
I0509 22:21:59.598209 19026 solver.cpp:237]     Train net output #0: loss = 0.103051 (* 1 = 0.103051 loss)
I0509 22:21:59.598217 19026 sgd_solver.cpp:105] Iteration 5364, lr = 0.00132119
I0509 22:22:04.573712 19026 solver.cpp:218] Iteration 5376 (2.41182 iter/s, 4.9755s/12 iters), loss = 0.182918
I0509 22:22:04.573879 19026 solver.cpp:237]     Train net output #0: loss = 0.182918 (* 1 = 0.182918 loss)
I0509 22:22:04.573894 19026 sgd_solver.cpp:105] Iteration 5376, lr = 0.00130999
I0509 22:22:09.545526 19026 solver.cpp:218] Iteration 5388 (2.41368 iter/s, 4.97166s/12 iters), loss = 0.0992391
I0509 22:22:09.545568 19026 solver.cpp:237]     Train net output #0: loss = 0.0992391 (* 1 = 0.0992391 loss)
I0509 22:22:09.545576 19026 sgd_solver.cpp:105] Iteration 5388, lr = 0.00129887
I0509 22:22:14.467566 19026 solver.cpp:218] Iteration 5400 (2.43803 iter/s, 4.922s/12 iters), loss = 0.133208
I0509 22:22:14.467607 19026 solver.cpp:237]     Train net output #0: loss = 0.133208 (* 1 = 0.133208 loss)
I0509 22:22:14.467613 19026 sgd_solver.cpp:105] Iteration 5400, lr = 0.00128783
I0509 22:22:16.467861 19026 solver.cpp:330] Iteration 5406, Testing net (#0)
I0509 22:22:16.467881 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:22:22.705020 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:22:23.505071 19026 solver.cpp:397]     Test net output #0: accuracy = 0.483964
I0509 22:22:23.505120 19026 solver.cpp:397]     Test net output #1: loss = 2.73312 (* 1 = 2.73312 loss)
I0509 22:22:25.393339 19026 solver.cpp:218] Iteration 5412 (1.09832 iter/s, 10.9258s/12 iters), loss = 0.11065
I0509 22:22:25.393386 19026 solver.cpp:237]     Train net output #0: loss = 0.11065 (* 1 = 0.11065 loss)
I0509 22:22:25.393395 19026 sgd_solver.cpp:105] Iteration 5412, lr = 0.00127687
I0509 22:22:30.357682 19026 solver.cpp:218] Iteration 5424 (2.41726 iter/s, 4.9643s/12 iters), loss = 0.145351
I0509 22:22:30.357722 19026 solver.cpp:237]     Train net output #0: loss = 0.145351 (* 1 = 0.145351 loss)
I0509 22:22:30.357730 19026 sgd_solver.cpp:105] Iteration 5424, lr = 0.00126599
I0509 22:22:35.328191 19026 solver.cpp:218] Iteration 5436 (2.41426 iter/s, 4.97047s/12 iters), loss = 0.11257
I0509 22:22:35.328308 19026 solver.cpp:237]     Train net output #0: loss = 0.11257 (* 1 = 0.11257 loss)
I0509 22:22:35.328318 19026 sgd_solver.cpp:105] Iteration 5436, lr = 0.00125519
I0509 22:22:40.257726 19026 solver.cpp:218] Iteration 5448 (2.43436 iter/s, 4.92942s/12 iters), loss = 0.0875584
I0509 22:22:40.257763 19026 solver.cpp:237]     Train net output #0: loss = 0.0875584 (* 1 = 0.0875584 loss)
I0509 22:22:40.257771 19026 sgd_solver.cpp:105] Iteration 5448, lr = 0.00124446
I0509 22:22:45.216984 19026 solver.cpp:218] Iteration 5460 (2.41973 iter/s, 4.95922s/12 iters), loss = 0.203237
I0509 22:22:45.217027 19026 solver.cpp:237]     Train net output #0: loss = 0.203237 (* 1 = 0.203237 loss)
I0509 22:22:45.217036 19026 sgd_solver.cpp:105] Iteration 5460, lr = 0.00123382
I0509 22:22:45.765372 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:22:50.152395 19026 solver.cpp:218] Iteration 5472 (2.43143 iter/s, 4.93537s/12 iters), loss = 0.114677
I0509 22:22:50.152434 19026 solver.cpp:237]     Train net output #0: loss = 0.114677 (* 1 = 0.114677 loss)
I0509 22:22:50.152442 19026 sgd_solver.cpp:105] Iteration 5472, lr = 0.00122326
I0509 22:22:55.130508 19026 solver.cpp:218] Iteration 5484 (2.41057 iter/s, 4.97808s/12 iters), loss = 0.122681
I0509 22:22:55.130551 19026 solver.cpp:237]     Train net output #0: loss = 0.122681 (* 1 = 0.122681 loss)
I0509 22:22:55.130559 19026 sgd_solver.cpp:105] Iteration 5484, lr = 0.00121277
I0509 22:23:00.092581 19026 solver.cpp:218] Iteration 5496 (2.41836 iter/s, 4.96203s/12 iters), loss = 0.151548
I0509 22:23:00.092620 19026 solver.cpp:237]     Train net output #0: loss = 0.151548 (* 1 = 0.151548 loss)
I0509 22:23:00.092628 19026 sgd_solver.cpp:105] Iteration 5496, lr = 0.00120236
I0509 22:23:04.558765 19026 solver.cpp:330] Iteration 5508, Testing net (#0)
I0509 22:23:04.558792 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:23:10.673156 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:23:11.467267 19026 solver.cpp:397]     Test net output #0: accuracy = 0.498766
I0509 22:23:11.467308 19026 solver.cpp:397]     Test net output #1: loss = 2.70921 (* 1 = 2.70921 loss)
I0509 22:23:11.563760 19026 solver.cpp:218] Iteration 5508 (1.0461 iter/s, 11.4712s/12 iters), loss = 0.09476
I0509 22:23:11.563802 19026 solver.cpp:237]     Train net output #0: loss = 0.0947599 (* 1 = 0.0947599 loss)
I0509 22:23:11.563810 19026 sgd_solver.cpp:105] Iteration 5508, lr = 0.00119203
I0509 22:23:15.786666 19026 solver.cpp:218] Iteration 5520 (2.84167 iter/s, 4.22287s/12 iters), loss = 0.0710697
I0509 22:23:15.786707 19026 solver.cpp:237]     Train net output #0: loss = 0.0710697 (* 1 = 0.0710697 loss)
I0509 22:23:15.786715 19026 sgd_solver.cpp:105] Iteration 5520, lr = 0.00118177
I0509 22:23:20.760347 19026 solver.cpp:218] Iteration 5532 (2.41272 iter/s, 4.97365s/12 iters), loss = 0.071547
I0509 22:23:20.760388 19026 solver.cpp:237]     Train net output #0: loss = 0.071547 (* 1 = 0.071547 loss)
I0509 22:23:20.760396 19026 sgd_solver.cpp:105] Iteration 5532, lr = 0.0011716
I0509 22:23:25.827935 19026 solver.cpp:218] Iteration 5544 (2.368 iter/s, 5.06756s/12 iters), loss = 0.0832953
I0509 22:23:25.827977 19026 solver.cpp:237]     Train net output #0: loss = 0.0832952 (* 1 = 0.0832952 loss)
I0509 22:23:25.827986 19026 sgd_solver.cpp:105] Iteration 5544, lr = 0.00116149
I0509 22:23:30.840979 19026 solver.cpp:218] Iteration 5556 (2.39377 iter/s, 5.01301s/12 iters), loss = 0.0747713
I0509 22:23:30.841022 19026 solver.cpp:237]     Train net output #0: loss = 0.0747713 (* 1 = 0.0747713 loss)
I0509 22:23:30.841028 19026 sgd_solver.cpp:105] Iteration 5556, lr = 0.00115147
I0509 22:23:33.529250 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:23:35.829551 19026 solver.cpp:218] Iteration 5568 (2.40552 iter/s, 4.98853s/12 iters), loss = 0.111353
I0509 22:23:35.829602 19026 solver.cpp:237]     Train net output #0: loss = 0.111352 (* 1 = 0.111352 loss)
I0509 22:23:35.829610 19026 sgd_solver.cpp:105] Iteration 5568, lr = 0.00114151
I0509 22:23:40.838060 19026 solver.cpp:218] Iteration 5580 (2.39594 iter/s, 5.00846s/12 iters), loss = 0.0626151
I0509 22:23:40.838147 19026 solver.cpp:237]     Train net output #0: loss = 0.062615 (* 1 = 0.062615 loss)
I0509 22:23:40.838156 19026 sgd_solver.cpp:105] Iteration 5580, lr = 0.00113164
I0509 22:23:45.826117 19026 solver.cpp:218] Iteration 5592 (2.40579 iter/s, 4.98798s/12 iters), loss = 0.057463
I0509 22:23:45.826159 19026 solver.cpp:237]     Train net output #0: loss = 0.057463 (* 1 = 0.057463 loss)
I0509 22:23:45.826169 19026 sgd_solver.cpp:105] Iteration 5592, lr = 0.00112184
I0509 22:23:50.693248 19026 solver.cpp:218] Iteration 5604 (2.46554 iter/s, 4.86708s/12 iters), loss = 0.0784514
I0509 22:23:50.693310 19026 solver.cpp:237]     Train net output #0: loss = 0.0784514 (* 1 = 0.0784514 loss)
I0509 22:23:50.693322 19026 sgd_solver.cpp:105] Iteration 5604, lr = 0.00111211
I0509 22:23:52.647244 19026 solver.cpp:330] Iteration 5610, Testing net (#0)
I0509 22:23:52.647266 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:23:58.805951 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:23:59.678570 19026 solver.cpp:397]     Test net output #0: accuracy = 0.493421
I0509 22:23:59.678612 19026 solver.cpp:397]     Test net output #1: loss = 2.71893 (* 1 = 2.71893 loss)
I0509 22:24:01.567340 19026 solver.cpp:218] Iteration 5616 (1.10354 iter/s, 10.8741s/12 iters), loss = 0.121816
I0509 22:24:01.567391 19026 solver.cpp:237]     Train net output #0: loss = 0.121816 (* 1 = 0.121816 loss)
I0509 22:24:01.567405 19026 sgd_solver.cpp:105] Iteration 5616, lr = 0.00110246
I0509 22:24:06.533473 19026 solver.cpp:218] Iteration 5628 (2.41639 iter/s, 4.96609s/12 iters), loss = 0.0947419
I0509 22:24:06.533514 19026 solver.cpp:237]     Train net output #0: loss = 0.0947418 (* 1 = 0.0947418 loss)
I0509 22:24:06.533522 19026 sgd_solver.cpp:105] Iteration 5628, lr = 0.00109288
I0509 22:24:11.480525 19026 solver.cpp:218] Iteration 5640 (2.4257 iter/s, 4.94702s/12 iters), loss = 0.0890154
I0509 22:24:11.480659 19026 solver.cpp:237]     Train net output #0: loss = 0.0890153 (* 1 = 0.0890153 loss)
I0509 22:24:11.480670 19026 sgd_solver.cpp:105] Iteration 5640, lr = 0.00108337
I0509 22:24:16.464824 19026 solver.cpp:218] Iteration 5652 (2.40762 iter/s, 4.98417s/12 iters), loss = 0.160196
I0509 22:24:16.464867 19026 solver.cpp:237]     Train net output #0: loss = 0.160196 (* 1 = 0.160196 loss)
I0509 22:24:16.464876 19026 sgd_solver.cpp:105] Iteration 5652, lr = 0.00107393
I0509 22:24:21.264637 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:24:21.433013 19026 solver.cpp:218] Iteration 5664 (2.41538 iter/s, 4.96815s/12 iters), loss = 0.0739092
I0509 22:24:21.433054 19026 solver.cpp:237]     Train net output #0: loss = 0.0739091 (* 1 = 0.0739091 loss)
I0509 22:24:21.433061 19026 sgd_solver.cpp:105] Iteration 5664, lr = 0.00106457
I0509 22:24:26.374835 19026 solver.cpp:218] Iteration 5676 (2.42827 iter/s, 4.94179s/12 iters), loss = 0.139548
I0509 22:24:26.374876 19026 solver.cpp:237]     Train net output #0: loss = 0.139548 (* 1 = 0.139548 loss)
I0509 22:24:26.374884 19026 sgd_solver.cpp:105] Iteration 5676, lr = 0.00105528
I0509 22:24:31.347498 19026 solver.cpp:218] Iteration 5688 (2.41321 iter/s, 4.97262s/12 iters), loss = 0.0916695
I0509 22:24:31.347540 19026 solver.cpp:237]     Train net output #0: loss = 0.0916695 (* 1 = 0.0916695 loss)
I0509 22:24:31.347548 19026 sgd_solver.cpp:105] Iteration 5688, lr = 0.00104606
I0509 22:24:36.287333 19026 solver.cpp:218] Iteration 5700 (2.42925 iter/s, 4.9398s/12 iters), loss = 0.126246
I0509 22:24:36.287371 19026 solver.cpp:237]     Train net output #0: loss = 0.126246 (* 1 = 0.126246 loss)
I0509 22:24:36.287379 19026 sgd_solver.cpp:105] Iteration 5700, lr = 0.00103692
I0509 22:24:40.785601 19026 solver.cpp:330] Iteration 5712, Testing net (#0)
I0509 22:24:40.785620 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:24:47.048597 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:24:47.868669 19026 solver.cpp:397]     Test net output #0: accuracy = 0.500411
I0509 22:24:47.868716 19026 solver.cpp:397]     Test net output #1: loss = 2.66328 (* 1 = 2.66328 loss)
I0509 22:24:47.965209 19026 solver.cpp:218] Iteration 5712 (1.02758 iter/s, 11.6779s/12 iters), loss = 0.102322
I0509 22:24:47.965246 19026 solver.cpp:237]     Train net output #0: loss = 0.102322 (* 1 = 0.102322 loss)
I0509 22:24:47.965255 19026 sgd_solver.cpp:105] Iteration 5712, lr = 0.00102784
I0509 22:24:52.061590 19026 solver.cpp:218] Iteration 5724 (2.92944 iter/s, 4.09635s/12 iters), loss = 0.121791
I0509 22:24:52.061633 19026 solver.cpp:237]     Train net output #0: loss = 0.12179 (* 1 = 0.12179 loss)
I0509 22:24:52.061641 19026 sgd_solver.cpp:105] Iteration 5724, lr = 0.00101883
I0509 22:24:56.982167 19026 solver.cpp:218] Iteration 5736 (2.43876 iter/s, 4.92054s/12 iters), loss = 0.093107
I0509 22:24:56.982210 19026 solver.cpp:237]     Train net output #0: loss = 0.093107 (* 1 = 0.093107 loss)
I0509 22:24:56.982218 19026 sgd_solver.cpp:105] Iteration 5736, lr = 0.0010099
I0509 22:25:01.951515 19026 solver.cpp:218] Iteration 5748 (2.41482 iter/s, 4.96931s/12 iters), loss = 0.0529532
I0509 22:25:01.951557 19026 solver.cpp:237]     Train net output #0: loss = 0.0529531 (* 1 = 0.0529531 loss)
I0509 22:25:01.951565 19026 sgd_solver.cpp:105] Iteration 5748, lr = 0.00100103
I0509 22:25:06.910820 19026 solver.cpp:218] Iteration 5760 (2.41971 iter/s, 4.95927s/12 iters), loss = 0.0907409
I0509 22:25:06.910864 19026 solver.cpp:237]     Train net output #0: loss = 0.0907408 (* 1 = 0.0907408 loss)
I0509 22:25:06.910872 19026 sgd_solver.cpp:105] Iteration 5760, lr = 0.000992235
I0509 22:25:08.834676 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:25:11.836138 19026 solver.cpp:218] Iteration 5772 (2.43641 iter/s, 4.92528s/12 iters), loss = 0.111145
I0509 22:25:11.836179 19026 solver.cpp:237]     Train net output #0: loss = 0.111145 (* 1 = 0.111145 loss)
I0509 22:25:11.836185 19026 sgd_solver.cpp:105] Iteration 5772, lr = 0.000983507
I0509 22:25:16.804123 19026 solver.cpp:218] Iteration 5784 (2.41548 iter/s, 4.96795s/12 iters), loss = 0.107613
I0509 22:25:16.804169 19026 solver.cpp:237]     Train net output #0: loss = 0.107613 (* 1 = 0.107613 loss)
I0509 22:25:16.804177 19026 sgd_solver.cpp:105] Iteration 5784, lr = 0.000974847
I0509 22:25:21.722923 19026 solver.cpp:218] Iteration 5796 (2.43964 iter/s, 4.91876s/12 iters), loss = 0.170439
I0509 22:25:21.723078 19026 solver.cpp:237]     Train net output #0: loss = 0.170439 (* 1 = 0.170439 loss)
I0509 22:25:21.723088 19026 sgd_solver.cpp:105] Iteration 5796, lr = 0.000966255
I0509 22:25:26.684475 19026 solver.cpp:218] Iteration 5808 (2.41867 iter/s, 4.9614s/12 iters), loss = 0.0429737
I0509 22:25:26.684540 19026 solver.cpp:237]     Train net output #0: loss = 0.0429737 (* 1 = 0.0429737 loss)
I0509 22:25:26.684553 19026 sgd_solver.cpp:105] Iteration 5808, lr = 0.000957731
I0509 22:25:28.679437 19026 solver.cpp:330] Iteration 5814, Testing net (#0)
I0509 22:25:28.679461 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:25:34.724427 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:25:35.569160 19026 solver.cpp:397]     Test net output #0: accuracy = 0.498355
I0509 22:25:35.569211 19026 solver.cpp:397]     Test net output #1: loss = 2.67846 (* 1 = 2.67846 loss)
I0509 22:25:37.402508 19026 solver.cpp:218] Iteration 5820 (1.11961 iter/s, 10.718s/12 iters), loss = 0.0639272
I0509 22:25:37.402552 19026 solver.cpp:237]     Train net output #0: loss = 0.0639271 (* 1 = 0.0639271 loss)
I0509 22:25:37.402561 19026 sgd_solver.cpp:105] Iteration 5820, lr = 0.000949275
I0509 22:25:42.385967 19026 solver.cpp:218] Iteration 5832 (2.40798 iter/s, 4.98342s/12 iters), loss = 0.0752334
I0509 22:25:42.386008 19026 solver.cpp:237]     Train net output #0: loss = 0.0752333 (* 1 = 0.0752333 loss)
I0509 22:25:42.386018 19026 sgd_solver.cpp:105] Iteration 5832, lr = 0.000940885
I0509 22:25:47.342032 19026 solver.cpp:218] Iteration 5844 (2.4213 iter/s, 4.95602s/12 iters), loss = 0.0856403
I0509 22:25:47.342075 19026 solver.cpp:237]     Train net output #0: loss = 0.0856402 (* 1 = 0.0856402 loss)
I0509 22:25:47.342083 19026 sgd_solver.cpp:105] Iteration 5844, lr = 0.000932562
I0509 22:25:52.286520 19026 solver.cpp:218] Iteration 5856 (2.42696 iter/s, 4.94445s/12 iters), loss = 0.0878403
I0509 22:25:52.286649 19026 solver.cpp:237]     Train net output #0: loss = 0.0878402 (* 1 = 0.0878402 loss)
I0509 22:25:52.286659 19026 sgd_solver.cpp:105] Iteration 5856, lr = 0.000924305
I0509 22:25:56.465651 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:25:57.261775 19026 solver.cpp:218] Iteration 5868 (2.41199 iter/s, 4.97514s/12 iters), loss = 0.0786323
I0509 22:25:57.261812 19026 solver.cpp:237]     Train net output #0: loss = 0.0786323 (* 1 = 0.0786323 loss)
I0509 22:25:57.261821 19026 sgd_solver.cpp:105] Iteration 5868, lr = 0.000916113
I0509 22:26:02.201776 19026 solver.cpp:218] Iteration 5880 (2.42917 iter/s, 4.93997s/12 iters), loss = 0.0427767
I0509 22:26:02.201818 19026 solver.cpp:237]     Train net output #0: loss = 0.0427767 (* 1 = 0.0427767 loss)
I0509 22:26:02.201826 19026 sgd_solver.cpp:105] Iteration 5880, lr = 0.000907987
I0509 22:26:07.183617 19026 solver.cpp:218] Iteration 5892 (2.40877 iter/s, 4.9818s/12 iters), loss = 0.128639
I0509 22:26:07.183660 19026 solver.cpp:237]     Train net output #0: loss = 0.128639 (* 1 = 0.128639 loss)
I0509 22:26:07.183668 19026 sgd_solver.cpp:105] Iteration 5892, lr = 0.000899926
I0509 22:26:12.112848 19026 solver.cpp:218] Iteration 5904 (2.43448 iter/s, 4.92919s/12 iters), loss = 0.213812
I0509 22:26:12.112891 19026 solver.cpp:237]     Train net output #0: loss = 0.213812 (* 1 = 0.213812 loss)
I0509 22:26:12.112900 19026 sgd_solver.cpp:105] Iteration 5904, lr = 0.000891929
I0509 22:26:16.597792 19026 solver.cpp:330] Iteration 5916, Testing net (#0)
I0509 22:26:16.597823 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:26:19.142405 19026 blocking_queue.cpp:49] Waiting for data
I0509 22:26:22.618728 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:26:23.470072 19026 solver.cpp:397]     Test net output #0: accuracy = 0.5
I0509 22:26:23.470118 19026 solver.cpp:397]     Test net output #1: loss = 2.70537 (* 1 = 2.70537 loss)
I0509 22:26:23.566642 19026 solver.cpp:218] Iteration 5916 (1.04769 iter/s, 11.4538s/12 iters), loss = 0.123232
I0509 22:26:23.566685 19026 solver.cpp:237]     Train net output #0: loss = 0.123232 (* 1 = 0.123232 loss)
I0509 22:26:23.566694 19026 sgd_solver.cpp:105] Iteration 5916, lr = 0.000883997
I0509 22:26:27.686540 19026 solver.cpp:218] Iteration 5928 (2.91272 iter/s, 4.11985s/12 iters), loss = 0.0319149
I0509 22:26:27.686579 19026 solver.cpp:237]     Train net output #0: loss = 0.0319149 (* 1 = 0.0319149 loss)
I0509 22:26:27.686587 19026 sgd_solver.cpp:105] Iteration 5928, lr = 0.000876128
I0509 22:26:32.634359 19026 solver.cpp:218] Iteration 5940 (2.42533 iter/s, 4.94778s/12 iters), loss = 0.115656
I0509 22:26:32.634407 19026 solver.cpp:237]     Train net output #0: loss = 0.115656 (* 1 = 0.115656 loss)
I0509 22:26:32.634416 19026 sgd_solver.cpp:105] Iteration 5940, lr = 0.000868323
I0509 22:26:37.605922 19026 solver.cpp:218] Iteration 5952 (2.41375 iter/s, 4.97152s/12 iters), loss = 0.0611556
I0509 22:26:37.605967 19026 solver.cpp:237]     Train net output #0: loss = 0.0611555 (* 1 = 0.0611555 loss)
I0509 22:26:37.605974 19026 sgd_solver.cpp:105] Iteration 5952, lr = 0.00086058
I0509 22:26:42.569156 19026 solver.cpp:218] Iteration 5964 (2.4178 iter/s, 4.96319s/12 iters), loss = 0.0844679
I0509 22:26:42.569203 19026 solver.cpp:237]     Train net output #0: loss = 0.0844678 (* 1 = 0.0844678 loss)
I0509 22:26:42.569212 19026 sgd_solver.cpp:105] Iteration 5964, lr = 0.000852901
I0509 22:26:43.866973 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:26:47.494083 19026 solver.cpp:218] Iteration 5976 (2.4366 iter/s, 4.92489s/12 iters), loss = 0.0502722
I0509 22:26:47.494123 19026 solver.cpp:237]     Train net output #0: loss = 0.0502721 (* 1 = 0.0502721 loss)
I0509 22:26:47.494132 19026 sgd_solver.cpp:105] Iteration 5976, lr = 0.000845283
I0509 22:26:52.462136 19026 solver.cpp:218] Iteration 5988 (2.41545 iter/s, 4.96801s/12 iters), loss = 0.0857417
I0509 22:26:52.462182 19026 solver.cpp:237]     Train net output #0: loss = 0.0857417 (* 1 = 0.0857417 loss)
I0509 22:26:52.462190 19026 sgd_solver.cpp:105] Iteration 5988, lr = 0.000837727
I0509 22:26:57.426982 19026 solver.cpp:218] Iteration 6000 (2.41701 iter/s, 4.96481s/12 iters), loss = 0.0670133
I0509 22:26:57.427120 19026 solver.cpp:237]     Train net output #0: loss = 0.0670132 (* 1 = 0.0670132 loss)
I0509 22:26:57.427129 19026 sgd_solver.cpp:105] Iteration 6000, lr = 0.000830233
I0509 22:27:02.370517 19026 solver.cpp:218] Iteration 6012 (2.42748 iter/s, 4.9434s/12 iters), loss = 0.0711047
I0509 22:27:02.370558 19026 solver.cpp:237]     Train net output #0: loss = 0.0711046 (* 1 = 0.0711046 loss)
I0509 22:27:02.370566 19026 sgd_solver.cpp:105] Iteration 6012, lr = 0.0008228
I0509 22:27:04.363036 19026 solver.cpp:330] Iteration 6018, Testing net (#0)
I0509 22:27:04.363056 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:27:10.755977 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:27:11.694684 19026 solver.cpp:397]     Test net output #0: accuracy = 0.505345
I0509 22:27:11.694730 19026 solver.cpp:397]     Test net output #1: loss = 2.69908 (* 1 = 2.69908 loss)
I0509 22:27:13.495220 19026 solver.cpp:218] Iteration 6024 (1.07868 iter/s, 11.1247s/12 iters), loss = 0.0780319
I0509 22:27:13.495260 19026 solver.cpp:237]     Train net output #0: loss = 0.0780319 (* 1 = 0.0780319 loss)
I0509 22:27:13.495268 19026 sgd_solver.cpp:105] Iteration 6024, lr = 0.000815427
I0509 22:27:18.440409 19026 solver.cpp:218] Iteration 6036 (2.42662 iter/s, 4.94515s/12 iters), loss = 0.0810413
I0509 22:27:18.440449 19026 solver.cpp:237]     Train net output #0: loss = 0.0810412 (* 1 = 0.0810412 loss)
I0509 22:27:18.440457 19026 sgd_solver.cpp:105] Iteration 6036, lr = 0.000808114
I0509 22:27:23.404271 19026 solver.cpp:218] Iteration 6048 (2.41749 iter/s, 4.96383s/12 iters), loss = 0.154968
I0509 22:27:23.404309 19026 solver.cpp:237]     Train net output #0: loss = 0.154968 (* 1 = 0.154968 loss)
I0509 22:27:23.404318 19026 sgd_solver.cpp:105] Iteration 6048, lr = 0.000800862
I0509 22:27:28.334069 19026 solver.cpp:218] Iteration 6060 (2.43419 iter/s, 4.92976s/12 iters), loss = 0.0844331
I0509 22:27:28.334224 19026 solver.cpp:237]     Train net output #0: loss = 0.084433 (* 1 = 0.084433 loss)
I0509 22:27:28.334233 19026 sgd_solver.cpp:105] Iteration 6060, lr = 0.000793669
I0509 22:27:31.783987 19031 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:27:33.304023 19026 solver.cpp:218] Iteration 6072 (2.41458 iter/s, 4.96981s/12 iters), loss = 0.0890982
I0509 22:27:33.304066 19026 solver.cpp:237]     Train net output #0: loss = 0.0890981 (* 1 = 0.0890981 loss)
I0509 22:27:33.304075 19026 sgd_solver.cpp:105] Iteration 6072, lr = 0.000786535
I0509 22:27:38.258189 19026 solver.cpp:218] Iteration 6084 (2.42222 iter/s, 4.95412s/12 iters), loss = 0.124816
I0509 22:27:38.258230 19026 solver.cpp:237]     Train net output #0: loss = 0.124815 (* 1 = 0.124815 loss)
I0509 22:27:38.258239 19026 sgd_solver.cpp:105] Iteration 6084, lr = 0.000779459
I0509 22:27:43.217028 19026 solver.cpp:218] Iteration 6096 (2.41994 iter/s, 4.9588s/12 iters), loss = 0.0636831
I0509 22:27:43.217072 19026 solver.cpp:237]     Train net output #0: loss = 0.0636831 (* 1 = 0.0636831 loss)
I0509 22:27:43.217079 19026 sgd_solver.cpp:105] Iteration 6096, lr = 0.000772442
I0509 22:27:48.195569 19026 solver.cpp:218] Iteration 6108 (2.41036 iter/s, 4.97851s/12 iters), loss = 0.0805253
I0509 22:27:48.195607 19026 solver.cpp:237]     Train net output #0: loss = 0.0805253 (* 1 = 0.0805253 loss)
I0509 22:27:48.195616 19026 sgd_solver.cpp:105] Iteration 6108, lr = 0.000765483
I0509 22:27:52.657212 19026 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_6120.caffemodel
I0509 22:27:56.172245 19026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6120.solverstate
I0509 22:27:58.579051 19026 solver.cpp:310] Iteration 6120, loss = 0.0699758
I0509 22:27:58.579119 19026 solver.cpp:330] Iteration 6120, Testing net (#0)
I0509 22:27:58.579125 19026 net.cpp:676] Ignoring source layer train-data
I0509 22:28:04.791620 19032 data_layer.cpp:73] Restarting data prefetching from start.
I0509 22:28:05.675537 19026 solver.cpp:397]     Test net output #0: accuracy = 0.508635
I0509 22:28:05.675585 19026 solver.cpp:397]     Test net output #1: loss = 2.6886 (* 1 = 2.6886 loss)
I0509 22:28:05.675596 19026 solver.cpp:315] Optimization Done.
I0509 22:28:05.675603 19026 caffe.cpp:259] Optimization Done.
